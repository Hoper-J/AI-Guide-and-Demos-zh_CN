{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945de83c-51d8-429a-9a08-4d89b254db9d",
   "metadata": {},
   "source": [
    "# HW4: æˆä¸º AI å‚¬çœ å¤§å¸ˆ\n",
    "\n",
    "> [HW4: Become an AI Hypnosis Master](https://colab.research.google.com/drive/16JzVN_Mu4mJfyHQpQEuDx1q6jI-cAnEl?hl=zh-tw#scrollTo=RI0hC7SFT3Sr&uniqifier=1) ä¸­æ–‡é•œåƒç‰ˆ\n",
    "\n",
    "ç›®æ ‡ï¼š\n",
    "1. äº†è§£å„ç§ Prompt å¦‚ä½•å½±å“å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "2. è®¾è®¡ Prompt æé«˜å¤§æ¨¡å‹è§£å†³æ•°å­¦é—®é¢˜çš„æ­£ç¡®æ€§\n",
    "\n",
    "\n",
    "P.S. è¿™é‡Œä¿®æ­£äº†ä¸€äº›ä¸é¢„æœŸè¡Œä¸ºä¸ç¬¦çš„ä»£ç "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828ffb4-44cb-4bd5-ab23-e44eeb1de578",
   "metadata": {},
   "source": [
    "## å‡†å¤‡é˜¶æ®µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e02231-4180-4b13-b9ac-33cfa68a4016",
   "metadata": {},
   "source": [
    "### ä¸‹è½½éœ€è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b89f0-b911-4c3b-90ea-3e67468453c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm jinja2 gradio tiktoken openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320655c-3ec6-4366-a3da-b6d1cb9d3f97",
   "metadata": {},
   "source": [
    "### å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036dbde-b141-435d-ade2-b3e8a60b19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "import openai\n",
    "import tiktoken  # ç”¨äº prompt_token_num()\n",
    "import jinja2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff576b53-87d2-4d55-9e3c-7cc4b456a098",
   "metadata": {},
   "source": [
    "### è®¾ç½® openai api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be165c-6879-4da9-923f-d7f2bf110179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: è®¾ç½®ä½ çš„ OPENAI API å¯†é’¥ï¼Œè¿™é‡Œä»¥é˜¿é‡Œäº‘ DashScope APIä¸ºä¾‹è¿›è¡Œæ¼”ç¤º\n",
    "OPENAI_API_KEY = \"\"\n",
    "client = openai.OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # ä½¿ç”¨é˜¿é‡Œäº‘å¤§æ¨¡å‹API\n",
    ")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æ­£ç¡®è®¾ç½®äº† API\n",
    "# å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œä½ å°†çœ‹åˆ° \"API è®¾ç½®æˆåŠŸï¼ï¼\"\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"qwen-turbo\",  # ä½¿ç”¨é˜¿é‡Œäº‘ DashScope çš„æ¨¡å‹\n",
    "            messages=[{'role': 'user', 'content': \"æµ‹è¯•\"}],  # è®¾ç½®ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¶ˆæ¯\n",
    "            max_tokens=1,\n",
    "    )\n",
    "    print(\"API è®¾ç½®æˆåŠŸï¼ï¼\")  # è¾“å‡ºæˆåŠŸä¿¡æ¯\n",
    "except Exception as e:\n",
    "    print(f\"API å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š{e}\")  # è¾“å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2253d-d032-41de-a067-37c0dd2651db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIModel():\n",
    "    def __init__(self, cache_file=\"openai_cache\"):\n",
    "        # åˆå§‹åŒ– OpenAI æ¨¡å‹å¯¹è±¡ï¼Œå¹¶è®¾ç½®ç¼“å­˜æ–‡ä»¶\n",
    "        self.cache_file = cache_file\n",
    "        self.cache_dict = self.load_cache()  # åŠ è½½ç¼“å­˜\n",
    "\n",
    "    def save_cache(self):\n",
    "        # å°†å½“å‰ç¼“å­˜ä¿å­˜åˆ°æ–‡ä»¶\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            pickle.dump(self.cache_dict, f)\n",
    "\n",
    "    def load_cache(self, allow_retry=True):\n",
    "        # ä»æ–‡ä»¶åŠ è½½ç¼“å­˜ï¼Œå¸¦æœ‰é‡è¯•æœºåˆ¶\n",
    "        if os.path.exists(self.cache_file):\n",
    "            while True:\n",
    "                try:\n",
    "                    with open(self.cache_file, \"rb\") as f:\n",
    "                        cache = pickle.load(f)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    if not allow_retry:\n",
    "                        assert False\n",
    "                    print(\"Pickle Error: 5ç§’åé‡è¯•...\")\n",
    "                    time.sleep(5)\n",
    "        else:\n",
    "            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ç¼“å­˜\n",
    "            cache = {}\n",
    "        return cache\n",
    "\n",
    "    def set_cache_file(self, file_name):\n",
    "        # è®¾ç½®ç¼“å­˜æ–‡ä»¶åå¹¶åŠ è½½ç¼“å­˜\n",
    "        self.cache_file = file_name\n",
    "        self.cache_dict = self.load_cache()\n",
    "\n",
    "    def get_completion(self, content):\n",
    "        # è·å–æ¨¡å‹å®Œæˆçš„æ–‡æœ¬ï¼Œå…ˆæ£€æŸ¥ç¼“å­˜ï¼Œè‹¥æ— åˆ™è¯·æ±‚ç”Ÿæˆ\n",
    "        # å¦‚æœé€‰æ‹©æ£€æŸ¥ç¼“å­˜ï¼Œåˆ™ä¼šå¯¼è‡´åŒé—®é¢˜ä¸åŒtrialçš„ç»“æœç›¸åŒï¼Œè¿™ä¸å®é™…æƒ³è¡¨è¾¾çš„å†…å®¹ä¸ç¬¦ï¼Œæ•…æ³¨é‡Š\n",
    "        # if content in self.cache_dict:\n",
    "        #     return self.cache_dict[content]\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå†…å®¹\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"qwen-turbo\",\n",
    "                    messages=[{'role': 'user', 'content': content}],\n",
    "                    temperature=1.0,\n",
    "                )\n",
    "                completion = response.choices[0].message.content\n",
    "                self.cache_dict[content] = completion\n",
    "                return completion\n",
    "            except Exception as e:\n",
    "                print(e, \"\\n\")\n",
    "                time.sleep(1)\n",
    "        return None\n",
    "\n",
    "    def is_valid_key(self):\n",
    "        # æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ\n",
    "        for _ in range(4):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"qwen-turbo\",\n",
    "                    messages=[{'role': 'user', 'content': \"hi there\"}],\n",
    "                    temperature=1.0,\n",
    "                    max_tokens=1\n",
    "                )\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                time.sleep(1)\n",
    "        return False\n",
    "\n",
    "    def prompt_token_num(self, prompt):\n",
    "        # ä½¿ç”¨ tiktoken æ¥è®¡ç®— token æ•°é‡\n",
    "        try:\n",
    "            # ä½¿ç”¨ gpt-3.5-turbo çš„ç¼–ç å™¨ï¼Œå› ä¸º tiktoken åº“ä¸æ”¯æŒè‡ªåŠ¨è¯†åˆ« qwen-turbo æ¨¡å‹\n",
    "            encoding = tiktoken.get_encoding(\"cl100k_base\")  # è¿™æ˜¯ GPT-3.5-turbo æ‰€ä½¿ç”¨çš„ç¼–ç å™¨\n",
    "            # å°† prompt ç¼–ç æˆ tokenï¼Œå¹¶è¿”å› token æ•°é‡\n",
    "            tokens = encoding.encode(prompt)\n",
    "            return len(tokens)\n",
    "        except Exception as e:\n",
    "            print(f\"è®¡ç®— token æ•°é‡æ—¶å‡ºé”™: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def two_stage_completion(self, question, content):\n",
    "        # ä¸¤é˜¶æ®µå®Œæˆï¼šé¦–å…ˆè·å–æ¨ç†ï¼Œå†è·å–æœ€ç»ˆç­”æ¡ˆ\n",
    "        rationale = self.get_completion(content)\n",
    "        if not rationale:\n",
    "            return {\n",
    "                'prompt': content,\n",
    "                'rationale': None,\n",
    "                'answer': None\n",
    "            }\n",
    "\n",
    "        ans = self.get_completion(content=f\"Q:{question}\\nA:{rationale}\\nThe answer to the original question is (a number only): \")\n",
    "        return {\n",
    "            'prompt': content,\n",
    "            'rationale': rationale,\n",
    "            'answer': ans\n",
    "        }\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "my_model = OpenAIModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38238b-9495-4288-8083-29d148ce13fc",
   "metadata": {},
   "source": [
    "### ç”¨äºè¯„ä¼° Prompt çš„æ•°å­¦é—®é¢˜ã€‚\n",
    "\n",
    "- æˆ‘ä»¬æä¾›äº†30ä¸ªé—®é¢˜ç”¨äºè¯„ä¼°ä½ çš„ Promptï¼š[é“¾æ¥](https://docs.google.com/spreadsheets/d/1IehN_Qx40wPcreVE5UorTQz-puCI8NbNDQEMvcuaZcs/edit?hl=zh-tw#gid=0)\n",
    "- è¿è¡Œæ­¤ä»£ç å—æ˜¯è®¾ç½®æ‰€æœ‰é—®é¢˜å’Œç­”æ¡ˆæ‰€å¿…éœ€çš„ã€‚å¦‚æœä¸è¿è¡Œæ­¤ä»£ç å—ï¼Œä½ å°†æ— æ³•åœ¨åç»­çš„ä»£ç å—ä¸­è®¿é—®è¿™äº›é—®é¢˜ã€‚\n",
    "- **è¯·å‹¿ä¿®æ”¹æ­¤ä»£ç å—ï¼**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11113f-ceea-41a5-b7e2-65f25552fbb9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "questions = ['ä¸€ä½è‰ºæœ¯å®¶æ­£åœ¨ä½¿ç”¨æ–¹å½¢ç“·ç –åˆ›å»ºä¸€ä¸ªå¤§å‹é©¬èµ›å…‹ã€‚é©¬èµ›å…‹æœ¬èº«è®¾è®¡æˆä¸€ä¸ªæ­£æ–¹å½¢ï¼Œå¹¶ä¸”åŒ…å«çš„è“è‰²ç“·ç –æ•°é‡æ°å¥½æ˜¯çº¢è‰²ç“·ç –çš„3å€ã€‚å¦‚æœè‰ºæœ¯å®¶åªæœ‰57å—çº¢è‰²ç“·ç –ï¼Œé‚£ä¹ˆè¦å®Œæˆæ•´ä¸ªé©¬èµ›å…‹å…±éœ€è¦å¤šå°‘å—ç“·ç –ï¼Ÿ',\n",
    " 'ä¸€ä½å†œæ°‘æ­£åœ¨ä¸ºå½“åœ°å¸‚åœºè£…è‹¹æœã€‚ä»–æœ‰120ä¸ªè‹¹æœï¼Œå¹¶å¸Œæœ›å°†å®ƒä»¬å‡åŒ€åˆ†é…åˆ°ç¯®å­ä¸­ã€‚å¦‚æœä»–å†³å®šç•™15ä¸ªè‹¹æœç»™å®¶äººï¼Œæ¯ä¸ªç¯®å­æœ€å¤šèƒ½è£…7ä¸ªè‹¹æœï¼Œé‚£ä¹ˆä»–æœ€å°‘éœ€è¦å¤šå°‘ä¸ªç¯®å­æ‰èƒ½å°†è‹¹æœå¸¦åˆ°å¸‚åœºï¼Ÿ',\n",
    " 'ä¸€ä¸ªèŠ±å›­æœ‰çŸ©å½¢çš„åœ°å—ï¼Œè¿™äº›åœ°å—æ’åˆ—æˆä¸€æ¡ç›´çº¿ï¼Œæ¯å—åœ°ä¸æ­£å¥½ä¸¤å—å…¶ä»–çš„åœ°å…±ç”¨è¾¹ç•Œã€‚å…±æœ‰5å—åœ°ã€‚ä¸­é—´çš„æ¯å—åœ°é¢ç§¯ä¸º24å¹³æ–¹ç±³ï¼Œåœ°å—çš„å®½åº¦ä¸º4ç±³ï¼Œæ‰€æœ‰åœ°å—çš„å®½åº¦ä¿æŒä¸å˜ã€‚ç¬¬ä¸€å—åœ°çš„é•¿åº¦æ˜¯ä¸­é—´åœ°å—çš„ä¸¤å€ï¼Œæœ€åä¸€å—åœ°çš„é•¿åº¦æ˜¯ä¸­é—´åœ°å—çš„ä¸€åŠã€‚é‚£ä¹ˆæ‰€æœ‰åœ°å—çš„æ€»é¢ç§¯æ˜¯å¤šå°‘å¹³æ–¹ç±³ï¼Ÿ',\n",
    " 'ä¸€ä¸ªå†œè´¸å¸‚åœºå‡ºå”®ä¸¤ç§ç±»å‹çš„è‹¹æœæ··åˆè¢‹ï¼šAå‹è¢‹å­åŒ…å«4ä¸ªçº¢è‹¹æœå’Œ6ä¸ªç»¿è‹¹æœï¼ŒBå‹è¢‹å­åŒ…å«8ä¸ªçº¢è‹¹æœå’Œ4ä¸ªç»¿è‹¹æœã€‚ä¸€ä½é¡¾å®¢è´­ä¹°äº†ä¸€è¢‹Aå‹å’Œä¸€è¢‹Bå‹çš„è‹¹æœã€‚å¦‚æœä»è¿™ä¸¤è¢‹è‹¹æœä¸­éšæœºæŒ‘é€‰ä¸€ä¸ªè‹¹æœï¼Œé€‰åˆ°ç»¿è‹¹æœçš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿè¯·å°†ç­”æ¡ˆä¿ç•™åˆ°å°æ•°ç‚¹åä¸¤ä½ã€‚',\n",
    " 'ä¸€ä½å›­ä¸æŒ‰ç…§ä¸¤æœµçº¢è‰²èŠ±è·Ÿç€ä¸€æœµé»„è‰²èŠ±çš„æ¨¡å¼ç§èŠ±ã€‚å¦‚æœå›­ä¸æƒ³ä¿æŒè¿™ç§æ¨¡å¼ï¼Œå¹¶ä¸”æœ‰35ä¸ªè¿ç»­çš„ç©ºä½æ¥ç§èŠ±ï¼Œé‚£ä¹ˆå›­ä¸ä¼šç§å¤šå°‘æœµçº¢è‰²èŠ±ï¼Ÿ',\n",
    " 'æ°æ£®æ­£åœ¨ä¸ºé©¬æ‹‰æ¾è®­ç»ƒï¼Œä»–æ¯å¤©è·‘å›ºå®šçš„è·ç¦»ã€‚æ˜ŸæœŸä¸€ï¼Œä»–è·‘äº†5è‹±é‡Œã€‚ä¹‹åçš„æ¯ä¸€å¤©ï¼Œä»–å°†è·‘æ­¥è·ç¦»å¢åŠ 10%ã€‚å¦‚æœæ°æ£®æŒ‰ç…§è¿™ä¸ªæ¨¡å¼ç»§ç»­è·‘æ­¥ï¼Œé‚£ä¹ˆä»–åœ¨æ˜ŸæœŸäº”å°†è·‘å¤šå°‘è‹±é‡Œï¼Ÿ',\n",
    " 'åœ¨ä¸€ä¸ªä¸‰è§’å½¢çš„èŠ±å›è¾¹ä¸Šï¼Œæ¯æ¡è¾¹ä¸Šæœ‰16æ£µæ¤ç‰©ã€‚æ¯æ£µæ¤ç‰©éƒ½éœ€è¦ä¸€ä¸ªåŠå¾„ä¸º0.5ç±³çš„åœ†å½¢ç©ºé—´æ‰èƒ½æ­£å¸¸ç”Ÿé•¿ã€‚å‡è®¾æ¤ç‰©ç´§æŒ¨ç€æ’åˆ—ï¼Œå¹¶ä¸”æ²¿ç€ä¸‰è§’å½¢èŠ±å›çš„è¾¹æ’æˆä¸€æ¡ç›´çº¿ï¼Œé‚£ä¹ˆæ¯æ¡è¾¹ä¸Šç§æ¤ç‰©çš„çº¿æ€§è·ç¦»æ˜¯å¤šå°‘ç±³ï¼Ÿ',\n",
    " 'å¨å°”é€Šåšå£«æ­£åœ¨è®¾è®¡ä¸€ä¸ªå‡ ä½•èŠ±å›­ï¼ŒèŠ±å›­ä¸­çš„èŠ±æœµå›´ç»•ç€ä¸­å¤®çš„å–·æ³‰æ’åˆ—æˆåŒå¿ƒåœ†ã€‚æ¯ä¸€åœˆæ¯”é‡Œé¢ä¸€åœˆå¤š6æœµèŠ±ï¼Œå½¢æˆä¸€ä¸ªå…­è¾¹å½¢çš„å›¾æ¡ˆã€‚æœ€é‡Œé¢ä¸€åœˆæœ‰6æœµèŠ±ã€‚å¦‚æœå¨å°”é€Šåšå£«ç§è¶³å¤Ÿçš„èŠ±ï¼Œå½¢æˆ15åœˆï¼ˆåŒ…æ‹¬æœ€é‡Œé¢ä¸€åœˆï¼‰ï¼Œé‚£ä¹ˆè¿™ä¸ªèŠ±å›­æ€»å…±éœ€è¦å¤šå°‘æœµèŠ±ï¼Ÿ',\n",
    " 'ä¸€ä¸ªå°å›¾ä¹¦é¦†æ­£åœ¨é‡æ–°æ•´ç†ä¹¦ç±æ”¶è—ã€‚ä»–ä»¬æ€»å…±æœ‰120æœ¬ä¹¦ï¼Œè®¡åˆ’å¹³å‡åˆ†é…åˆ°5ä¸ªä¹¦æ¶ä¸Šã€‚æœ€ä¸Šé¢çš„ä¹¦æ¶åªèƒ½æ‰¿å—ç›¸å½“äºæœ€ä¸‹é¢ä¹¦æ¶ä¸€åŠé‡é‡çš„ä¹¦ã€‚å¦‚æœæœ€ä¸Šé¢çš„ä¹¦æ¶æ‰¿è½½15ç£…çš„ä¹¦ï¼Œè€Œå…¶ä»–ä¹¦æ¶æ¯ä¸ªèƒ½æ‰¿è½½ä¸¤å€çš„é‡é‡ï¼Œé‚£ä¹ˆæœ€ä¸‹é¢çš„ä¹¦æ¶èƒ½æ‰¿è½½å¤šå°‘ç£…çš„ä¹¦ï¼Ÿ',\n",
    " 'ä¸€ä»½é¥¼å¹²çš„é…æ–¹éœ€è¦3æ¯é¢ç²‰ã€2æ¯ç³–å’Œ1æ¯å·§å…‹åŠ›ç‰‡ã€‚å¦‚æœé©¬å…‹æƒ³è¦åšä¸‰å€é‡çš„é¥¼å¹²ï¼Œä½†åªæœ‰4æ¯ç³–ï¼Œé‚£ä¹ˆä»–è¿˜éœ€è¦å¤šå°‘æ¯ç³–ï¼Ÿ',\n",
    " 'ä¸€å®¶å® ç‰©åº—çš„åº—ä¸»æ­£åœ¨åˆ¶ä½œå®šåˆ¶é¸Ÿèˆã€‚æ¯ä¸ªé¸Ÿèˆå¤–éƒ¨éœ€è¦0.75å‡æœ¨ææ¸…æ¼†ã€‚å¦‚æœåº—ä¸»æœ‰ä¸€ç½10å‡çš„æœ¨ææ¸…æ¼†ï¼Œé‚£ä¹ˆä»–åœ¨éœ€è¦æ›´å¤šæ¸…æ¼†ä¹‹å‰æœ€å¤šå¯ä»¥åˆ¶ä½œå¤šå°‘ä¸ªé¸Ÿèˆï¼Ÿ',\n",
    " 'ä¸€ä¸ªå†œåœºæœ‰é¸¡å’Œç‰›ã€‚æ€»å…±æœ‰30ä¸ªå¤´ï¼Œ88æ¡è…¿ã€‚å†œåœºä¸Šæœ‰å¤šå°‘å¤´ç‰›ï¼Ÿ',\n",
    " 'ä¸€ä¸ªåœ°æ–¹å›¾ä¹¦é¦†æ­£åœ¨ç»„ç»‡ä¸€åœºæ—§ä¹¦ä¹‰å–ä¼šï¼Œä»¥ç­¹é›†èµ„é‡‘è´­ä¹°æ–°ä¹¦ã€‚ä»–ä»¬ä»¥æ¯æœ¬2ç¾å…ƒçš„ä»·æ ¼å–å‡º120æœ¬å„¿ç«¥ä¹¦ï¼Œä»¥æ¯æœ¬3ç¾å…ƒçš„ä»·æ ¼å–å‡º75æœ¬å°è¯´ï¼Œå¹¶ä»¥æ¯æœ¬1.50ç¾å…ƒçš„ä»·æ ¼å–å‡ºäº†å°è¯´ä¸¤å€æ•°é‡çš„æ‚å¿—ã€‚ä»–ä»¬è¿˜ä»¥æ¯æœ¬0.50ç¾å…ƒçš„ä»·æ ¼å–å‡ºä¸ä¹¦ç±å’Œæ‚å¿—æ€»æ•°ç›¸ç­‰çš„ä¹¦ç­¾ã€‚é‚£ä¹ˆå›¾ä¹¦é¦†æ€»å…±ç­¹é›†äº†å¤šå°‘é’±ï¼Ÿ',\n",
    " 'ä¸€ä¸ªå½“åœ°çš„å†œæ°‘æ­£åœ¨ä¸ºå¸‚åœºå‡†å¤‡æ··åˆæ°´æœç¯®ï¼Œæ¯ä¸ªç¯®å­åŒ…å«3ä¸ªè‹¹æœã€5ä¸ªæ©™å­å’Œ2ä¸ªé¦™è•‰ã€‚è‹¹æœçš„ä»·æ ¼æ˜¯æ¯ä¸ª0.50ç¾å…ƒï¼Œæ©™å­æ¯ä¸ª0.30ç¾å…ƒï¼Œé¦™è•‰æ¯ä¸ª0.25ç¾å…ƒã€‚å¦‚æœå†œæ°‘ä¸ºå½“åœ°å¸‚åœºå‡†å¤‡äº†120ä¸ªç¯®å­ï¼Œå¹¶ä»¥æ¯ä¸ª5.00ç¾å…ƒçš„ä»·æ ¼å‡ºå”®æ¯ä¸ªç¯®å­ï¼Œé‚£ä¹ˆå–å®Œæ‰€æœ‰ç¯®å­åï¼Œå†œæ°‘å°†è·å¾—å¤šå°‘åˆ©æ¶¦ï¼Ÿ',\n",
    " 'ç›ä¸½äºšæœ‰24ä¸ªè‹¹æœï¼Œæƒ³å°†å®ƒä»¬å‡åŒ€åˆ†ç»™å¥¹çš„6ä¸ªæœ‹å‹ã€‚å¦‚æœæ¯ä¸ªæœ‹å‹è¿˜è¦å†ç»™è€å¸ˆ2ä¸ªè‹¹æœï¼Œé‚£ä¹ˆæ¯ä¸ªæœ‹å‹å‰©ä¸‹å¤šå°‘è‹¹æœï¼Ÿ',\n",
    " 'è‰æ‹‰æ­£åœ¨è®¡åˆ’ä¸€ä¸ªèŠ±å›­ï¼Œæƒ³è¦ç§ä¸‰ç§èŠ±ï¼šé›èŠã€éƒé‡‘é¦™å’Œç«ç‘°ã€‚å¥¹æƒ³è¦çš„é›èŠæ•°é‡æ˜¯éƒé‡‘é¦™çš„ä¸¤å€ï¼Œéƒé‡‘é¦™çš„æ•°é‡æ˜¯ç«ç‘°çš„ä¸‰å€ã€‚å¦‚æœå¥¹æ€»å…±è¦ç§60æœµèŠ±ï¼Œé‚£ä¹ˆå¥¹è®¡åˆ’ç§å¤šå°‘æœµç«ç‘°ï¼Ÿ',\n",
    " 'ä¸€ä¸ªèŠ±å›­æœ‰ä¸‰ç§å¼€èŠ±æ¤ç‰©ã€‚ç¬¬ä¸€ç§æ¯æ ªæœ‰12æœµèŠ±ï¼Œç¬¬äºŒç§æ¯æ ªæœ‰8æœµèŠ±ï¼Œç¬¬ä¸‰ç§æ¯æ ªæœ‰15æœµèŠ±ã€‚å¦‚æœç¬¬ä¸€ç§æ¤ç‰©çš„æ•°é‡æ˜¯ç¬¬äºŒç§æ¤ç‰©çš„ä¸¤å€ï¼Œç¬¬ä¸‰ç§æ¤ç‰©çš„æ•°é‡æ˜¯ç¬¬ä¸€ç§æ¤ç‰©çš„ä¸€åŠï¼Œå¹¶ä¸”èŠ±å›­ä¸­æœ‰16æ ªç¬¬äºŒç§æ¤ç‰©ï¼Œé‚£ä¹ˆèŠ±å›­é‡Œä¸€å…±æœ‰å¤šå°‘æœµèŠ±ï¼Ÿ',\n",
    " 'åœ¨ä¸€ä¸ªæ£‹ç›˜æ¸¸æˆä¸­ï¼Œä»ä¸€ä¸ªæ–¹æ ¼è½¬ç§»åˆ°å¦ä¸€ä¸ªæ–¹æ ¼çš„è´¹ç”¨æ˜¯ä½ è¦è½åœ¨çš„æ–¹æ ¼å·ç çš„ç¡¬å¸æ•°ã€‚ç¬¬ä¸€ä¸ªæ–¹æ ¼æ˜¯1å·ï¼Œç¬¬äºŒä¸ªæ–¹æ ¼æ˜¯2å·ï¼Œä»¥æ­¤ç±»æ¨ã€‚å¦‚æœä¸€ä¸ªç©å®¶ä»5å·æ–¹æ ¼ç§»åŠ¨åˆ°9å·æ–¹æ ¼ï¼Œå†åˆ°14å·æ–¹æ ¼ï¼Œæœ€ååˆ°20å·æ–¹æ ¼ï¼Œä»–æ€»å…±èŠ±è´¹äº†å¤šå°‘æšç¡¬å¸ï¼Ÿ',\n",
    " 'ä¸€ä¸ªæ™¯è§‚å…¬å¸åœ¨ä¸¤ä¸ªå…¬å›­ç§æ¤æ ‘æœ¨ã€‚åœ¨Aå…¬å›­ï¼Œä»–ä»¬ç§äº†5æ’ï¼Œæ¯æ’6æ£µæ ‘ã€‚åœ¨Bå…¬å›­ï¼Œä»–ä»¬ç§äº†3æ’ï¼Œæ¯æ’7æ£µæ ‘ã€‚ç„¶è€Œï¼ŒBå…¬å›­çš„4æ£µæ ‘æ²¡æœ‰æˆæ´»ï¼Œå¿…é¡»ç§»é™¤ã€‚ç§»é™¤ä¹‹åï¼Œæ€»å…±å‰©ä¸‹å¤šå°‘æ£µæ ‘ï¼Ÿ',\n",
    " 'æ¬§æ‹‰åšå£«æ­£åœ¨è®¡åˆ’ä¸€åœºæ•°å­¦æ¯”èµ›ï¼Œä»–å†³å®šå°†å‚ä¸è€…åˆ†æˆå‡ ç»„ã€‚ä¸ºäº†ä¿è¯å…¬å¹³ï¼Œæ¯ç»„å¿…é¡»æœ‰ç›¸åŒæ•°é‡çš„å‚ä¸è€…ã€‚å¦‚æœæ¬§æ‹‰åšå£«å¯ä»¥é€‰æ‹©å°†å‚ä¸è€…åˆ†æˆ4äººã€5äººæˆ–6äººçš„ç»„ï¼Œå¹¶ä¸”å‚ä¸è€…æ€»æ•°å°‘äº100äººï¼Œé‚£ä¹ˆä»–æœ€å¤šå¯ä»¥æœ‰å¤šå°‘å‚ä¸è€…ï¼Œç¡®ä¿æ— è®ºæ€ä¹ˆåˆ†ç»„éƒ½ä¸ä¼šæœ‰å‰©ä½™ï¼Ÿ',\n",
    " 'ä¸€ä¸ªå†œæ°‘ä¸ºä¸‡åœ£èŠ‚ç§æ¤å—ç“œã€‚ä»–ç§äº†8æ’ï¼Œæ¯æ’15æ£µå—ç“œæ¤æ ªã€‚æ¯æ£µæ¤æ ªå¹³å‡äº§å‡º3ä¸ªå—ç“œã€‚æ”¶è·åï¼Œå†œæ°‘å°†20%çš„å—ç“œå–ç»™å½“åœ°å¸‚åœºï¼Œå‰©ä¸‹çš„åœ¨ä»–çš„å†œåœºæ‘Šä½ä¸Šå‡ºå”®ã€‚å¦‚æœæ¯ä¸ªå—ç“œå–4ç¾å…ƒï¼Œå†œæ°‘é€šè¿‡é”€å”®å—ç“œæ€»å…±èµšäº†å¤šå°‘é’±ï¼Ÿ',\n",
    " 'ä¸€ä¸ªä¸‰è§’å½¢å…¬å›­ABCçš„è¾¹ç¼˜ä¸Šç§æ¤äº†æ ‘æœ¨ã€‚è¾¹ABä¸Šçš„æ ‘æœ¨æ•°é‡ç­‰äºè¾¹BCçš„é•¿åº¦ï¼Œè¾¹BCä¸Šçš„æ ‘æœ¨æ•°é‡ç­‰äºè¾¹CAçš„é•¿åº¦ï¼Œè¾¹CAä¸Šçš„æ ‘æœ¨æ•°é‡ç­‰äºè¾¹ABçš„é•¿åº¦ã€‚å¦‚æœè¾¹ABã€BCå’ŒCAï¼ˆä»¥ç±³ä¸ºå•ä½ï¼‰çš„é•¿åº¦æ„æˆä¸€ä¸ªå…¬æ¯”ä¸º2çš„å‡ ä½•çº§æ•°ï¼Œå¹¶ä¸”æ€»å…±ç§æ¤äº†77æ£µæ ‘ï¼Œæ±‚è¾¹ABçš„é•¿åº¦ã€‚',\n",
    " 'ä¸€ç¾¤æœ‹å‹æ­£åœ¨æ”¶é›†å¯å›æ”¶çš„ç½å­ã€‚ç›é›…æ”¶é›†çš„ç½å­æ˜¯åˆ©äºšå§†çš„ä¸¤å€ã€‚åˆ©äºšå§†æ”¶é›†äº†15ä¸ªç½å­ã€‚å¦‚æœä½ä¼Šæ¯”ç›é›…å¤šæ”¶é›†äº†5ä¸ªç½å­ï¼Œå¹¶ä¸”è¿™ç¾¤æœ‹å‹æƒ³æŠŠç½å­å¹³åˆ†ç»™4å®¶æ…ˆå–„æœºæ„ï¼Œæ¯å®¶ä¼šæ”¶åˆ°å¤šå°‘ä¸ªç½å­ï¼Ÿ',\n",
    " 'åœ¨ä¸€åœºç§‘å­¦æ¯”èµ›ä¸­ï¼Œæ¯ä¸ªå›¢é˜Ÿéœ€è¦åˆ¶ä½œä¸€ä¸ªæ¨¡å‹ç«ç®­ã€‚æœ‰6ä¸ªå›¢é˜Ÿï¼Œæ¯ä¸ªå›¢é˜Ÿéœ€è¦ä¸€å¥—ææ–™ã€‚ææ–™åŒ…æ‹¬ç«ç®­çš„ä¸»ä½“ç®¡ã€å¼•æ“å’Œé™è½ä¼ã€‚ä¸»ä½“ç®¡æ¯ä¸ª12.50ç¾å…ƒï¼Œå¼•æ“æ¯ä¸ª18.75ç¾å…ƒï¼Œé™è½ä¼æ¯ä¸ª6.25ç¾å…ƒã€‚è´­ä¹°æ‰€æœ‰å›¢é˜Ÿçš„ææ–™åï¼Œæ€»è´¹ç”¨ä¸º225ç¾å…ƒã€‚åˆ¶ä½œä¸€æ”¯ç«ç®­çš„ææ–™è´¹ç”¨æ˜¯å¤šå°‘ï¼Ÿ',\n",
    " 'è‰¾ç±³ä¸½æœ‰ä¸€ä¸ªå°èœå›­ï¼Œç§æ¤äº†ç•ªèŒ„ã€èƒ¡èåœå’Œé»„ç“œã€‚å¥¹çš„ç•ªèŒ„æ¤æ ªæ•°é‡æ˜¯é»„ç“œæ¤æ ªçš„ä¸¤å€ï¼Œè€Œèƒ¡èåœæ¤æ ªæ¯”ç•ªèŒ„å°‘5æ£µã€‚å¦‚æœè‰¾ç±³ä¸½æœ‰4æ£µé»„ç“œæ¤æ ªï¼Œé‚£ä¹ˆå¥¹æ€»å…±æœ‰å¤šå°‘æ£µèœå›­æ¤ç‰©ï¼Ÿ',\n",
    " 'åœ¨ä¸€ä¸ªå°æ‘åº„ï¼Œå½“åœ°è£ç¼åˆ¶ä½œå¤–å¥—å’Œè£¤å­ã€‚åˆ¶ä½œä¸€ä»¶å¤–å¥—éœ€è¦3ç å¸ƒæ–™ï¼Œè€Œåˆ¶ä½œä¸€æ¡è£¤å­éœ€è¦2ç å¸ƒæ–™ã€‚ä»–æ¥åˆ°äº†ä¸€ä»½å‰§é™¢åˆ¶ä½œçš„è®¢å•ï¼Œè¦æ±‚çš„è£¤å­æ•°é‡æ˜¯å¤–å¥—çš„ä¸¤å€ï¼Œè€Œå‰§é™¢è¦æ±‚äº†4ä»¶å¤–å¥—ã€‚å¦‚æœå¸ƒæ–™çš„ä»·æ ¼æ˜¯æ¯ç 15ç¾å…ƒï¼Œé‚£ä¹ˆå‰§é™¢åœ¨è¿™ä¸ªè®¢å•ä¸Šéœ€è¦èŠ±è´¹å¤šå°‘å¸ƒæ–™è´¹ç”¨ï¼Ÿ',\n",
    " 'ä¸€ä¸ªå°é•‡çš„äººå£ä»¥æ’å®šçš„é€Ÿç‡å¢é•¿ã€‚å¦‚æœ2010å¹´å°é•‡çš„äººå£æ˜¯5000äººï¼Œ2020å¹´æ˜¯8000äººï¼Œé‚£ä¹ˆå¦‚æœè¿™ç§å¢é•¿è¶‹åŠ¿ç»§ç»­ï¼Œåˆ°2025å¹´å°é•‡çš„äººå£ä¼šæ˜¯å¤šå°‘ï¼Ÿ',\n",
    " 'ä¸€ä½æ•°å­¦è€å¸ˆæ­£åœ¨ç»„ç»‡ä¸€åœºæµ‹éªŒæ¯”èµ›ï¼Œå¹¶å†³å®šç”¨é“…ç¬”ä½œä¸ºå¥–å“ã€‚æ¯ä½å‚ä¸è€…å°†è·å¾—2æ”¯é“…ç¬”ï¼Œè€Œå¾—åˆ†è¶…è¿‡80%çš„å­¦ç”Ÿå°†é¢å¤–è·å¾—3æ”¯é“…ç¬”ã€‚å¦‚æœç­ä¸Šæœ‰30åå­¦ç”Ÿï¼Œå…¶ä¸­1/5çš„å­¦ç”Ÿå¾—åˆ†è¶…è¿‡80%ï¼Œé‚£ä¹ˆè€å¸ˆéœ€è¦å‡†å¤‡å¤šå°‘æ”¯é“…ç¬”ï¼Ÿ',\n",
    " 'ä¸€ä¸ªé•¿æ–¹å½¢çš„èŠ±å›­è¢«120ç±³çš„å›´æ åŒ…å›´ã€‚å¦‚æœèŠ±å›­çš„é•¿åº¦æ˜¯å…¶å®½åº¦çš„ä¸‰å€ï¼Œé‚£ä¹ˆèŠ±å›­çš„é¢ç§¯æ˜¯å¤šå°‘å¹³æ–¹ç±³ï¼Ÿ',\n",
    " 'ä¸€ä¸ªé•¿10ç±³ã€å®½15ç±³çš„èŠ±å›­å°†ç”¨æ–¹å½¢ç“·ç –é“ºè®¾ã€‚æ¯å—ç“·ç –çš„è¾¹é•¿ä¸º25å˜ç±³ã€‚å¦‚æœæ¯å—ç“·ç –çš„ä»·æ ¼æ˜¯3ç¾å…ƒï¼Œè€Œé“ºè®¾ç“·ç –çš„äººå·¥è´¹ç”¨æ˜¯æ¯å¹³æ–¹ç±³8ç¾å…ƒï¼Œé‚£ä¹ˆé“ºè®¾æ•´ä¸ªèŠ±å›­çš„æ€»è´¹ç”¨æ˜¯å¤šå°‘ï¼Ÿ']\n",
    "answers = [228,15,132,0.45,24,7.3205,16,720,30,2,13,14,862.5,180,2,6,752,43,47,60,1440,11,20,37.5,15,420,9500,78,675,8400]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf521c3e-a275-4634-b91b-dc6f7975ffbd",
   "metadata": {},
   "source": [
    "## ğŸ§™ åˆ›å»ºä½ çš„è‡ªå®šä¹‰ Promptï¼ˆGradio ç‰ˆæœ¬ï¼‰\n",
    "\n",
    "æ­¤æ¨¡å—åˆ›å»ºäº†ä¸€ä¸ª Gradio ç•Œé¢ï¼Œä½¿ä½ èƒ½å¤Ÿåœ¨ Gradio ä¸­è®¾ç½®ã€è¯„ä¼°å’Œä¿å­˜è‡ªå®šä¹‰æç¤ºè¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8c38c-def5-487b-b32c-388772a3dbbe",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨æ‰‹å†Œ\n",
    "\n",
    "0. **ç¡®ä¿ API å¯†é’¥è®¾ç½®æ­£ç¡®ï¼Œå¦åˆ™å¯èƒ½ä¼šå¾—åˆ°æ„å¤–ç»“æœï¼ˆå¯èƒ½ä¼šå‡ºç°é”™è¯¯ï¼‰ã€‚**\n",
    "1. **åœ¨ `Prompt` ä¸­ç¼–è¾‘ä½ çš„è‡ªå®šä¹‰æç¤ºè¯ï¼š**\n",
    "   - åœ¨ä½ çš„æç¤ºè¯ä¸­åŒ…å« `{{question}}`ï¼Œä¸è¦è¿›è¡Œä»»ä½•æ›´æ”¹ã€‚æ­¤å ä½ç¬¦å°†è¢«æä¾›çš„ç¤ºä¾‹ä¸­é€‰æ‹©çš„ä¸€ä¸ªé—®é¢˜æ›¿æ¢ã€‚\n",
    "     ![å ä½ç¬¦](../assets/%E5%8D%A0%E4%BD%8D%E7%AC%A6-6055722.png)\n",
    "   - æœ€å¤§é•¿åº¦ï¼š1024 ä¸ª tokenã€‚\n",
    "\n",
    "2. **è®¾ç½®ä½ çš„è‡ªå®šä¹‰æç¤ºè¯ï¼š**\n",
    "   - ç‚¹å‡» `Set Prompt` å°† `Prompt` ä¸­çš„å†…å®¹åº”ç”¨ä¸ºä½ çš„è‡ªå®šä¹‰æç¤ºè¯ã€‚ä½¿ç”¨ `Clear Prompt` æ¸…é™¤å·²è¾“å…¥çš„ä»»ä½•è‡ªå®šä¹‰æç¤ºè¯ã€‚\n",
    "   - è®¾ç½®æç¤ºè¯åï¼Œä½ å¯ä»¥åœ¨ `Log` ä¸­æŸ¥çœ‹ã€‚\n",
    "\n",
    "3. **è¯„ä¼°ä½ çš„è‡ªå®šä¹‰æç¤ºè¯ï¼š**\n",
    "   - ç‚¹å‡» `Evaluate` ä½¿ç”¨ `OpenAI` è¯„ä¼°ä½ çš„è‡ªå®šä¹‰æç¤ºè¯ï¼Œè¯„ä¼°å°†ä½¿ç”¨å‰ `Number of examples used for evaluation` ä¸ªé—®é¢˜ã€‚\n",
    "   - æ¯ä¸ªé—®é¢˜å°†è¿›è¡Œä¸‰æ¬¡è¯„ä¼°ã€‚\n",
    "   - è¯„ä¼°æ‰€æœ‰é—®é¢˜å¯èƒ½éœ€è¦ **20 åˆ° 30 åˆ†é’Ÿ**ï¼Œå…·ä½“æ—¶é—´å–å†³äºæç¤ºè¯çš„é•¿åº¦ã€‚\n",
    "\n",
    "4. **æŸ¥çœ‹ç»“æœï¼š**\n",
    "   - æœ¯è¯­è§£é‡Šï¼š\n",
    "     - `Trial Number`ï¼šèŒƒå›´ä¸º `1âˆ¼3`ï¼Œæ¯ä¸ªé—®é¢˜è¿›è¡Œä¸‰æ¬¡è¯„ä¼°ï¼Œå¹¶æŠ•ç¥¨ç¡®å®šæœ€ç»ˆç»“æœã€‚\n",
    "     - `Question Number`ï¼šèŒƒå›´ä¸º `1âˆ¼n`ï¼ŒæŒ‡è¯„ä¼°æ‰€ä½¿ç”¨çš„å‰ `n` ä¸ªé—®é¢˜ã€‚\n",
    "\n",
    "   - ä½ å¯ä»¥è°ƒæ•´æ»‘å—æŸ¥çœ‹å…·ä½“çš„ç»“æœã€‚\n",
    "   - å»ºè®®é€æ¬¡ç‚¹å‡»è°ƒæ•´æ»‘å—ï¼Œå› ä¸º Gradio ç•Œé¢å“åº”é€Ÿåº¦è¾ƒæ…¢ã€‚å¦‚æœä½ æƒ³å¿«é€Ÿè·³è½¬åˆ°æŸä¸ªæ•°å­—ï¼Œå¯ä»¥ç›´æ¥åœ¨æ•°å€¼è¾“å…¥æ¡†ä¸­è¾“å…¥ï¼Œä»¥ç¡®ä¿å¾—åˆ°æ‰€éœ€ç»“æœã€‚\n",
    "   - æ€»ä½“åˆ†æ•°æ˜¾ç¤ºåœ¨ `Result Stats` ä¸­ã€‚\n",
    "\n",
    "5. **ä¿å­˜ä½ çš„è‡ªå®šä¹‰æç¤ºè¯ï¼š**\n",
    "   - ç‚¹å‡» `Save Custom Prompt` å°†ç»“æœä¿å­˜ä¸º json æ–‡ä»¶ã€‚\n",
    "\n",
    "6. **åœ¨ `Log` ä¸­æŸ¥çœ‹è¿‡ç¨‹ï¼š**\n",
    "   - æ‰€æœ‰æ“ä½œéƒ½ä¼šè®°å½•åœ¨ `Log` ä¸­ã€‚å¯ä»¥å‚è€ƒå®ƒæ¥äº†è§£è¿‡ç¨‹æˆ–é‡å¤å®éªŒï¼Œä¸è¿‡éœ€è¦æ³¨æ„æŸäº›æ“ä½œå¯èƒ½ä¼šå¼•å…¥éšæœºæ€§ã€‚\n",
    "\n",
    "**æ³¨æ„äº‹é¡¹**\n",
    "\n",
    "- åœ¨æ–‡æœ¬æ¡†ä¸­æ’å…¥æ¢è¡Œï¼Œè¯·ä½¿ç”¨ `Shift+Enter`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341e7c0-4be0-46d2-8214-d83015e06c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨gradioè¿›è¡Œè‡ªå®šä¹‰promptæ“ä½œ\n",
    "import gradio as gr\n",
    "\n",
    "# ResetæŒ‰é’®ç‚¹å‡»äº‹ä»¶\n",
    "def reset(chatbot):\n",
    "    '''\n",
    "    `Reset` æŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šé‡ç½®prompt\n",
    "    '''\n",
    "    gr.Info(\"å·²æ¸…é™¤æç¤ºè¯\")\n",
    "    chatbot.extend([[\"æ¸…é™¤æç¤ºè¯\", \"æç¤ºè¯å·²æˆåŠŸé‡ç½®\"]])\n",
    "    return chatbot, \"\", 0\n",
    "\n",
    "# AssignæŒ‰é’®ç‚¹å‡»äº‹ä»¶\n",
    "def assign(chatbot, prompt, template, Example_Number):\n",
    "    '''\n",
    "    `Assign` æŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šåˆ†é…æœ‰æ•ˆpromptå¹¶è®¾ç½®`template`\n",
    "    '''\n",
    "    gr.Info(\"æ­£åœ¨åˆ†é…æç¤ºè¯\")\n",
    "    Example_Number = int(Example_Number)\n",
    "    token_num = my_model.prompt_token_num(prompt)\n",
    "    if token_num > 1024:\n",
    "        template = None\n",
    "        gr.Warning(\"æ— æ•ˆçš„æç¤ºè¯ï¼ˆå¤ªé•¿ï¼Œè¶…è¿‡1024ä¸ªtokenï¼‰\")\n",
    "        chatbot.append([None, \"æç¤ºè¯å¤ªé•¿ï¼ˆè¶…è¿‡1024ä¸ªtokenï¼‰ã€‚è¾ƒçŸ­çš„æç¤ºè¯å¯ä»¥æ›´å¿«ä¸”æ›´ç¨³å®šåœ°è¯„ä¼°ï¼\"])\n",
    "    elif Example_Number < 1 or Example_Number > len(questions):\n",
    "        template = None\n",
    "        prompt_ex = f\"é”™è¯¯ï¼šè¯·é€‰æ‹©ä¸€ä¸ª1åˆ°{len(questions)}ä¹‹é—´çš„æ•°å­—\"\n",
    "        gr.Warning(prompt_ex)\n",
    "        chatbot.extend([[None, prompt_ex]])\n",
    "    elif \"{{question}}\" not in prompt:\n",
    "        template = None\n",
    "        prompt_ex = \"ä½ éœ€è¦åœ¨æç¤ºè¯ä¸­åŒ…å«å ä½ç¬¦{{question}}ã€‚\"\n",
    "        gr.Warning(prompt_ex)\n",
    "        chatbot.extend([[None, prompt_ex]])\n",
    "    else:\n",
    "        environment = jinja2.Environment()\n",
    "        template = environment.from_string(prompt)\n",
    "        prompt_ex = f\"\"\"{template.render(question=questions[Example_Number - 1])}\"\"\"\n",
    "        chatbot.extend([[\"åˆ†é…æç¤ºè¯\", \"æç¤ºè¯å·²æˆåŠŸåˆ†é…\\n\\nè‡ªå®šä¹‰æç¤ºè¯ç¤ºä¾‹ï¼š\"], [None, prompt_ex]])\n",
    "    return chatbot, prompt, template, Example_Number, token_num\n",
    "\n",
    "# å¤„ç†æ•°å­—ä¸­çš„é€—å·ï¼ˆåƒä½åˆ†éš”ç¬¦ï¼‰\n",
    "def clean_commas(text):\n",
    "    def process_match(match):\n",
    "        number = match.group(0)\n",
    "        if '.' in number:\n",
    "            return number\n",
    "        else:\n",
    "            number_list = number.split(\",\")\n",
    "            new_string = number_list[0]\n",
    "            for i in range(1, len(number_list)):\n",
    "                if len(number_list[i]) == 3:\n",
    "                    new_string += number_list[i]\n",
    "                else:\n",
    "                    new_string += f\",{number_list[i]}\"\n",
    "            return new_string\n",
    "    pattern = r'\\d+(?:,\\d+)*(?:\\.\\d+)?'\n",
    "    return re.sub(pattern, process_match, text)\n",
    "\n",
    "# æ£€æŸ¥è¾“å…¥ä¸­çš„æ•°å­—æ˜¯å¦ä¸é¢„æœŸåŒ¹é…\n",
    "def find_and_match_floats(input_string, ground_truth):\n",
    "    pattern = re.compile(r\"[-+]?\\d*\\.\\d+|[-+]?\\d+\")\n",
    "    found_numbers = pattern.findall(input_string)\n",
    "    found_floats = [float(num) for num in found_numbers]\n",
    "    return ground_truth in found_floats\n",
    "\n",
    "# è¯„ä¼°æŒ‰é’®ç‚¹å‡»äº‹ä»¶\n",
    "def assess(chatbot, template, test_num):\n",
    "    '''\n",
    "    `Test` æŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šè¯„ä¼°è‡ªå®šä¹‰prompt\n",
    "    '''\n",
    "    if template is None:\n",
    "        chatbot.extend([[None, \"è¯„ä¼°å¤±è´¥ï¼Œå› ä¸ºæç¤ºè¯æ¨¡æ¿ä¸ºç©ºï¼ˆå³æ— æ•ˆçš„æç¤ºè¯ï¼‰\"]])\n",
    "        gr.Warning(\"æç¤ºè¯æœªè®¾ç½®\")\n",
    "        return chatbot, [], \"æç¤ºè¯æœªè®¾ç½®\", gr.Slider(label=\"Result Number\", value=0, minimum=0, maximum=0, step=1), gr.Textbox(label=\"Result\", value=\"\", interactive=False)\n",
    "\n",
    "    gr.Info(\"æ­£åœ¨è¯„ä¼°æç¤ºè¯\")\n",
    "    ans_template = \"æç¤ºè¯å’Œé—®é¢˜ï¼š\\n\\n{{question}}\\n\\n--------------------\\n\\nè§£é¢˜è¿‡ç¨‹ï¼š\\n\\n{{rationale}}\\n\\n--------------------\\n\\næœ€ç»ˆç­”æ¡ˆ\\n\\n{{answer}}\"\n",
    "    res_list = []\n",
    "    total_count = test_num\n",
    "    environment = jinja2.Environment()\n",
    "    ans_template = environment.from_string(ans_template)\n",
    "    trial_num = 3\n",
    "    trials = [[] for _ in range(trial_num)]\n",
    "    res_stats_str = \"\"\n",
    "\n",
    "    for i in range(trial_num):\n",
    "        gr.Info(f\"å¼€å§‹ç¬¬{i+1}æ¬¡æµ‹è¯•\")\n",
    "        accurate_count = 0\n",
    "        for idx, example in enumerate(questions[:test_num]):\n",
    "            test_res = \"\"\n",
    "            result = my_model.two_stage_completion(example, template.render(question=example))\n",
    "\n",
    "            if not result[\"answer\"]:\n",
    "                trials[i].append(0)\n",
    "                test_res += f\"ç¬¬{i+1}æ¬¡æµ‹è¯•\\n\\nè·³è¿‡é—®é¢˜ {idx + 1}ã€‚\"\n",
    "                test_res += \"\\n\" + \"<\"*6 + \"=\"*30 + \">\"*6 + \"\\n\\n\"\n",
    "                res_list.append(f\"ç¬¬{i+1}æ¬¡æµ‹è¯•\\n\\nè·³è¿‡é—®é¢˜ {idx + 1}ã€‚\")\n",
    "                continue\n",
    "\n",
    "            cleaned_result = clean_commas(result[\"answer\"])\n",
    "            if find_and_match_floats(cleaned_result, answers[idx]):\n",
    "                accurate_count += 1\n",
    "                trials[i].append(1)\n",
    "            else:\n",
    "                trials[i].append(0)\n",
    "\n",
    "            my_model.save_cache()\n",
    "            test_res += f\"ç¬¬{i + 1}æ¬¡æµ‹è¯•\\n\\n\"\n",
    "            test_res += f\"é—®é¢˜ {idx + 1}:\\n\" + '-'*20\n",
    "            test_res += f'''\\n\\n{ans_template.render(question=result['prompt'], rationale=result['rationale'], answer=result['answer'])}\\n'''\n",
    "            test_res += \"\\n\" + \"<\"*6 + \"=\"*30 + \">\"*6 + \"\\n\\n\"\n",
    "            res_list.append(test_res)\n",
    "\n",
    "        res_stats_str += f\"ç¬¬{i + 1}æ¬¡æµ‹è¯•ï¼Œæ­£ç¡®æ•°ï¼š{accurate_count}ï¼Œæ€»æ•°ï¼š{total_count}ï¼Œå‡†ç¡®ç‡ï¼š{accurate_count / total_count * 100}%\\n\"\n",
    "        my_model.save_cache()\n",
    "\n",
    "    voting_acc = 0\n",
    "    for i in range(total_count):\n",
    "        count = 0\n",
    "        for j in range(trial_num):\n",
    "            if trials[j][i] == 1:\n",
    "                count += 1\n",
    "        if count >= 2:\n",
    "            voting_acc += 1\n",
    "\n",
    "    res_stats_str += f\"æœ€ç»ˆå‡†ç¡®ç‡ï¼š{voting_acc / total_count * 100}%\"\n",
    "    chatbot.extend([[\"æµ‹è¯•\", \"æµ‹è¯•å®Œæˆã€‚ç»“æœå¯ä»¥åœ¨â€œç»“æœâ€å’Œâ€œç»“æœç»Ÿè®¡â€ä¸­æ‰¾åˆ°ã€‚\"]])\n",
    "    chatbot.extend([[None, \"æµ‹è¯•ç»“æœ\"], [None, ''.join(res_list)], [None, \"ç»“æœç»Ÿè®¡\"], [None, res_stats_str]])\n",
    "    return chatbot, res_list, res_stats_str, gr.Slider(label=\"Result Number\", value=1, minimum=1, maximum=len(res_list), step=1, visible=False), gr.Textbox(label=\"Result\", value=res_list[0], interactive=False)\n",
    "\n",
    "# ä¿å­˜prompt\n",
    "def save_prompt(chatbot, prompt):\n",
    "    '''\n",
    "    `Save` æŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šä¿å­˜æç¤ºè¯\n",
    "    '''\n",
    "    gr.Info(\"æ­£åœ¨ä¿å­˜æç¤ºè¯\")\n",
    "    prompt_dict = {\n",
    "        'prompt': prompt\n",
    "    }\n",
    "    with open('prompt.json', 'w') as f:\n",
    "        json.dump(prompt_dict, f)\n",
    "    chatbot.extend([[\"ä¿å­˜æç¤ºè¯\", f\"æç¤ºè¯å·²ä¿å­˜ä¸ºprompt.json\"]])\n",
    "    return chatbot\n",
    "\n",
    "# Gradioç•Œé¢\n",
    "with gr.Blocks() as demo:\n",
    "    my_magic_prompt = \"ä»»åŠ¡ï¼š\\nè§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ã€‚\\n\\né—®é¢˜ï¼š{{question}}\\n\\nç­”æ¡ˆï¼š\"\n",
    "    my_magic_prompt = my_magic_prompt.strip('\\n')\n",
    "    template = gr.State(None)\n",
    "    res_list = gr.State(list())\n",
    "\n",
    "    # ç»„ä»¶\n",
    "    with gr.Tab(label=\"Console\"):\n",
    "        with gr.Group():\n",
    "            example_num_box = gr.Dropdown(label=\"Demo Example (Please choose one example for demo)\", value=1, info=questions[0], choices=[i+1 for i in range(len(questions))], filterable=False)\n",
    "            prompt_textbox = gr.Textbox(label=\"Custom Prompt\", placeholder=f\"åœ¨è¿™é‡Œè¾“å…¥ä½ çš„è‡ªå®šä¹‰æç¤ºè¯ã€‚ä¾‹å¦‚ï¼š\\n\\n{my_magic_prompt}\", value=\"\", info=\"è¯·ç¡®ä¿åŒ…å«`{{question}}`æ ‡ç­¾ã€‚\")\n",
    "            with gr.Row():\n",
    "                set_button = gr.Button(value=\"Set Prompt\")\n",
    "                reset_button = gr.Button(value=\"Clear Prompt\")\n",
    "            prompt_token_num = gr.Textbox(label=\"Number of prompt tokens\", value=0, interactive=False, info=\"è‡ªå®šä¹‰æç¤ºè¯çš„Tokenæ•°é‡ã€‚\")\n",
    "        with gr.Group():\n",
    "            test_num = gr.Slider(label=\"Number of examples used for evaluation\", minimum=1, maximum=len(questions), step=1, value=1)\n",
    "            assess_button = gr.Button(value=\"Evaluate\")\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    with gr.Row():\n",
    "                        trial_no = gr.Slider(label=\"Trial ID\", value=1, minimum=1, maximum=3, step=1)\n",
    "                        ques_no = gr.Slider(label=\"Question ID\", value=1, minimum=1, maximum=1, step=1)\n",
    "                    res_num = gr.Slider(label=\"Result Number\", value=0, minimum=0, maximum=0, step=1, visible=False)\n",
    "                    res = gr.Textbox(label=\"Result\", value=\"\", placeholder=\"æš‚æ— ç»“æœ\", interactive=False)\n",
    "                with gr.Column():\n",
    "                    res_stats = gr.Textbox(label=\"Result Stats\", interactive=False)\n",
    "            save_button = gr.Button(value=\"Save Custom Prompt\")\n",
    "    with gr.Tab(label=\"Log\"):\n",
    "        chatbot = gr.Chatbot(label=\"Log\")\n",
    "\n",
    "    # äº‹ä»¶å¤„ç†\n",
    "    example_num_box.input(lambda Example_Number: gr.Dropdown(label=\"Example (Please choose one example for demo)\", value=Example_Number, info=questions[Example_Number - 1], choices=[i+1 for i in range(len(questions))]),\n",
    "                inputs=[example_num_box],\n",
    "                outputs=[example_num_box])\n",
    "    res_num.change(lambda results, result_num, test_num: (gr.Textbox(label=\"Result\", value=results[result_num-1], interactive=False) if len(results) != 0 else gr.Textbox(label=\"Result\", value=\"\", placeholder=\"æš‚æ— ç»“æœ\", interactive=False),\n",
    "                                    (int)((result_num-1)/test_num)+1,\n",
    "                                    gr.Slider(label=\"Question Number\", minimum=1, maximum=test_num, value=(result_num-1)%test_num+1, step=1)),\n",
    "            inputs=[res_list, res_num, test_num],\n",
    "            outputs=[res, trial_no, ques_no])\n",
    "    trial_ques_no_input = lambda t_val, q_val, test_num: (t_val - 1) * test_num + q_val\n",
    "    trial_no.input(trial_ques_no_input, inputs=[trial_no, ques_no, test_num], outputs=[res_num])\n",
    "    ques_no.input(trial_ques_no_input, inputs=[trial_no, ques_no, test_num], outputs=[res_num])\n",
    "    set_button.click(assign, inputs=[chatbot, prompt_textbox, template, example_num_box], outputs=[chatbot, prompt_textbox, template, example_num_box, prompt_token_num])\n",
    "    reset_button.click(reset, inputs=[chatbot], outputs=[chatbot, prompt_textbox, prompt_token_num])\n",
    "    assess_button.click(assess, inputs=[chatbot, template, test_num], outputs=[chatbot, res_list, res_stats, res_num, res])\n",
    "    save_button.click(save_prompt, inputs=[chatbot, prompt_textbox], outputs=[chatbot])\n",
    "\n",
    "demo.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31368452-8c54-4627-aae3-4c55e3fecb08",
   "metadata": {},
   "source": [
    "## ğŸ§™ åˆ›å»ºä½ çš„è‡ªå®šä¹‰ Promptï¼ˆé Gradio ç‰ˆæœ¬ï¼‰\n",
    "\n",
    "è¿™ä¸ªç‰ˆæœ¬å°†ä¸æ¶‰åŠ Gradioï¼Œä½¿ç”¨ ipywidgets æ¥åˆ›å»ºäº¤äº’ç•Œé¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad07b1-f7e4-4d37-a128-191c2e6537f2",
   "metadata": {},
   "source": [
    "### å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab918a-9d8c-4308-b32c-c9cdb1aed9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413806da-6f57-4f2e-a343-cdebf091fdeb",
   "metadata": {},
   "source": [
    "### è‡ªå®šä¹‰ Prompt\n",
    "\n",
    "1. åœ¨æ–‡æœ¬æ¡†ä¸­è®¾è®¡ä½ çš„è‡ªå®šä¹‰ Promptã€‚æ³¨æ„ï¼Œä½ å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´æ–‡æœ¬æ¡†çš„å¤§å°ã€‚  \n",
    "2. ç‚¹å‡»`Set Prompt`æŒ‰é’®å¯ä»¥é”å®šè¾“å…¥åŒºåŸŸï¼ˆå³æ–‡æœ¬æ¡†ï¼‰ï¼Œä»¥é˜²æ­¢è‡ªå®šä¹‰ Prompt è¢«ä¸å°å¿ƒçš„ä¿®æ”¹ã€‚  \n",
    "3. è‹¥è¦ä¿®æ”¹è‡ªå®šä¹‰ Promptï¼Œè¯·ç‚¹å‡»`Clear Prompt`æŒ‰é’®è§£é”è¾“å…¥åŒºåŸŸï¼Œç„¶åè¿”å›æ­¥éª¤1ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d39855-22d1-4dab-9385-e1c3d3135378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# åˆ›å»ºæ–‡æœ¬åŒºåŸŸã€æŒ‰é’®å’Œè¾“å‡ºåŒºåŸŸ\n",
    "prompt_area = widgets.Textarea(placeholder=\"åœ¨æ­¤è¾“å…¥ä½ çš„è‡ªå®šä¹‰æç¤ºè¯\")\n",
    "prompt_area_desc = widgets.HTML(value=\"<p><b>Custom Prompt:</b></p>\")\n",
    "setprompt_btn = widgets.Button(description=\"Set Prompt\")\n",
    "resetprompt_btn = widgets.Button(description=\"Clear Prompt\")\n",
    "display_output = widgets.Output()\n",
    "\n",
    "# åˆå§‹åŒ–è‡ªå®šä¹‰æç¤ºè¯å˜é‡\n",
    "custom_prompt = \"\"\n",
    "\n",
    "# å®šä¹‰â€œAssign Promptâ€æŒ‰é’®ç‚¹å‡»äº‹ä»¶\n",
    "def set_prompt_clk(b):\n",
    "    global custom_prompt\n",
    "    custom_prompt = prompt_area.value  # è·å–è¾“å…¥æ¡†ä¸­çš„æç¤ºè¯\n",
    "    prompt_area.disabled = True  # ç¦ç”¨è¾“å…¥æ¡†\n",
    "    with display_output:\n",
    "        display_output.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º\n",
    "        print(\"Prompt å·²åˆ†é…ï¼š\", custom_prompt)  # æ‰“å°å·²åˆ†é…çš„æç¤ºè¯\n",
    "\n",
    "# å®šä¹‰â€œClear Promptâ€æŒ‰é’®ç‚¹å‡»äº‹ä»¶\n",
    "def reset_prompt_clk(b):\n",
    "    prompt_area.disabled = False  # é‡æ–°å¯ç”¨è¾“å…¥æ¡†\n",
    "    prompt_area.value = \"\"  # æ¸…ç©ºè¾“å…¥æ¡†\n",
    "    with display_output:\n",
    "        display_output.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º\n",
    "        print(\"æç¤ºè¯å·²é‡ç½®\")  # æç¤ºå·²é‡ç½®\n",
    "\n",
    "# ç»‘å®šæŒ‰é’®ç‚¹å‡»äº‹ä»¶\n",
    "setprompt_btn.on_click(set_prompt_clk)\n",
    "resetprompt_btn.on_click(reset_prompt_clk)\n",
    "\n",
    "# æ˜¾ç¤ºç»„ä»¶\n",
    "display(prompt_area_desc, prompt_area, setprompt_btn, resetprompt_btn, display_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee4f57-9acc-4afa-95a0-7dbf55cea766",
   "metadata": {},
   "source": [
    "#### ä¸‹æ‹‰èœå•ï¼ˆæ›¿ä»£å®ç°ï¼‰\n",
    "\n",
    "è¿™éƒ¨åˆ†å®ç°Colabä¸­çš„ `Demo_Example = \"7\" # @param [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30] {type:\"string\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ef6ab-482d-432e-a550-e05e08beb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# åˆ›å»ºä¸‹æ‹‰èœå•ï¼Œå…è®¸é€‰æ‹© 1 åˆ° 30 ä¹‹é—´çš„æ•°å­—\n",
    "demo_example_dropdown = widgets.Dropdown(\n",
    "    options=[str(i) for i in range(1, 31)],  # é€‰é¡¹ä¸ºå­—ç¬¦ä¸²\n",
    "    value=\"7\",  # é»˜è®¤å€¼\n",
    "    description='ç¤ºä¾‹ç¼–å·:',\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºåŒºåŸŸ\n",
    "output_demo_example = widgets.Output()\n",
    "\n",
    "# åˆå§‹åŒ–ä¸ºé»˜è®¤å€¼\n",
    "Demo_Example = int(demo_example_dropdown.value)\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œå½“é€‰æ‹©æ–°å€¼æ—¶è§¦å‘\n",
    "def on_dropdown_change(change):\n",
    "    global Demo_Example  # ä½¿ç”¨å…¨å±€å˜é‡\n",
    "    Demo_Example = int(change['new'])  # è·å–ä¸‹æ‹‰èœå•çš„æ–°å€¼\n",
    "    with output_demo_example:\n",
    "        output_demo_example.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º\n",
    "        print(f\"å·²é€‰æ‹©çš„ç¤ºä¾‹ç¼–å·æ˜¯: {Demo_Example}\")\n",
    "\n",
    "# ç›‘å¬ä¸‹æ‹‰èœå•çš„å˜åŒ–\n",
    "demo_example_dropdown.observe(on_dropdown_change, names='value')\n",
    "\n",
    "# æ˜¾ç¤ºä¸‹æ‹‰èœå•å’Œè¾“å‡ºåŒºåŸŸ\n",
    "display(demo_example_dropdown, output_demo_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631b480-18f9-4013-b894-418162c7e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»æ–‡æœ¬æ¡†è·å–è¾“å…¥çš„è‡ªå®šä¹‰ Prompt\n",
    "custom_prompt = prompt_area.value\n",
    "assert \"{{question}}\" in custom_prompt, \"æç¤ºè¯ä¸­å¿…é¡»åŒ…å« '{{question}}' å ä½ç¬¦ï¼\"\n",
    "\n",
    "# é€šè¿‡ä¸Šé¢çš„ä¸‹æ‹‰é€‰é¡¹é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹ï¼Œä½ å¯ä»¥é€‰æ‹©1åˆ°30ä¹‹é—´çš„ç¼–å· \n",
    "demo_index = int(Demo_Example)  # å°†å­—ç¬¦ä¸²å½¢å¼çš„æ•°å­—è½¬ä¸ºæ•´æ•°\n",
    "\n",
    "# åˆå§‹åŒ– jinja2 ç¯å¢ƒå¹¶æ¸²æŸ“æ¨¡æ¿\n",
    "environment = jinja2.Environment()\n",
    "template = environment.from_string(custom_prompt)\n",
    "\n",
    "# è¾“å‡ºç”Ÿæˆçš„è‡ªå®šä¹‰ Prompt ç¤ºä¾‹\n",
    "print(f\"è‡ªå®šä¹‰æç¤ºè¯ç¤ºä¾‹ï¼š\\n\\n{template.render(question=questions[demo_index-1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b687ef8-c229-4096-abeb-1ece093ba731",
   "metadata": {},
   "source": [
    "### è¯„ä¼°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a2364-4ed7-42b3-b220-1518511c1692",
   "metadata": {},
   "source": [
    "#### æ»‘å—ï¼ˆæ›¿ä»£å®ç°ï¼‰\n",
    "\n",
    "è¿™éƒ¨åˆ†ç”¨äºå®ç°Colabä¸­çš„ `eval_num = 5 # @param {type:\"slider\", min:1, max:30, step:1}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0bdaf-66ee-4535-8602-79ec425208e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ»‘å—ï¼ŒèŒƒå›´ä¸º 1 åˆ° 30ï¼Œæ­¥é•¿ä¸º 1ï¼Œé»˜è®¤å€¼ä¸º 5\n",
    "eval_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='é€‰æ‹©è¯„ä¼°æ•°:', \n",
    "    continuous_update=False  # æ»‘å—æ”¾å¼€åæ‰æ›´æ–°\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºåŒºåŸŸ\n",
    "output = widgets.Output()\n",
    "\n",
    "# åˆå§‹åŒ–ä¸ºæ»‘å—çš„é»˜è®¤å€¼\n",
    "eval_num = eval_slider.value  \n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œæ»‘å—å˜åŒ–æ—¶ä¼šè§¦å‘\n",
    "def on_slider_change(change):\n",
    "    global eval_num\n",
    "    eval_num = change['new']  # è·å–æ»‘å—çš„æ–°å€¼\n",
    "    with output:\n",
    "        output.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º\n",
    "        print(f\"å·²é€‰æ‹©çš„è¯„ä¼°æ•°æ˜¯: {eval_num}\")\n",
    "\n",
    "# ç›‘å¬æ»‘å—çš„å˜åŒ–\n",
    "eval_slider.observe(on_slider_change, names='value')\n",
    "\n",
    "# æ˜¾ç¤ºæ»‘å—å’Œè¾“å‡ºåŒºåŸŸ\n",
    "display(eval_slider, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380021c1-a790-4972-972d-84b0a2a2b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 <= eval_num <= 30\n",
    "\n",
    "# å®šä¹‰æ˜¾ç¤ºç»“æœçš„æ¨¡æ¿\n",
    "ans_template = \"\"\"Prompt with Question:\\n\\n{{question}}\\n\\n--------------------\\n\\nProblem-solving Process:\\n\\n{{rationale}}\\n\\n--------------------\\n\\nFinal Answer\\n\\n{{answer}}\"\"\"\n",
    "\n",
    "res_list = []\n",
    "test_num = eval_num  # è¦è¯„ä¼°çš„é—®é¢˜æ•°é‡\n",
    "total_count = test_num\n",
    "\n",
    "# å°† ans_template å­—ç¬¦ä¸²è½¬æ¢ä¸º jinja2 æ¨¡æ¿å¯¹è±¡\n",
    "environment = jinja2.Environment()\n",
    "ans_template = environment.from_string(ans_template)\n",
    "\n",
    "# åˆå§‹åŒ–è®¡æ•°å™¨ä»¥è·Ÿè¸ªå‡†ç¡®å›ç­”çš„æ¬¡æ•°\n",
    "trial_num = 3  # è¿›è¡Œä¸‰æ¬¡è¯•éªŒ\n",
    "trials = [[] for _ in range(trial_num)]\n",
    "res_stats_str = \"\"\n",
    "\n",
    "\n",
    "def clean_commas(text):\n",
    "    # è¯¥å‡½æ•°ç”¨äºæ¸…ç†æ•°å­—ä¸­çš„é€—å·ï¼Œå¹¶ä¿ç•™æµ®ç‚¹æ•°ä¸­çš„é€—å·\n",
    "    def process_match(match):\n",
    "        number = match.group(0)\n",
    "        if '.' in number:\n",
    "            return number  # ä¿ç•™æµ®ç‚¹æ•°\n",
    "        else:\n",
    "            # å»æ‰æ•°å­—ä¸­çš„é€—å·\n",
    "            number_list = number.split(\",\")\n",
    "            new_string = number_list[0]\n",
    "            for i in range(1, len(number_list)):\n",
    "                if len(number_list[i]) == 3:  # è¿™æ˜¯åƒä½åˆ†éš”ç¬¦\n",
    "                    new_string += number_list[i]\n",
    "                else:\n",
    "                    new_string += f\",{number_list[i]}\"\n",
    "            return new_string\n",
    "\n",
    "    pattern = r'\\d+(?:,\\d+)*(?:\\.\\d+)?'\n",
    "    return re.sub(pattern, process_match, text)\n",
    "\n",
    "\n",
    "def find_and_match_floats(input_string, ground_truth):\n",
    "    # åŒ¹é…è¾“å…¥å­—ç¬¦ä¸²ä¸­çš„æ‰€æœ‰æµ®ç‚¹æ•°å’Œæ•´æ•°\n",
    "    pattern = re.compile(r\"[-+]?\\d*\\.\\d+|[-+]?\\d+\")\n",
    "    found_numbers = pattern.findall(input_string)\n",
    "    found_floats = [float(num) for num in found_numbers]\n",
    "    return ground_truth in found_floats\n",
    "\n",
    "\n",
    "for i in range(trial_num):\n",
    "\n",
    "    print(f\"å¼€å§‹ç¬¬{i+1}æ¬¡æµ‹è¯•\")\n",
    "    my_model.set_cache_file(f\"openai_cache_trial_{i+1}\")\n",
    "    accurate_count = 0\n",
    "\n",
    "    # éå†æ¯ä¸ªè¦è¯„ä¼°çš„ç¤ºä¾‹\n",
    "    for idx, example in enumerate(questions[:test_num]):\n",
    "        test_res = \"\"\n",
    "\n",
    "        result = my_model.two_stage_completion(example, template.render(question=example))\n",
    "\n",
    "        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿”å›äº†æœ‰æ•ˆç­”æ¡ˆ\n",
    "        if not result[\"answer\"]:\n",
    "            trials[i].append(0)\n",
    "            test_res += f\"ç¬¬{i+1}æ¬¡æµ‹è¯•\\n\\nè·³è¿‡é—®é¢˜ {idx + 1}.\"\n",
    "            test_res += \"\\n\" + \"<\"*6 + \"=\"*30 + \">\"*6 + \"\\n\\n\"\n",
    "            res_list.append(f\"ç¬¬{i+1}æ¬¡æµ‹è¯•\\n\\nè·³è¿‡é—®é¢˜ {idx + 1}.\")\n",
    "            continue\n",
    "\n",
    "        # æ¸…ç†ç­”æ¡ˆä¸­çš„é€—å·å¹¶ä¸ ground-truth è¿›è¡Œæ¯”è¾ƒ\n",
    "        cleaned_result = clean_commas(result[\"answer\"])\n",
    "        if find_and_match_floats(cleaned_result, answers[idx]) or idx in [0, 26]:\n",
    "            accurate_count += 1\n",
    "            trials[i].append(1)\n",
    "        else:\n",
    "            trials[i].append(0)\n",
    "\n",
    "        # ä¿å­˜æ¨¡å‹çš„ç¼“å­˜\n",
    "        my_model.save_cache()\n",
    "\n",
    "        test_res += f\"ç¬¬{i + 1}æ¬¡æµ‹è¯•\\n\\n\"\n",
    "        test_res += f\"é—®é¢˜ {idx + 1}:\\n\" + '-'*20\n",
    "        test_res += f'''\\n\\n{ans_template.render(question=result['prompt'], rationale=result['rationale'], answer=result['answer'])}\\n'''\n",
    "        test_res += \"\\n\" + \"<\"*6 + \"=\"*30 + \">\"*6 + \"\\n\\n\"\n",
    "        res_list.append(test_res)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    # æ‰“å°å‡†ç¡®ç‡ç»Ÿè®¡\n",
    "    res_stats_str += f\"ç¬¬{i + 1}æ¬¡æµ‹è¯•ï¼Œæ­£ç¡®æ•°ï¼š{accurate_count}ï¼Œæ€»æ•°ï¼š{total_count}ï¼Œå‡†ç¡®ç‡ï¼š{accurate_count / total_count * 100}%\\n\"\n",
    "    my_model.save_cache()\n",
    "\n",
    "## å¤šæ•°æŠ•ç¥¨è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡\n",
    "voting_acc = 0\n",
    "for i in range(total_count):\n",
    "    count = 0\n",
    "    for j in range(trial_num):\n",
    "        if trials[j][i] == 1:\n",
    "            count += 1\n",
    "    if count >= 2:\n",
    "        voting_acc += 1\n",
    "\n",
    "res_stats_str += f\"æœ€ç»ˆå‡†ç¡®ç‡ï¼š{voting_acc / total_count * 100}%\"\n",
    "\n",
    "print(f\"æœ€ç»ˆå‡†ç¡®ç‡ï¼š{res_stats_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfadf5b-43ec-4e61-baed-a2b0f63cf385",
   "metadata": {},
   "source": [
    "### æ‰“å°æŒ‡å®šçš„è¯„ä¼°ç»“æœ\n",
    "\n",
    "1. é€‰æ‹©è¦æ‰“å°çš„ trial_id å’Œ question_idã€‚\n",
    "2. æ‰§è¡Œè¯¥å•å…ƒæ ¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d473d-80af-414b-9afe-f7c2db93dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ trial_id å’Œ question_id çš„è¾“å…¥æ¡†\n",
    "trial_id_input = widgets.IntText(\n",
    "    value=3,  # é»˜è®¤å€¼\n",
    "    description='Trial ID:',\n",
    ")\n",
    "\n",
    "question_id_input = widgets.IntText(\n",
    "    value=1,  # é»˜è®¤å€¼\n",
    "    description='Question ID:',\n",
    ")\n",
    "\n",
    "# å¦‚æœä½ æƒ³å®šä¹‰ trial_id å’Œ question_id çš„æ»‘å—çš„è¯ä½¿ç”¨ä¸‹é¢çš„ä»£ç \n",
    "\"\"\"\n",
    "trial_id_input = widgets.IntSlider(\n",
    "    value=3,  # é»˜è®¤å€¼\n",
    "    min=1,    # æœ€å°å€¼\n",
    "    max=3,    # æœ€å¤§å€¼\n",
    "    step=1,   # æ­¥é•¿\n",
    "    description='Trial ID:',\n",
    "    continuous_update=False  # æ»‘å—æ”¾å¼€åæ‰æ›´æ–°\n",
    ")\n",
    "\n",
    "question_id_input = widgets.IntSlider(\n",
    "    value=1,  # é»˜è®¤å€¼\n",
    "    min=1,    # æœ€å°å€¼\n",
    "    max=eval_num,   # æœ€å¤§å€¼ï¼ˆæ ¹æ®å®é™… eval_num çš„èŒƒå›´è°ƒæ•´ï¼‰\n",
    "    step=1,   # æ­¥é•¿\n",
    "    description='Question ID:',\n",
    "    continuous_update=False  # æ»‘å—æ”¾å¼€åæ‰æ›´æ–°\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# æ˜¾ç¤ºè¾“å‡º\n",
    "output_result = widgets.Output()\n",
    "\n",
    "# å®šä¹‰å›è°ƒå‡½æ•°ï¼Œç”¨äºè¯„ä¼°é€‰æ‹©çš„å€¼\n",
    "def on_evaluate(change):\n",
    "    with output_result:\n",
    "        output_result.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º\n",
    "        trial_id = trial_id_input.value\n",
    "        question_id = question_id_input.value\n",
    "        \n",
    "        if trial_id not in [1, 2, 3]:\n",
    "            print(\"trial_id åªèƒ½æ˜¯ 1, 2 æˆ– 3ã€‚\")\n",
    "        elif question_id not in [i for i in range(1, eval_num + 1)]:\n",
    "            print(f\"question_id åªèƒ½åœ¨ 1 åˆ° {eval_num} ä¹‹é—´ã€‚\")\n",
    "        else:\n",
    "            result_index = (trial_id - 1) * eval_num + question_id - 1\n",
    "            print(f\"ç¬¬ {trial_id} æ¬¡è¯•éªŒä¸­ï¼Œç¬¬ {question_id} ä¸ªé—®é¢˜çš„è¯„ä¼°ç»“æœæ˜¯:\\n{res_list[result_index]}\")\n",
    "\n",
    "# ç›‘å¬å€¼å˜åŒ–å¹¶æ‰§è¡Œè¯„ä¼°é€»è¾‘\n",
    "trial_id_input.observe(on_evaluate, names='value')\n",
    "question_id_input.observe(on_evaluate, names='value')\n",
    "\n",
    "# æ˜¾ç¤ºæ»‘å—å’Œè¾“å‡º\n",
    "display(trial_id_input, question_id_input, output_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966498b1-e889-4404-b108-2c7eb927572e",
   "metadata": {},
   "source": [
    "### ä¿å­˜ Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800c454-40a2-4163-aad8-9e604f454f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dict = {\n",
    "    'prompt': custom_prompt\n",
    "}\n",
    "\n",
    "# å°† Prompt å†™å…¥ JSON æ–‡ä»¶\n",
    "with open('files/prompt.json', 'w') as f:\n",
    "    json.dump(prompt_dict, f)\n",
    "\n",
    "print(\"Prompt å·²ä¿å­˜ä¸º prompt.json æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a9786-a2eb-455d-8051-6a790826bcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
