{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f01cd25-5a0f-40d5-a48f-990022340c09",
   "metadata": {},
   "source": [
    "# 简介\n",
    "\n",
    "> 指导文章：[01. 初识 LLM API：环境配置与多轮对话演示](https://github.com/Hoper-J/LLM-Guide-and-Demos/blob/master/Guide/01.%20初识%20LLM%20API：环境配置与多轮对话演示.md)\n",
    "\n",
    "在这个 Notebook 中，我们将展示如何使用 API 与大模型进行交互。这是对 API 的一个基础演示，不涉及构建 AI 应用。\n",
    "\n",
    "在线链接：[Kaggle](https://www.kaggle.com/code/aidemos/01-llm-api) | [Colab](https://colab.research.google.com/drive/1jFC_WIec7KW08GBxHuEHikcXWbbv3gSh?usp=share_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9688f10-a828-498a-ae34-2458372eeac0",
   "metadata": {},
   "source": [
    "# 环境变量配置\n",
    "\n",
    "为了保护 API 密钥的安全，需要将其设置为环境变量。环境变量允许我们在不将敏感信息写入代码的情况下访问它们。\n",
    "\n",
    "你可以通过两种方式之一来设置环境变量：\n",
    "1. 在终端中设置环境变量。\n",
    "2. 在 Python 脚本中设置环境变量。\n",
    "\n",
    "这里直接在 Python 中进行设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcc60ff-c2f1-4a4d-89ba-703ce064aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此方法仅在当前 Python 程序或 Notebook 中有效，其他程序或 Notebook 不会共享此设置。\n",
    "# 国内大模型开启了新的篇章，考虑到以后可能会进行多模型的 API 输出对比，不再固定命名为 `OPENAI_API_KEY`。\n",
    "import os\n",
    "\n",
    "# 阿里云（通义千问） API 密钥在 OPENAI_API_KEY 设置\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'\n",
    "\n",
    "# 智谱 API\n",
    "os.environ['ZHIPUAI_API_KEY'] = 'your-api-key'\n",
    "\n",
    "# DEEPSEEK API\n",
    "os.environ['DEEPSEEK_API_KEY'] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde759d2-84d8-47d8-afb9-b60eb8b8c8c8",
   "metadata": {},
   "source": [
    "# 获取环境变量\n",
    "\n",
    "使用 `os.getenv()` 函数来获取环境变量的值，这样我们可以在代码中安全地访问API密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2537743-ddf7-409f-a0b7-9907fc3c171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取API密钥\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "# api_key = os.getenv('ZHIPUAI_API_KEY')\n",
    "# api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "# 打印密钥以确认它被成功读取\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90edf1-6557-4d2e-bc9f-0cd32ee2399a",
   "metadata": {},
   "source": [
    "# 安装所需库\n",
    "\n",
    "接下来，我们需要安装 openai 库，用于与阿里云的大模型 API 进行交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861d904-182e-459b-8d68-bcb643d11615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "!uv add openai\n#!uv add 'httpx<0.28.0' # 降级 httpx 以解决关键字 'proxies' 被移除的问题，最新的 openai 库不会引发该问题，故默认注释"
  },
  {
   "cell_type": "markdown",
   "id": "8c8337b2-a8d3-4f39-a278-71749a9e5763",
   "metadata": {},
   "source": [
    "根据 API 平台执行后续对应的代码块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bec3a1-907b-45f8-b86f-e76dfbd11838",
   "metadata": {},
   "source": [
    "# 单轮对话演示\n",
    "\n",
    "在这一部分，我们将通过API调用构建一个简单的单轮对话，你可以输入一个问题，模型将会返回一个响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c001e93-89f5-4764-aeb3-255f050e2099",
   "metadata": {},
   "source": [
    "## 阿里 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32ed729-5af0-41f1-bba5-ca31b04b833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是阿里云开发的一款超大规模语言模型，我叫通义千问。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端，使用阿里云 DashScope API\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'), # 如果你没有配置环境变量，使用 api_key=\"your-api-key\" 替换\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\", # 这里使用的是阿里云的大模型，如果需要使用其他平台，请参考对应的开发文档后对应修改\n",
    ")\n",
    "\n",
    "# 调用 API 获取模型回复\n",
    "response = client.chat.completions.create(\n",
    "    model=\"qwen-turbo\",\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}]\n",
    "    )\n",
    "\n",
    "# 打印模型回复内容\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb56a4-3e75-429a-99fb-59596527af15",
   "metadata": {},
   "source": [
    "## 智谱 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba141c08-61fd-490b-b67a-44c324a68763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，旨在帮助解答问题和提供信息。你有什么问题或需要帮助的地方吗？\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('ZHIPUAI_API_KEY'),\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    ")\n",
    "\n",
    "# 调用 API 获取模型回复\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}]\n",
    "    )\n",
    "\n",
    "# 打印模型回复内容\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d8202-7966-4b90-bb21-7b1eabf0c856",
   "metadata": {},
   "source": [
    "## DeepSeek API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23857fab-e807-433f-b3a6-b2e36f21e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('DEEPSEEK_API_KEY'),  # 1\n",
    "    base_url=\"https://api.deepseek.com\",  # 2\n",
    ")\n",
    "\n",
    "# 调用 API 获取模型回复\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",  # 3\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}]\n",
    "    )\n",
    "\n",
    "# 打印模型回复内容\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca8c3f-bde7-404e-ba2b-2180c3d62118",
   "metadata": {},
   "source": [
    "# 多轮对话演示\n",
    "\n",
    "扩展上面的代码，支持多轮对话。这意味着模型可以记住上下文，从而生成更连贯的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabc1a1-875a-4781-80d8-a8ebcb4772f3",
   "metadata": {},
   "source": [
    "## 阿里 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85bb7a3-b42e-4888-b5cd-470b196106e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：hello\n",
      "模型输出：Hello! How can I assist you today?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： 1+2=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：1+2=\n",
      "模型输出：1 + 2 equals 3. Is there anything else you'd like to know or calculate?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： 我们刚刚说了什么\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：我们刚刚说了什么\n",
      "模型输出：我们刚刚进行了一个简单的数学计算，1 + 2 等于 3。还有什么其他问题或内容需要讨论吗？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化OpenAI客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'), \n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "# 初始化对话历史\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "# 进行多轮对话，当前为3轮\n",
    "for i in range(3):\n",
    "    # 获取用户输入\n",
    "    user_input = input(\"请输入：\")\n",
    "    \n",
    "    # 添加用户消息到对话历史\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 调用API获取模型回复\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # 提取模型回复内容\n",
    "    assistant_output = response.choices[0].message.content\n",
    "    \n",
    "    # 将模型回复添加到对话历史\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_output})\n",
    "    \n",
    "    print(f'用户输入：{user_input}')\n",
    "    print(f'模型输出：{assistant_output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bf0e-3db1-4d9b-b5f7-40bc2167e086",
   "metadata": {},
   "source": [
    "## 智谱 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5377fc54-d7e5-46a8-a82c-51c949bb4f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：hello\n",
      "模型输出：Hello! How can I assist you today? If you have any questions or need help with something, feel free to let me know!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： 1+2=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：1+2=\n",
      "模型输出：1 + 2 = 3\n",
      "\n",
      "If you have any more questions or need further assistance, feel free to ask!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： 我们刚刚说了什么\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：我们刚刚说了什么\n",
      "模型输出：我们刚刚进行了以下对话：\n",
      "\n",
      "1. 你说：“hello”\n",
      "2. 我回应：“Hello! How can I assist you today? If you have any questions or need help with something, feel free to let me know!”\n",
      "3. 你问：“1+2=”\n",
      "4. 我回答：“1 + 2 = 3”\n",
      "\n",
      "如果你还有其他问题或需要进一步的帮助，请随时告诉我！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('ZHIPUAI_API_KEY'),\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    ")\n",
    "\n",
    "# 初始化对话历史\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "# 进行多轮对话，当前为3轮\n",
    "for i in range(3):\n",
    "    # 获取用户输入\n",
    "    user_input = input(\"请输入：\")\n",
    "    \n",
    "    # 添加用户消息到对话历史\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 调用API获取模型回复\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4-plus\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # 提取模型回复内容\n",
    "    assistant_output = response.choices[0].message.content\n",
    "    \n",
    "    # 将模型回复添加到对话历史\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_output})\n",
    "    \n",
    "    print(f'用户输入：{user_input}')\n",
    "    print(f'模型输出：{assistant_output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb045f-3fca-4a9e-9953-2ad75a513afd",
   "metadata": {},
   "source": [
    "## DeepSeek API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd84b44d-8c32-46fc-9a10-df397bb32e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：hello\n",
      "模型输出：Hello! How can I assist you today? 😊\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： 1+2=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：1+2=\n",
      "模型输出：1 + 2 equals **3**. Let me know if you have more questions! 😊\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入： 我们刚刚说了什么\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入：我们刚刚说了什么\n",
      "模型输出：我们刚刚讨论了简单的加法问题：**1 + 2 = 3**。如果你有其他问题或需要帮助，随时告诉我！ 😊\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('DEEPSEEK_API_KEY'),\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    ")\n",
    "\n",
    "# 初始化对话历史\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "# 进行多轮对话，当前为3轮\n",
    "for i in range(3):\n",
    "    # 获取用户输入\n",
    "    user_input = input(\"请输入：\")\n",
    "    \n",
    "    # 添加用户消息到对话历史\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 调用API获取模型回复\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # 提取模型回复内容\n",
    "    assistant_output = response.choices[0].message.content\n",
    "    \n",
    "    # 将模型回复添加到对话历史\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_output})\n",
    "    \n",
    "    print(f'用户输入：{user_input}')\n",
    "    print(f'模型输出：{assistant_output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b46ed-df4a-455d-be25-f10914ab4e08",
   "metadata": {},
   "source": [
    "# 流式输出演示\n",
    "\n",
    "流式输出允许我们实时查看模型生成的回答，而不是等待最终结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3154f465-cbe0-44cb-b85a-85fa48f063d6",
   "metadata": {},
   "source": [
    "## 阿里 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5207ea23-f336-4c76-bc7d-c5637796fdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是来自阿里云的大规模语言模型，我叫通义千问。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化OpenAI客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "# 开启流式输出\n",
    "response = client.chat.completions.create(\n",
    "    model=\"qwen-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁？\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# 实时打印模型回复的增量内容\n",
    "for chunk in response:\n",
    "    # 判断回复内容是否非空\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902072d5-aeee-4846-a0de-8f43abcd6692",
   "metadata": {},
   "source": [
    "## 智谱 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "415c0883-c6b1-4b4a-920b-2b90e3625706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是人工智能助手智谱清言（ChatGLM），是基于智谱 AI 公司于 2024 年训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('ZHIPUAI_API_KEY'),\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    ")\n",
    "\n",
    "# 开启流式输出\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁？\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# 实时打印模型回复的增量内容\n",
    "for chunk in response:\n",
    "    # 判断回复内容是否非空\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead8eca-d36b-45fc-b73c-78044a1f802a",
   "metadata": {},
   "source": [
    "## DeepSeek API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47961125-d1b4-4f32-aecd-ac8235130854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('DEEPSEEK_API_KEY'),\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    ")\n",
    "\n",
    "# 开启流式输出\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁？\"}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# 实时打印模型回复的增量内容\n",
    "for chunk in response:\n",
    "    # 判断回复内容是否非空\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbac289-276e-4b60-8d1c-b7eef5e3da0b",
   "metadata": {},
   "source": [
    "# 总结与扩展学习\n",
    "\n",
    "恭喜你完成了 API 的使用！在这个 Notebook 中，我们学习了如何与大语言模型API进行交互，设置环境变量和实现单轮和多轮对话以及流式输出。\n",
    "\n",
    "如果对 AI 和生成式人工智能感兴趣，推荐观看李宏毅老师的课程：\n",
    "- [生成式人工智能导论-视频](https://www.bilibili.com/video/BV1BJ4m1e7g8)\n",
    "- [课程主页](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)\n",
    "\n",
    "# 下一步\n",
    "\n",
    "- 可以遵循导论的顺序进行阅读，如果对 API 的使用感兴趣，推荐跳转阅读 《[DeepSeek 使用手册](../README.md#deepseek-使用手册doing)》。\n",
    "- 对流式输出感到疑惑的同学阅读：《[DeepSeek API 输出解析 - OpenAI SDK](../Guide/DeepSeek%20API%20输出解析%20-%20OpenAI%20SDK.md)》和 《[流式输出解析](../Guide/DeepSeek%20API%20流式输出解析%20-%20OpenAI%20SDK.md)》。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c266f-d51c-4690-b280-852151b4b19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}