{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae64ac8-c461-469e-88b0-8e485a0c8439",
   "metadata": {},
   "source": [
    "# DeepSeek API è¾“å‡ºè§£æ - OpenAI SDK\n",
    "\n",
    "> æŒ‡å¯¼æ–‡ç« ï¼š[DeepSeek API è¾“å‡ºè§£æ - OpenAI SDK](https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/Guide/DeepSeek%20API%20è¾“å‡ºè§£æ%20-%20OpenAI%20SDK.md)\n",
    "\n",
    "ä»ä¸‹æ–¹é€‰æ‹©å¹³å°å¼€å§‹ï¼Œæ›¿æ¢ `your-api-key` åç‚¹å‡» `â–º` æˆ–ä½¿ç”¨ `Shift + å›è½¦` è¿è¡Œä»£ç å—ã€‚\n",
    "\n",
    "åœ¨çº¿é“¾æ¥ï¼š[Kaggle](https://www.kaggle.com/code/aidemos/deepseek-api-guide-2) | [Colab](https://colab.research.google.com/drive/1WT0jpeIzWewoN5cT12Uwi92d5_tNff2J?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3091b9c4-ab24-451e-9c13-c49b863e4c7c",
   "metadata": {},
   "source": [
    "# ç¯å¢ƒä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2beceb-535d-40c8-a2d5-a49d693f511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc8f41-c3d1-4398-988b-2349e0b2c293",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc379cb-6848-469c-bbda-6b5e14ffdd84",
   "metadata": {},
   "source": [
    "## è®¤è¯†è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1eb298-ca95-466b-a2ef-aa73c88b375e",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201e4f42-074e-4876-9eea-8e66f01f6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1ï¼šæ›¿æ¢æˆå¯¹åº”çš„ API_Keyï¼Œå¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡è€Œéæ˜æ–‡å¡«å†™ï¼Œå³ api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    base_url=\"https://api.deepseek.com/v1\", # 2ï¼šæ¯ä¸ªå¹³å°çš„ base_url ä¸åŒ\n",
    ")\n",
    "\n",
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\", # 3ï¼šæ¨¡å‹æ ‡è¯†ï¼ˆmodel_idï¼‰å¯èƒ½å­˜åœ¨å·®å¼‚\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1765ca0-cdcf-4165-826e-518b6bb0d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-V3ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067885,\n",
      " 'id': '8e2cd3b1-c2cd-4bd6-9207-d843d8bc4535',\n",
      " 'model': 'deepseek-chat',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': 'fp_3a5770e1b4',\n",
      " 'usage': {'completion_tokens': 37,\n",
      "           'prompt_cache_hit_tokens': 0,\n",
      "           'prompt_cache_miss_tokens': 11,\n",
      "           'prompt_tokens': 11,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 48}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b0d94-46e9-4487-913b-e8af8467b9ad",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6dbef5e-f4c0-4f93-8f08-82debb1b3fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-V3ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87174746-cc3b-4e7c-88f1-0e64008b8583",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c3c7b4-e01c-4229-b713-9bbaa2fda7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 11 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 11]\n",
      "è¾“å‡º: 37 tokens\n",
      "æ€»æ¶ˆè€—: 48 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0000 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0003 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0003 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion):\n",
    "    stats = completion.usage\n",
    "    hit = stats.prompt_cache_hit_tokens\n",
    "    miss = stats.prompt_cache_miss_tokens\n",
    "    \n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # æŒ‰ DeepSeek å®šä»·è®¡ç®—æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰\n",
    "    # - è¾“å…¥: 2å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 0.5å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "\t# - è¾“å‡º: 8å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    # å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    input_cost = (hit * 0.5 + miss * 2) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * 8 / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4035819-f0e4-4fc4-a596-c941df3608aa",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212843ec-d21d-4402-a6b8-c2919432df6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\", # 3ï¼šæ¢æˆæ¨ç†æ¨¡å‹\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e3ab1f-89e8-4c6a-a42e-b0f974c41890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': 'Alright, the user asked \"ä½ æ˜¯è°ï¼Ÿ\" '\n",
      "                                               'which means \"Who are you?\" in '\n",
      "                                               'Chinese. I need to respond in '\n",
      "                                               'Chinese. Let me start by '\n",
      "                                               'greeting them politely.\\n'\n",
      "                                               '\\n'\n",
      "                                               \"I should mention that I'm an \"\n",
      "                                               'AI assistant created by '\n",
      "                                               \"DeepSeek. It's important to \"\n",
      "                                               'highlight my purpose, like '\n",
      "                                               'helping with information, '\n",
      "                                               'answering questions, and '\n",
      "                                               'offering advice. Keeping it '\n",
      "                                               'friendly and open-ended would '\n",
      "                                               'encourage further interaction. '\n",
      "                                               'Let me make sure the tone is '\n",
      "                                               'approachable and the '\n",
      "                                               'information is clear.',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067891,\n",
      " 'id': '2943392c-b18c-4309-a531-db40f5fb79e7',\n",
      " 'model': 'deepseek-reasoner',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': 'fp_7e73fd9a08',\n",
      " 'usage': {'completion_tokens': 134,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 95},\n",
      "           'prompt_cache_hit_tokens': 0,\n",
      "           'prompt_cache_miss_tokens': 13,\n",
      "           'prompt_tokens': 13,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 147}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66576f-0e8a-40bd-ab31-70499c460a61",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246cc1f4-f310-4449-b98d-48d28ba45c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\n",
      "Alright, the user asked \"ä½ æ˜¯è°ï¼Ÿ\" which means \"Who are you?\" in Chinese. I need to respond in Chinese. Let me start by greeting them politely.\n",
      "\n",
      "I should mention that I'm an AI assistant created by DeepSeek. It's important to highlight my purpose, like helping with information, answering questions, and offering advice. Keeping it friendly and open-ended would encourage further interaction. Let me make sure the tone is approachable and the information is clear.\n",
      "===== æ¨¡å‹å›å¤ =====\n",
      "æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è·å–æ¨ç†æ€è€ƒè¿‡ç¨‹ï¼ˆReasonerç‰¹æœ‰å­—æ®µï¼‰\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\\n{reasoning_content}\")\n",
    "\n",
    "# è·å–æ¨¡å‹å›å¤å†…å®¹ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== æ¨¡å‹å›å¤ =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870783c-3eb7-456d-9c60-63366167d3aa",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c624853-3e3c-4341-ae30-5332b59d6393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 13 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 13]\n",
      "è¾“å‡º: 134 tokens\n",
      "â”œâ”€ æ¨ç†è¿‡ç¨‹: 95 tokens\n",
      "â””â”€ æœ€ç»ˆå›ç­”: 39 tokens\n",
      "æ€»æ¶ˆè€—: 147 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0001 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0021 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0022 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion):\n",
    "    stats = completion.usage\n",
    "    hit = stats.prompt_cache_hit_tokens\n",
    "    miss = stats.prompt_cache_miss_tokens\n",
    "    \n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # æ¨ç†æ¨¡å‹çš„tokenåˆ†è§£\n",
    "    if details := stats.completion_tokens_details:\n",
    "        reasoning = details['reasoning_tokens']\n",
    "        final = stats.completion_tokens - reasoning\n",
    "        print(f\"â”œâ”€ æ¨ç†è¿‡ç¨‹: {reasoning} tokens\")\n",
    "        print(f\"â””â”€ æœ€ç»ˆå›ç­”: {final} tokens\")\n",
    "    \n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # æŒ‰ DeepSeek å®šä»·è®¡ç®—æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰\n",
    "    # - è¾“å…¥Token: 4å…ƒ/ç™¾ä¸‡Tokensï¼ˆæœªå‘½ä¸­ç¼“å­˜ 1å…ƒ/ç™¾ä¸‡Tokensï¼‰\n",
    "\t# - è¾“å‡ºToken: 16å…ƒ/ç™¾ä¸‡Tokens\n",
    "    # å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    input_cost = (hit * 1 + miss * 4) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * 16 / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedcdfed-70a7-4ec8-9764-da8a13da1755",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ç¡…åŸºæµåŠ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94d5c4-45fc-4d36-9fe2-491ab9cfa2f9",
   "metadata": {},
   "source": [
    "## è®¤è¯†è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3cb9d-a2da-4936-8dc0-a93439be1226",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ceedf55-5208-472b-a696-1087839314c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1ï¼šæ›¿æ¢æˆå¯¹åº”çš„ API_Keyï¼Œå¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡è€Œéæ˜æ–‡å¡«å†™ï¼Œå³ api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://api.siliconflow.cn/v1\", # 2ï¼šæ¯ä¸ªå¹³å°çš„ base_url ä¸åŒ\n",
    ")\n",
    "\n",
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-V3\", # 3ï¼šæ¨¡å‹æ ‡è¯†ï¼ˆmodel_idï¼‰å¯èƒ½å­˜åœ¨å·®å¼‚\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1812b04-0d73-48ad-8327-459256c5efd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œç”± OpenAI '\n",
      "                                     'å¼€å‘ï¼Œæ—¨åœ¨å›ç­”å„ç§é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œå¸®åŠ©è§£å†³ä»»åŠ¡ã€‚ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›æœ‰ç”¨çš„å›ç­”ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067903,\n",
      " 'id': '0194e8864c5c970c36e16c8a98326619',\n",
      " 'model': 'deepseek-ai/DeepSeek-V3',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': '',\n",
      " 'usage': {'completion_tokens': 37, 'prompt_tokens': 11, 'total_tokens': 48}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddde14f-04e9-43fa-8ffb-36474b4f7958",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e666f7-7be0-40fb-99fb-d4ef836b87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œç”± OpenAI å¼€å‘ï¼Œæ—¨åœ¨å›ç­”å„ç§é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œå¸®åŠ©è§£å†³ä»»åŠ¡ã€‚ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›æœ‰ç”¨çš„å›ç­”ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e04b3b-6a7d-4685-ac15-40405194883e",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "482daee3-382c-4188-9095-fad357fa3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 11 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 11]\n",
      "è¾“å‡º: 37 tokens\n",
      "æ€»æ¶ˆè€—: 48 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0000 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0003 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0003 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek èŠå¤©æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 2å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 0.5å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "\t- è¾“å‡º: 8å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81780ee6-3d27-4cc4-a702-66ec3c48007c",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13adbfc-3543-4e9e-9245-87e5540b60c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1\", # 3ï¼šæ¢æˆæ¨ç†æ¨¡å‹\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded0a469-32af-47d6-ad10-dcaea53c09dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚æˆ‘å¯ä»¥ååŠ©æ‚¨è§£ç­”å„ç±»é—®é¢˜ï¼Œæä¾›ä¿¡æ¯æŸ¥è¯¢ã€å­¦ä¹ å»ºè®®ã€ç§‘æŠ€èµ„è®¯ç­‰æ”¯æŒã€‚å¸Œæœ›ä»¥ä¸“ä¸šåˆæ¸©æš–çš„æ–¹å¼å¸®åŠ©åˆ°æ‚¨ï¼âœ¨\\n'\n",
      "                                     '\\n'\n",
      "                                     'æœ‰å…·ä½“éœ€æ±‚éšæ—¶å‘Šè¯‰æˆ‘å“¦ï½ğŸ˜Š',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': 'Good, I should start by '\n",
      "                                               'greeting the user. Then '\n",
      "                                               \"explain that I'm an AI \"\n",
      "                                               'assistant created by DeepSeek '\n",
      "                                               'to help with various tasks. '\n",
      "                                               'Mention the areas I can assist '\n",
      "                                               'with like answering questions, '\n",
      "                                               'providing info, learning '\n",
      "                                               'advice, and tech support. Use '\n",
      "                                               'simple Chinese, friendly and '\n",
      "                                               'professional tone. Keep it '\n",
      "                                               'concise. Make sure to include '\n",
      "                                               'the emojis and the structure '\n",
      "                                               'as shown. Avoid markdown '\n",
      "                                               'formatting.',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067906,\n",
      " 'id': '0194e88658c9a31e3f87c0732767a4a5',\n",
      " 'model': 'deepseek-ai/DeepSeek-R1',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': '',\n",
      " 'usage': {'completion_tokens': 147, 'prompt_tokens': 13, 'total_tokens': 160}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbdf093-015f-40b2-bc0f-1a53d7314c6f",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323d6c16-8c0a-46ea-bc1e-ddb4cd368e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\n",
      "Good, I should start by greeting the user. Then explain that I'm an AI assistant created by DeepSeek to help with various tasks. Mention the areas I can assist with like answering questions, providing info, learning advice, and tech support. Use simple Chinese, friendly and professional tone. Keep it concise. Make sure to include the emojis and the structure as shown. Avoid markdown formatting.\n",
      "===== æ¨¡å‹å›å¤ =====\n",
      "æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚æˆ‘å¯ä»¥ååŠ©æ‚¨è§£ç­”å„ç±»é—®é¢˜ï¼Œæä¾›ä¿¡æ¯æŸ¥è¯¢ã€å­¦ä¹ å»ºè®®ã€ç§‘æŠ€èµ„è®¯ç­‰æ”¯æŒã€‚å¸Œæœ›ä»¥ä¸“ä¸šåˆæ¸©æš–çš„æ–¹å¼å¸®åŠ©åˆ°æ‚¨ï¼âœ¨\n",
      "\n",
      "æœ‰å…·ä½“éœ€æ±‚éšæ—¶å‘Šè¯‰æˆ‘å“¦ï½ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# è·å–æ¨ç†æ€è€ƒè¿‡ç¨‹ï¼ˆReasonerç‰¹æœ‰å­—æ®µï¼‰\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\\n{reasoning_content}\")\n",
    "\n",
    "# è·å–æ¨¡å‹å›å¤å†…å®¹ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== æ¨¡å‹å›å¤ =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448878e0-094a-46ad-aa38-663af46417e3",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1508ae2c-f673-4aea-a8db-92a1f5b51d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 13 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 13]\n",
      "è¾“å‡º: 147 tokens\n",
      "æ€»æ¶ˆè€—: 160 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0001 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0024 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0024 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek æ¨ç†æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 4å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 1å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - è¾“å‡º: 16å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # å°è¯•è·å–æ¨ç†è¿‡ç¨‹è¯¦æƒ…\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # å°è¯•è·å– reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # ä»…åœ¨å­˜åœ¨æ¨ç†tokensæ•°é‡å­—æ®µæ—¶å¤„ç†\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"â”œâ”€ æ¨ç†è¿‡ç¨‹: {reasoning} tokens\")\n",
    "            print(f\"â””â”€ æœ€ç»ˆå›ç­”: {final} tokens\")\n",
    "    \n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de9f59-ae1b-4377-83c2-31de5b6cd669",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# é˜¿é‡Œäº‘ç™¾ç‚¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b599e5-18ff-431b-b0ae-3282e65cb081",
   "metadata": {},
   "source": [
    "## è®¤è¯†è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071d7d0-9cdc-470b-a8c3-0ed76f3137e1",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc954701-c1ff-4563-ba92-0c36669339b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1ï¼šæ›¿æ¢æˆå¯¹åº”çš„ API_Keyï¼Œå¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡è€Œéæ˜æ–‡å¡«å†™ï¼Œå³ api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\", # 2ï¼šæ¯ä¸ªå¹³å°çš„ base_url ä¸åŒ\n",
    ")\n",
    "\n",
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-v3\", # 3ï¼šæ¨¡å‹æ ‡è¯†ï¼ˆmodel_idï¼‰å¯èƒ½å­˜åœ¨å·®å¼‚\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28cb7bff-0933-4a2f-9f90-3b16a1f418b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æˆ‘æ˜¯DeepSeek '\n",
      "                                     'Chatï¼Œä¸€ä¸ªç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æä¾›ä¿¡æ¯æŸ¥è¯¢ã€å¯¹è¯äº¤æµå’Œè§£ç­”é—®é¢˜ç­‰æœåŠ¡ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067920,\n",
      " 'id': 'chatcmpl-35b95e65-9196-926e-9bd4-d2198ce3fc06',\n",
      " 'model': 'deepseek-v3',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 45, 'prompt_tokens': 12, 'total_tokens': 57}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277530a-81a2-434b-8f41-b51d242d8ce8",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfe8e595-420e-4d33-be4e-19f25c271edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯DeepSeek Chatï¼Œä¸€ä¸ªç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æä¾›ä¿¡æ¯æŸ¥è¯¢ã€å¯¹è¯äº¤æµå’Œè§£ç­”é—®é¢˜ç­‰æœåŠ¡ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb48d4-e06b-4888-8b3d-e17f8a591a17",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a44d4230-b450-4a53-91e6-b129991c93f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 12 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 12]\n",
      "è¾“å‡º: 45 tokens\n",
      "æ€»æ¶ˆè€—: 57 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0000 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0004 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0004 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek èŠå¤©æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 2å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 0.5å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "\t- è¾“å‡º: 8å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439e8ba-6329-4337-8a5a-3871d60ab20d",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868871f-d587-4cf6-a3df-c2af062bb495",
   "metadata": {},
   "source": [
    "> é˜¿é‡Œäº‘ç™¾ç‚¼çš„ deepseek-r1 API å¯èƒ½ä¼šå‡ºç°é¢„æœŸå¤–çš„è¾“å‡ºï¼šé‡å¤/æ²¡æœ‰æ€ç»´é“¾æˆ–ä¸è§£æ `<think>` æ ‡ç­¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da018abb-4ea6-42e8-85e3-bf297c67e951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\", # 3ï¼šæ¢æˆæ¨ç†æ¨¡å‹\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b452d52-8eb5-4f47-9ff5-e4803c974fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚æœ‰å…³æ¨¡å‹å’Œäº§å“çš„è¯¦ç»†å†…å®¹è¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ã€‚',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': '',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067923,\n",
      " 'id': 'chatcmpl-3e65620f-0cd6-94ff-9b85-90beb6929042',\n",
      " 'model': 'deepseek-r1',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 38, 'prompt_tokens': 12, 'total_tokens': 50}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0e42c-b019-49d4-99cb-66d8996db804",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183a35bb-59cb-4285-8fd0-24629a62be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\n",
      "\n",
      "\n",
      "===== æœ€ç»ˆå›å¤ =====\n",
      "æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚æœ‰å…³æ¨¡å‹å’Œäº§å“çš„è¯¦ç»†å†…å®¹è¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ã€‚\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_reasoner_response(completion):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - completion (object): API è¿”å›çš„å¯¹è±¡\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - (reasoning_content, reply_content)\n",
    "    \n",
    "    å¤„ç†ä¸¤ç§å¹³å°æ ¼å¼ï¼š\n",
    "    1. æœ‰ç‹¬ç«‹ reasoning_content å­—æ®µçš„å¹³å°ï¼šDeepSeek å®˜æ–¹ï¼Œç¡…åŸºæµåŠ¨ï¼Œç™¾åº¦æ™ºèƒ½äº‘...\n",
    "    2. å¯èƒ½éœ€è¦ä» content è§£æ <think> æ ‡ç­¾çš„å¹³å°ï¼šé˜¿é‡Œäº‘ç™¾ç‚¼ï¼ˆå¶å°”ä¼šæ²¡æœ‰ reasoning_contentï¼‰...\n",
    "    \"\"\"\n",
    "    message = completion.choices[0].message\n",
    "    \n",
    "    # å°è¯•ç›´æ¥è·å– reasoning_content å­—æ®µ\n",
    "    reasoning = getattr(message, 'reasoning_content', None)\n",
    "    \n",
    "    # æœ‰ reasoning_content æ—¶ç›´æ¥è·å–æœ€ç»ˆå›å¤\n",
    "    if reasoning:\n",
    "        final_content = getattr(message, 'content', '')\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰ï¼Œåˆ™å°è¯•ä» content è§£æ\n",
    "        content = getattr(message, 'content', '')\n",
    "        \n",
    "        # ä½¿ç”¨éè´ªå©ªæ¨¡å¼åŒ¹é… <think> æ ‡ç­¾\n",
    "        reasoning_match = re.search(\n",
    "            r'<think>(.*?)</think>', \n",
    "            content, \n",
    "            re.DOTALL  # å…è®¸è·¨è¡ŒåŒ¹é…\n",
    "        )\n",
    "        \n",
    "        if reasoning_match:\n",
    "            reasoning = reasoning_match.group(1).strip()\n",
    "            # ä»åŸå§‹å†…å®¹ç§»é™¤æ¨ç†éƒ¨åˆ†\n",
    "            final_content = re.sub(\n",
    "                r'<think>.*?</think>', \n",
    "                '', \n",
    "                content, \n",
    "                flags=re.DOTALL\n",
    "            ).strip()\n",
    "        else:\n",
    "            reasoning = ''\n",
    "            final_content = content\n",
    "    \n",
    "    return reasoning, final_content\n",
    "\n",
    "reasoning_content, content = parse_reasoner_response(completion)\n",
    "\n",
    "print(f\"===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\\n{reasoning_content}\")\n",
    "print(f\"\\n===== æœ€ç»ˆå›å¤ =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121ab5b-3273-4481-9197-993cff97eb25",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66fcdbea-faa7-4455-9f53-712172dd1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 12 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 12]\n",
      "è¾“å‡º: 38 tokens\n",
      "æ€»æ¶ˆè€—: 50 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0000 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0006 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0007 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek æ¨ç†æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 4å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 1å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - è¾“å‡º: 16å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # å°è¯•è·å–æ¨ç†è¿‡ç¨‹è¯¦æƒ…\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # å°è¯•è·å– reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # ä»…åœ¨å­˜åœ¨æ¨ç†tokensæ•°é‡å­—æ®µæ—¶å¤„ç†\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"â”œâ”€ æ¨ç†è¿‡ç¨‹: {reasoning} tokens\")\n",
    "            print(f\"â””â”€ æœ€ç»ˆå›ç­”: {final} tokens\")\n",
    "    \n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a5f80-bc05-4796-81a9-ccda08b2a9ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ç™¾åº¦æ™ºèƒ½äº‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a0a47-8e24-4130-be11-abe9f5751249",
   "metadata": {},
   "source": [
    "## è®¤è¯†è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a029e69-968f-4385-baf6-03653f1ed074",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acd60c76-161c-4793-8576-215b485afec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1ï¼šæ›¿æ¢æˆå¯¹åº”çš„ API_Keyï¼Œå¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡è€Œéæ˜æ–‡å¡«å†™ï¼Œå³ api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://qianfan.baidubce.com/v2\" # 2ï¼šæ¯ä¸ªå¹³å°çš„ base_url ä¸åŒ\n",
    ")\n",
    "\n",
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-v3\", # 3ï¼šæ¨¡å‹æ ‡è¯†ï¼ˆmodel_idï¼‰å¯èƒ½å­˜åœ¨å·®å¼‚\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "921e0103-84b6-4401-ad5b-3cbedb810820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'normal',\n",
      "              'flag': 0,\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œç”±OpenAIå¼€å‘ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯æ¥å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯å’ŒååŠ©ç”¨æˆ·å®Œæˆå„ç§ä»»åŠ¡ã€‚ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›å¸®åŠ©ï¼',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067928,\n",
      " 'id': 'as-ivpqpffkd1',\n",
      " 'model': 'deepseek-v3',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 36, 'prompt_tokens': 8, 'total_tokens': 44}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ebf29-e261-43cf-be7d-c67e38780a3d",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a7c199d-9bd1-4b6f-825f-a3522661d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œç”±OpenAIå¼€å‘ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯æ¥å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯å’ŒååŠ©ç”¨æˆ·å®Œæˆå„ç§ä»»åŠ¡ã€‚ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›å¸®åŠ©ï¼\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc439c-485e-4941-a39c-09c3cb059e3a",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20087743-44e9-4976-a23a-f903d58f1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 8 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 8]\n",
      "è¾“å‡º: 36 tokens\n",
      "æ€»æ¶ˆè€—: 44 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0000 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0003 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0003 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek èŠå¤©æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 2å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 0.5å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "\t- è¾“å‡º: 8å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4845a-2920-47d5-9ecf-2cee311444ab",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce09efe-a8a3-4a3a-be08-e34958958fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\", # 3ï¼šæ¢æˆæ¨ç†æ¨¡å‹\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e93c7d4a-66df-4b0f-97ab-6fcab74ad229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'normal',\n",
      "              'flag': 0,\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '\\n'\n",
      "                                     '\\n'\n",
      "                                     'æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': 'å—¯ï¼Œç”¨æˆ·é—®â€œä½ æ˜¯è°ï¼Ÿâ€ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„é—®é¢˜ï¼Œå¯èƒ½ä»–ä»¬æƒ³äº†è§£æˆ‘çš„åŸºæœ¬ä¿¡æ¯æˆ–è€…åŠŸèƒ½ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ä¿æŒå›ç­”ç®€æ´æ˜äº†ï¼Œä½†ä¹Ÿè¦å…¨é¢ã€‚ç”¨æˆ·å¯èƒ½æ˜¯åˆæ¬¡ä½¿ç”¨ï¼Œæ‰€ä»¥åº”è¯¥è¯¦ç»†ä»‹ç»æˆ‘çš„åŠŸèƒ½å’Œç”¨é€”ï¼Œé¿å…ä½¿ç”¨æŠ€æœ¯æœ¯è¯­ï¼Œè®©å›ç­”æ›´æ˜“æ‡‚ã€‚åŒæ—¶ï¼Œè¦å¼ºè°ƒæˆ‘çš„é™åˆ¶ï¼Œæ¯”å¦‚æ•°æ®æˆªæ­¢åˆ°2023å¹´ï¼Œä¸èƒ½è”ç½‘ç­‰ï¼Œè¿™æ ·å¯ä»¥ç®¡ç†ç”¨æˆ·çš„é¢„æœŸã€‚å¦å¤–ï¼Œè¦ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„è¯­æ°”ï¼Œè®©ç”¨æˆ·æ„Ÿè§‰è¢«é‡è§†ã€‚å¯èƒ½ç”¨æˆ·åç»­ä¼šæœ‰æ›´å…·ä½“çš„é—®é¢˜ï¼Œæ‰€ä»¥æœ€åå¯ä»¥é‚€è¯·ä»–ä»¬æå‡ºæ›´å¤šéœ€æ±‚ï¼Œä¿ƒè¿›äº’åŠ¨ã€‚éœ€è¦ç¡®ä¿å›ç­”ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹è¯´æ˜ï¼Œä½†ä¸è¦å¤ªæœºæ¢°ï¼Œè‡ªç„¶æµç•…æœ€å¥½ã€‚\\n',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067946,\n",
      " 'id': 'as-bxdt1ar9hb',\n",
      " 'model': 'deepseek-r1',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 165,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 131},\n",
      "           'prompt_tokens': 8,\n",
      "           'total_tokens': 173}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303550b9-95d6-4ec2-a114-432cbe79de9e",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9facdcd7-95e8-40d5-ab6c-38c8785db50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\n",
      "å—¯ï¼Œç”¨æˆ·é—®â€œä½ æ˜¯è°ï¼Ÿâ€ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„é—®é¢˜ï¼Œå¯èƒ½ä»–ä»¬æƒ³äº†è§£æˆ‘çš„åŸºæœ¬ä¿¡æ¯æˆ–è€…åŠŸèƒ½ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ä¿æŒå›ç­”ç®€æ´æ˜äº†ï¼Œä½†ä¹Ÿè¦å…¨é¢ã€‚ç”¨æˆ·å¯èƒ½æ˜¯åˆæ¬¡ä½¿ç”¨ï¼Œæ‰€ä»¥åº”è¯¥è¯¦ç»†ä»‹ç»æˆ‘çš„åŠŸèƒ½å’Œç”¨é€”ï¼Œé¿å…ä½¿ç”¨æŠ€æœ¯æœ¯è¯­ï¼Œè®©å›ç­”æ›´æ˜“æ‡‚ã€‚åŒæ—¶ï¼Œè¦å¼ºè°ƒæˆ‘çš„é™åˆ¶ï¼Œæ¯”å¦‚æ•°æ®æˆªæ­¢åˆ°2023å¹´ï¼Œä¸èƒ½è”ç½‘ç­‰ï¼Œè¿™æ ·å¯ä»¥ç®¡ç†ç”¨æˆ·çš„é¢„æœŸã€‚å¦å¤–ï¼Œè¦ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„è¯­æ°”ï¼Œè®©ç”¨æˆ·æ„Ÿè§‰è¢«é‡è§†ã€‚å¯èƒ½ç”¨æˆ·åç»­ä¼šæœ‰æ›´å…·ä½“çš„é—®é¢˜ï¼Œæ‰€ä»¥æœ€åå¯ä»¥é‚€è¯·ä»–ä»¬æå‡ºæ›´å¤šéœ€æ±‚ï¼Œä¿ƒè¿›äº’åŠ¨ã€‚éœ€è¦ç¡®ä¿å›ç­”ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹è¯´æ˜ï¼Œä½†ä¸è¦å¤ªæœºæ¢°ï¼Œè‡ªç„¶æµç•…æœ€å¥½ã€‚\n",
      "\n",
      "===== æ¨¡å‹å›å¤ =====\n",
      "\n",
      "\n",
      "æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è·å–æ¨ç†æ€è€ƒè¿‡ç¨‹ï¼ˆReasonerç‰¹æœ‰å­—æ®µï¼‰\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\\n{reasoning_content}\")\n",
    "\n",
    "# è·å–æ¨¡å‹å›å¤å†…å®¹ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== æ¨¡å‹å›å¤ =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48cc16d-d179-417b-80a7-a4a70c550ccf",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06600d31-6f52-405d-ac22-674d5adc047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 8 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 8]\n",
      "è¾“å‡º: 165 tokens\n",
      "â”œâ”€ æ¨ç†è¿‡ç¨‹: 131 tokens\n",
      "â””â”€ æœ€ç»ˆå›ç­”: 34 tokens\n",
      "æ€»æ¶ˆè€—: 173 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0000 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0026 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0027 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek æ¨ç†æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 4å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 1å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - è¾“å‡º: 16å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # å°è¯•è·å–æ¨ç†è¿‡ç¨‹è¯¦æƒ…\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # å°è¯•è·å– reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # ä»…åœ¨å­˜åœ¨æ¨ç†tokensæ•°é‡å­—æ®µæ—¶å¤„ç†\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"â”œâ”€ æ¨ç†è¿‡ç¨‹: {reasoning} tokens\")\n",
    "            print(f\"â””â”€ æœ€ç»ˆå›ç­”: {final} tokens\")\n",
    "    \n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7306ffe-e8a6-495b-b93a-6c442b859150",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# å­—èŠ‚ç«å±±å¼•æ“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f4726-25bd-47e0-8076-c62dcc24915b",
   "metadata": {},
   "source": [
    "## è®¤è¯†è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0d828-1ca6-4e60-9d63-3275e381a9a0",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99952546-851c-41df-8526-cd6fb0456fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1ï¼šæ›¿æ¢æˆå¯¹åº”çš„ API_Keyï¼Œå¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡è€Œéæ˜æ–‡å¡«å†™ï¼Œå³ api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://ark.cn-beijing.volces.com/api/v3\" # 2ï¼šæ¯ä¸ªå¹³å°çš„ base_url ä¸åŒ\n",
    ")\n",
    "\n",
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-v3-241226\", # 3ï¼šæ¨¡å‹æ ‡è¯†ï¼ˆmodel_idï¼‰å¯èƒ½å­˜åœ¨å·®å¼‚\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18326f43-c920-4f80-b0b1-16feb9087bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'æˆ‘æ˜¯DeepSeek '\n",
      "                                     'Chatï¼Œä¸€ä¸ªç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æä¾›ä¿¡æ¯æŸ¥è¯¢ã€å¯¹è¯äº¤æµå’Œè§£ç­”é—®é¢˜ç­‰æœåŠ¡ã€‚å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067948,\n",
      " 'id': '0217390679463949666a785a9e88d5b0179ae9e4e1f0138c10560',\n",
      " 'model': 'deepseek-v3-241226',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 45,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 0},\n",
      "           'prompt_tokens': 11,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 56}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1acc6-a7ed-4d93-9c59-a371f17ee703",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "460539aa-b1a6-4562-ae68-2c6bdc1710fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯DeepSeek Chatï¼Œä¸€ä¸ªç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æä¾›ä¿¡æ¯æŸ¥è¯¢ã€å¯¹è¯äº¤æµå’Œè§£ç­”é—®é¢˜ç­‰æœåŠ¡ã€‚å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9caa83-5d62-4f8c-98da-07bce9ed76ad",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "637b7d02-343c-4193-8c3a-13d7c28ed53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 11 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 11]\n",
      "è¾“å‡º: 45 tokens\n",
      "æ€»æ¶ˆè€—: 56 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0000 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0004 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0004 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek èŠå¤©æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 2å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 0.5å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "\t- è¾“å‡º: 8å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7be81a-745f-468c-8e2b-84db9d9d47af",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b323e6d-31f2-41d3-9606-1bade6780599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# å•è½®å¯¹è¯ç¤ºä¾‹\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1-250120\", # 3ï¼šæ¢æˆæ¨ç†æ¨¡å‹\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'ä½ æ˜¯è°ï¼Ÿ'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80c8acac-05ea-46ac-bdf2-cde82ac18516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '\\n'\n",
      "                                     '\\n'\n",
      "                                     'æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': 'å¥½çš„ï¼Œç”¨æˆ·é—®æˆ‘â€œä½ æ˜¯è°ï¼Ÿâ€ï¼Œæˆ‘éœ€è¦ç”¨ä¸­æ–‡å›ç­”ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥ä»‹ç»è‡ªå·±çš„èº«ä»½ï¼Œè¯´æ˜æˆ‘æ˜¯ç”±DeepSeekå¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ã€‚æ¥ç€ï¼Œå¯ä»¥æåˆ°æˆ‘çš„ä¸»è¦åŠŸèƒ½æ˜¯æä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜å’ŒååŠ©å®Œæˆä»»åŠ¡ã€‚è¦ä¿æŒå›ç­”ç®€æ´æ˜äº†ï¼Œç¬¦åˆç”¨æˆ·çš„éœ€æ±‚ã€‚å¯èƒ½ç”¨æˆ·æƒ³çŸ¥é“æˆ‘çš„å¼€å‘èƒŒæ™¯æˆ–è€…ç”¨é€”ï¼Œæ‰€ä»¥éœ€è¦æ¶µç›–è¿™äº›æ–¹é¢ã€‚åŒæ—¶ï¼Œè¦ç¡®ä¿è¯­æ°”å‹å¥½ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«å¸®åŠ©ã€‚ç„¶åï¼Œè¦æ£€æŸ¥æœ‰æ²¡æœ‰é—æ¼çš„é‡è¦ä¿¡æ¯ï¼Œæ¯”å¦‚æ˜¯å¦éœ€è¦æåˆ°å…·ä½“çš„æœåŠ¡èŒƒå›´æˆ–æŠ€æœ¯ç‰¹ç‚¹ã€‚æœ€åï¼Œç”¨è‡ªç„¶çš„å£è¯­åŒ–è¡¨è¾¾ï¼Œé¿å…ä½¿ç”¨è¿‡äºæ­£å¼æˆ–å¤æ‚çš„å¥å­ç»“æ„ï¼Œè®©ç”¨æˆ·æ›´å®¹æ˜“ç†è§£ã€‚\\n',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067957,\n",
      " 'id': '0217390679487739666a785a9e88d5b0179ae9e4e1f0138eb752d',\n",
      " 'model': 'deepseek-r1-250120',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 163,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 125},\n",
      "           'prompt_tokens': 13,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 176}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc2343-5945-4d3c-8cb5-05667c2acc06",
   "metadata": {},
   "source": [
    "#### è·å–æ¨¡å‹å›å¤ï¼ˆchoicesï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a873452-370d-4e51-ae2c-a42c0536b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\n",
      "å¥½çš„ï¼Œç”¨æˆ·é—®æˆ‘â€œä½ æ˜¯è°ï¼Ÿâ€ï¼Œæˆ‘éœ€è¦ç”¨ä¸­æ–‡å›ç­”ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥ä»‹ç»è‡ªå·±çš„èº«ä»½ï¼Œè¯´æ˜æˆ‘æ˜¯ç”±DeepSeekå¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ã€‚æ¥ç€ï¼Œå¯ä»¥æåˆ°æˆ‘çš„ä¸»è¦åŠŸèƒ½æ˜¯æä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜å’ŒååŠ©å®Œæˆä»»åŠ¡ã€‚è¦ä¿æŒå›ç­”ç®€æ´æ˜äº†ï¼Œç¬¦åˆç”¨æˆ·çš„éœ€æ±‚ã€‚å¯èƒ½ç”¨æˆ·æƒ³çŸ¥é“æˆ‘çš„å¼€å‘èƒŒæ™¯æˆ–è€…ç”¨é€”ï¼Œæ‰€ä»¥éœ€è¦æ¶µç›–è¿™äº›æ–¹é¢ã€‚åŒæ—¶ï¼Œè¦ç¡®ä¿è¯­æ°”å‹å¥½ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«å¸®åŠ©ã€‚ç„¶åï¼Œè¦æ£€æŸ¥æœ‰æ²¡æœ‰é—æ¼çš„é‡è¦ä¿¡æ¯ï¼Œæ¯”å¦‚æ˜¯å¦éœ€è¦æåˆ°å…·ä½“çš„æœåŠ¡èŒƒå›´æˆ–æŠ€æœ¯ç‰¹ç‚¹ã€‚æœ€åï¼Œç”¨è‡ªç„¶çš„å£è¯­åŒ–è¡¨è¾¾ï¼Œé¿å…ä½¿ç”¨è¿‡äºæ­£å¼æˆ–å¤æ‚çš„å¥å­ç»“æ„ï¼Œè®©ç”¨æˆ·æ›´å®¹æ˜“ç†è§£ã€‚\n",
      "\n",
      "===== æ¨¡å‹å›å¤ =====\n",
      "\n",
      "\n",
      "æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è·å–æ¨ç†æ€è€ƒè¿‡ç¨‹ï¼ˆReasonerç‰¹æœ‰å­—æ®µï¼‰\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== æ¨¡å‹æ¨ç†è¿‡ç¨‹ =====\\n{reasoning_content}\")\n",
    "\n",
    "# è·å–æ¨¡å‹å›å¤å†…å®¹ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== æ¨¡å‹å›å¤ =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08821e68-c3b7-4e28-b83f-3f9961102704",
   "metadata": {},
   "source": [
    "#### è·å–ç”¨é‡ä¿¡æ¯ï¼ˆusageï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19d1ff7d-c761-41af-bd52-f0615c048138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN æ¶ˆè€—æ˜ç»† =====\n",
      "è¾“å…¥: 13 tokens [ç¼“å­˜å‘½ä¸­: 0 | æœªå‘½ä¸­: 13]\n",
      "è¾“å‡º: 163 tokens\n",
      "â”œâ”€ æ¨ç†è¿‡ç¨‹: 125 tokens\n",
      "â””â”€ æœ€ç»ˆå›ç­”: 38 tokens\n",
      "æ€»æ¶ˆè€—: 176 tokens\n",
      "\n",
      "===== æˆæœ¬æ˜ç»† =====\n",
      "è¾“å…¥æˆæœ¬: ï¿¥0.0001 å…ƒ\n",
      "è¾“å‡ºæˆæœ¬: ï¿¥0.0026 å…ƒ\n",
      "é¢„ä¼°æ€»æˆæœ¬: ï¿¥0.0027 å…ƒ\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    å‚æ•°ï¼š\n",
    "    - input_cost: è¾“å…¥ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - output_cost: è¾“å‡ºä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - cache_hit_cost: ç¼“å­˜å‘½ä¸­ä»·æ ¼ï¼ˆå½“å¹³å°ä¸æ”¯æŒæ—¶è‡ªåŠ¨é€€åŒ–åˆ°å…¨ä»·æ¨¡å¼ï¼‰\n",
    "\n",
    "    æŒ‰ DeepSeek æ¨ç†æ¨¡å‹å®šä»·è®¾å®šé»˜è®¤æˆæœ¬ï¼ˆå•ä½ï¼šå…ƒï¼‰ï¼š\n",
    "    - è¾“å…¥: 4å…ƒ/ç™¾ä¸‡ Tokensï¼ˆç¼“å­˜å‘½ä¸­ 1å…ƒ/ç™¾ä¸‡ Tokensï¼‰\n",
    "    - è¾“å‡º: 16å…ƒ/ç™¾ä¸‡ Tokens\n",
    "    å®˜æ–¹ä»·æ ¼æ–‡æ¡£ï¼šhttps://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # å°è¯•è·å–å­—æ®µï¼ˆå…¼å®¹å…¶ä»–å¹³å°ï¼‰\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN æ¶ˆè€—æ˜ç»† =====\")\n",
    "    # ä»…åœ¨å­˜åœ¨ç¼“å­˜æœºåˆ¶æ—¶æ˜¾ç¤ºç»†èŠ‚\n",
    "    if hit + miss > 0:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens [ç¼“å­˜å‘½ä¸­: {hit} | æœªå‘½ä¸­: {miss}]\")\n",
    "    else:\n",
    "        print(f\"è¾“å…¥: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"è¾“å‡º: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # å°è¯•è·å–æ¨ç†è¿‡ç¨‹è¯¦æƒ…\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # å°è¯•è·å– reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # ä»…åœ¨å­˜åœ¨æ¨ç†tokensæ•°é‡å­—æ®µæ—¶å¤„ç†\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"â”œâ”€ æ¨ç†è¿‡ç¨‹: {reasoning} tokens\")\n",
    "            print(f\"â””â”€ æœ€ç»ˆå›ç­”: {final} tokens\")\n",
    "    \n",
    "    print(f\"æ€»æ¶ˆè€—: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # åŠ¨æ€æˆæœ¬è®¡ç®—\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== æˆæœ¬æ˜ç»† =====\")\n",
    "    print(f\"è¾“å…¥æˆæœ¬: ï¿¥{input_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"è¾“å‡ºæˆæœ¬: ï¿¥{output_cost_total:.4f} å…ƒ\")\n",
    "    print(f\"é¢„ä¼°æ€»æˆæœ¬: ï¿¥{total_cost:.4f} å…ƒ\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
