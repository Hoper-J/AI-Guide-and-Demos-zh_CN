{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae64ac8-c461-469e-88b0-8e485a0c8439",
   "metadata": {},
   "source": [
    "# DeepSeek API 输出解析 - OpenAI SDK\n",
    "\n",
    "> 指导文章：[DeepSeek API 输出解析 - OpenAI SDK](https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/Guide/DeepSeek%20API%20输出解析%20-%20OpenAI%20SDK.md)\n",
    "\n",
    "从下方选择平台开始，替换 `your-api-key` 后点击 `►` 或使用 `Shift + 回车` 运行代码块。\n",
    "\n",
    "在线链接：[Kaggle](https://www.kaggle.com/code/aidemos/deepseek-api-guide-2) | [Colab](https://colab.research.google.com/drive/1WT0jpeIzWewoN5cT12Uwi92d5_tNff2J?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3091b9c4-ab24-451e-9c13-c49b863e4c7c",
   "metadata": {},
   "source": [
    "# 环境依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2beceb-535d-40c8-a2d5-a49d693f511b",
   "metadata": {},
   "outputs": [],
   "source": "!uv add openai"
  },
  {
   "cell_type": "markdown",
   "id": "bcdc8f41-c3d1-4398-988b-2349e0b2c293",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc379cb-6848-469c-bbda-6b5e14ffdd84",
   "metadata": {},
   "source": [
    "## 认识输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1eb298-ca95-466b-a2ef-aa73c88b375e",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201e4f42-074e-4876-9eea-8e66f01f6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1：替换成对应的 API_Key，可以使用环境变量而非明文填写，即 api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    base_url=\"https://api.deepseek.com/v1\", # 2：每个平台的 base_url 不同\n",
    ")\n",
    "\n",
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\", # 3：模型标识（model_id）可能存在差异\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1765ca0-cdcf-4165-826e-518b6bb0d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067885,\n",
      " 'id': '8e2cd3b1-c2cd-4bd6-9207-d843d8bc4535',\n",
      " 'model': 'deepseek-chat',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': 'fp_3a5770e1b4',\n",
      " 'usage': {'completion_tokens': 37,\n",
      "           'prompt_cache_hit_tokens': 0,\n",
      "           'prompt_cache_miss_tokens': 11,\n",
      "           'prompt_tokens': 11,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 48}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b0d94-46e9-4487-913b-e8af8467b9ad",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6dbef5e-f4c0-4f93-8f08-82debb1b3fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87174746-cc3b-4e7c-88f1-0e64008b8583",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c3c7b4-e01c-4229-b713-9bbaa2fda7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 11 tokens [缓存命中: 0 | 未命中: 11]\n",
      "输出: 37 tokens\n",
      "总消耗: 48 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0000 元\n",
      "输出成本: ￥0.0003 元\n",
      "预估总成本: ￥0.0003 元\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion):\n",
    "    stats = completion.usage\n",
    "    hit = stats.prompt_cache_hit_tokens\n",
    "    miss = stats.prompt_cache_miss_tokens\n",
    "    \n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # 按 DeepSeek 定价计算成本（单位：元）\n",
    "    # - 输入: 2元/百万 Tokens（缓存命中 0.5元/百万 Tokens）\n",
    "\t# - 输出: 8元/百万 Tokens\n",
    "    # 官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    input_cost = (hit * 0.5 + miss * 2) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * 8 / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4035819-f0e4-4fc4-a596-c941df3608aa",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212843ec-d21d-4402-a6b8-c2919432df6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\", # 3：换成推理模型\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e3ab1f-89e8-4c6a-a42e-b0f974c41890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': 'Alright, the user asked \"你是谁？\" '\n",
      "                                               'which means \"Who are you?\" in '\n",
      "                                               'Chinese. I need to respond in '\n",
      "                                               'Chinese. Let me start by '\n",
      "                                               'greeting them politely.\\n'\n",
      "                                               '\\n'\n",
      "                                               \"I should mention that I'm an \"\n",
      "                                               'AI assistant created by '\n",
      "                                               \"DeepSeek. It's important to \"\n",
      "                                               'highlight my purpose, like '\n",
      "                                               'helping with information, '\n",
      "                                               'answering questions, and '\n",
      "                                               'offering advice. Keeping it '\n",
      "                                               'friendly and open-ended would '\n",
      "                                               'encourage further interaction. '\n",
      "                                               'Let me make sure the tone is '\n",
      "                                               'approachable and the '\n",
      "                                               'information is clear.',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067891,\n",
      " 'id': '2943392c-b18c-4309-a531-db40f5fb79e7',\n",
      " 'model': 'deepseek-reasoner',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': 'fp_7e73fd9a08',\n",
      " 'usage': {'completion_tokens': 134,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 95},\n",
      "           'prompt_cache_hit_tokens': 0,\n",
      "           'prompt_cache_miss_tokens': 13,\n",
      "           'prompt_tokens': 13,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 147}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66576f-0e8a-40bd-ab31-70499c460a61",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246cc1f4-f310-4449-b98d-48d28ba45c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 模型推理过程 =====\n",
      "Alright, the user asked \"你是谁？\" which means \"Who are you?\" in Chinese. I need to respond in Chinese. Let me start by greeting them politely.\n",
      "\n",
      "I should mention that I'm an AI assistant created by DeepSeek. It's important to highlight my purpose, like helping with information, answering questions, and offering advice. Keeping it friendly and open-ended would encourage further interaction. Let me make sure the tone is approachable and the information is clear.\n",
      "===== 模型回复 =====\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "# 获取推理思考过程（Reasoner特有字段）\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== 模型推理过程 =====\\n{reasoning_content}\")\n",
    "\n",
    "# 获取模型回复内容（与之前相同）\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== 模型回复 =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870783c-3eb7-456d-9c60-63366167d3aa",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c624853-3e3c-4341-ae30-5332b59d6393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 13 tokens [缓存命中: 0 | 未命中: 13]\n",
      "输出: 134 tokens\n",
      "├─ 推理过程: 95 tokens\n",
      "└─ 最终回答: 39 tokens\n",
      "总消耗: 147 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0001 元\n",
      "输出成本: ￥0.0021 元\n",
      "预估总成本: ￥0.0022 元\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion):\n",
    "    stats = completion.usage\n",
    "    hit = stats.prompt_cache_hit_tokens\n",
    "    miss = stats.prompt_cache_miss_tokens\n",
    "    \n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # 推理模型的token分解\n",
    "    if details := stats.completion_tokens_details:\n",
    "        reasoning = details['reasoning_tokens']\n",
    "        final = stats.completion_tokens - reasoning\n",
    "        print(f\"├─ 推理过程: {reasoning} tokens\")\n",
    "        print(f\"└─ 最终回答: {final} tokens\")\n",
    "    \n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # 按 DeepSeek 定价计算成本（单位：元）\n",
    "    # - 输入Token: 4元/百万Tokens（未命中缓存 1元/百万Tokens）\n",
    "\t# - 输出Token: 16元/百万Tokens\n",
    "    # 官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    input_cost = (hit * 1 + miss * 4) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * 16 / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedcdfed-70a7-4ec8-9764-da8a13da1755",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 硅基流动"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94d5c4-45fc-4d36-9fe2-491ab9cfa2f9",
   "metadata": {},
   "source": [
    "## 认识输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3cb9d-a2da-4936-8dc0-a93439be1226",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ceedf55-5208-472b-a696-1087839314c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1：替换成对应的 API_Key，可以使用环境变量而非明文填写，即 api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://api.siliconflow.cn/v1\", # 2：每个平台的 base_url 不同\n",
    ")\n",
    "\n",
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-V3\", # 3：模型标识（model_id）可能存在差异\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1812b04-0d73-48ad-8327-459256c5efd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '我是一个人工智能助手，由 OpenAI '\n",
      "                                     '开发，旨在回答各种问题、提供信息和帮助解决任务。你可以问我任何问题，我会尽力提供有用的回答！有什么我可以帮助你的吗？',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067903,\n",
      " 'id': '0194e8864c5c970c36e16c8a98326619',\n",
      " 'model': 'deepseek-ai/DeepSeek-V3',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': '',\n",
      " 'usage': {'completion_tokens': 37, 'prompt_tokens': 11, 'total_tokens': 48}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddde14f-04e9-43fa-8ffb-36474b4f7958",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e666f7-7be0-40fb-99fb-d4ef836b87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，由 OpenAI 开发，旨在回答各种问题、提供信息和帮助解决任务。你可以问我任何问题，我会尽力提供有用的回答！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e04b3b-6a7d-4685-ac15-40405194883e",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "482daee3-382c-4188-9095-fad357fa3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 11 tokens [缓存命中: 0 | 未命中: 11]\n",
      "输出: 37 tokens\n",
      "总消耗: 48 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0000 元\n",
      "输出成本: ￥0.0003 元\n",
      "预估总成本: ￥0.0003 元\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 聊天模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 2元/百万 Tokens（缓存命中 0.5元/百万 Tokens）\n",
    "\t- 输出: 8元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # 动态成本计算\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81780ee6-3d27-4cc4-a702-66ec3c48007c",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13adbfc-3543-4e9e-9245-87e5540b60c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1\", # 3：换成推理模型\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded0a469-32af-47d6-ad10-dcaea53c09dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '您好！我是由深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。我可以协助您解答各类问题，提供信息查询、学习建议、科技资讯等支持。希望以专业又温暖的方式帮助到您！✨\\n'\n",
      "                                     '\\n'\n",
      "                                     '有具体需求随时告诉我哦～😊',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': 'Good, I should start by '\n",
      "                                               'greeting the user. Then '\n",
      "                                               \"explain that I'm an AI \"\n",
      "                                               'assistant created by DeepSeek '\n",
      "                                               'to help with various tasks. '\n",
      "                                               'Mention the areas I can assist '\n",
      "                                               'with like answering questions, '\n",
      "                                               'providing info, learning '\n",
      "                                               'advice, and tech support. Use '\n",
      "                                               'simple Chinese, friendly and '\n",
      "                                               'professional tone. Keep it '\n",
      "                                               'concise. Make sure to include '\n",
      "                                               'the emojis and the structure '\n",
      "                                               'as shown. Avoid markdown '\n",
      "                                               'formatting.',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067906,\n",
      " 'id': '0194e88658c9a31e3f87c0732767a4a5',\n",
      " 'model': 'deepseek-ai/DeepSeek-R1',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': '',\n",
      " 'usage': {'completion_tokens': 147, 'prompt_tokens': 13, 'total_tokens': 160}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbdf093-015f-40b2-bc0f-1a53d7314c6f",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323d6c16-8c0a-46ea-bc1e-ddb4cd368e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 模型推理过程 =====\n",
      "Good, I should start by greeting the user. Then explain that I'm an AI assistant created by DeepSeek to help with various tasks. Mention the areas I can assist with like answering questions, providing info, learning advice, and tech support. Use simple Chinese, friendly and professional tone. Keep it concise. Make sure to include the emojis and the structure as shown. Avoid markdown formatting.\n",
      "===== 模型回复 =====\n",
      "您好！我是由深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。我可以协助您解答各类问题，提供信息查询、学习建议、科技资讯等支持。希望以专业又温暖的方式帮助到您！✨\n",
      "\n",
      "有具体需求随时告诉我哦～😊\n"
     ]
    }
   ],
   "source": [
    "# 获取推理思考过程（Reasoner特有字段）\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== 模型推理过程 =====\\n{reasoning_content}\")\n",
    "\n",
    "# 获取模型回复内容（与之前相同）\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== 模型回复 =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448878e0-094a-46ad-aa38-663af46417e3",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1508ae2c-f673-4aea-a8db-92a1f5b51d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 13 tokens [缓存命中: 0 | 未命中: 13]\n",
      "输出: 147 tokens\n",
      "总消耗: 160 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0001 元\n",
      "输出成本: ￥0.0024 元\n",
      "预估总成本: ￥0.0024 元\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 推理模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 4元/百万 Tokens（缓存命中 1元/百万 Tokens）\n",
    "    - 输出: 16元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # 尝试获取推理过程详情\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # 尝试获取 reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # 仅在存在推理tokens数量字段时处理\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"├─ 推理过程: {reasoning} tokens\")\n",
    "            print(f\"└─ 最终回答: {final} tokens\")\n",
    "    \n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # 动态成本计算\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost_total:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost_total:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de9f59-ae1b-4377-83c2-31de5b6cd669",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 阿里云百炼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b599e5-18ff-431b-b0ae-3282e65cb081",
   "metadata": {},
   "source": [
    "## 认识输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071d7d0-9cdc-470b-a8c3-0ed76f3137e1",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc954701-c1ff-4563-ba92-0c36669339b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1：替换成对应的 API_Key，可以使用环境变量而非明文填写，即 api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\", # 2：每个平台的 base_url 不同\n",
    ")\n",
    "\n",
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-v3\", # 3：模型标识（model_id）可能存在差异\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28cb7bff-0933-4a2f-9f90-3b16a1f418b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '我是DeepSeek '\n",
      "                                     'Chat，一个由深度求索公司开发的智能助手，旨在通过自然语言处理和机器学习技术来提供信息查询、对话交流和解答问题等服务。如果您有任何问题或需要帮助，请随时告诉我！',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067920,\n",
      " 'id': 'chatcmpl-35b95e65-9196-926e-9bd4-d2198ce3fc06',\n",
      " 'model': 'deepseek-v3',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 45, 'prompt_tokens': 12, 'total_tokens': 57}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277530a-81a2-434b-8f41-b51d242d8ce8",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfe8e595-420e-4d33-be4e-19f25c271edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是DeepSeek Chat，一个由深度求索公司开发的智能助手，旨在通过自然语言处理和机器学习技术来提供信息查询、对话交流和解答问题等服务。如果您有任何问题或需要帮助，请随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb48d4-e06b-4888-8b3d-e17f8a591a17",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a44d4230-b450-4a53-91e6-b129991c93f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 12 tokens [缓存命中: 0 | 未命中: 12]\n",
      "输出: 45 tokens\n",
      "总消耗: 57 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0000 元\n",
      "输出成本: ￥0.0004 元\n",
      "预估总成本: ￥0.0004 元\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 聊天模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 2元/百万 Tokens（缓存命中 0.5元/百万 Tokens）\n",
    "\t- 输出: 8元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # 动态成本计算\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439e8ba-6329-4337-8a5a-3871d60ab20d",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868871f-d587-4cf6-a3df-c2af062bb495",
   "metadata": {},
   "source": [
    "> 阿里云百炼的 deepseek-r1 API 可能会出现预期外的输出：重复/没有思维链或不解析 `<think>` 标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da018abb-4ea6-42e8-85e3-bf297c67e951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\", # 3：换成推理模型\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b452d52-8eb5-4f47-9ff5-e4803c974fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。有关模型和产品的详细内容请参考官方文档。',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': '',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067923,\n",
      " 'id': 'chatcmpl-3e65620f-0cd6-94ff-9b85-90beb6929042',\n",
      " 'model': 'deepseek-r1',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 38, 'prompt_tokens': 12, 'total_tokens': 50}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0e42c-b019-49d4-99cb-66d8996db804",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183a35bb-59cb-4285-8fd0-24629a62be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 模型推理过程 =====\n",
      "\n",
      "\n",
      "===== 最终回复 =====\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。有关模型和产品的详细内容请参考官方文档。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_reasoner_response(completion):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - completion (object): API 返回的对象\n",
    "    \n",
    "    返回：\n",
    "    - (reasoning_content, reply_content)\n",
    "    \n",
    "    处理两种平台格式：\n",
    "    1. 有独立 reasoning_content 字段的平台：DeepSeek 官方，硅基流动，百度智能云...\n",
    "    2. 可能需要从 content 解析 <think> 标签的平台：阿里云百炼（偶尔会没有 reasoning_content）...\n",
    "    \"\"\"\n",
    "    message = completion.choices[0].message\n",
    "    \n",
    "    # 尝试直接获取 reasoning_content 字段\n",
    "    reasoning = getattr(message, 'reasoning_content', None)\n",
    "    \n",
    "    # 有 reasoning_content 时直接获取最终回复\n",
    "    if reasoning:\n",
    "        final_content = getattr(message, 'content', '')\n",
    "    else:\n",
    "        # 如果没有，则尝试从 content 解析\n",
    "        content = getattr(message, 'content', '')\n",
    "        \n",
    "        # 使用非贪婪模式匹配 <think> 标签\n",
    "        reasoning_match = re.search(\n",
    "            r'<think>(.*?)</think>', \n",
    "            content, \n",
    "            re.DOTALL  # 允许跨行匹配\n",
    "        )\n",
    "        \n",
    "        if reasoning_match:\n",
    "            reasoning = reasoning_match.group(1).strip()\n",
    "            # 从原始内容移除推理部分\n",
    "            final_content = re.sub(\n",
    "                r'<think>.*?</think>', \n",
    "                '', \n",
    "                content, \n",
    "                flags=re.DOTALL\n",
    "            ).strip()\n",
    "        else:\n",
    "            reasoning = ''\n",
    "            final_content = content\n",
    "    \n",
    "    return reasoning, final_content\n",
    "\n",
    "reasoning_content, content = parse_reasoner_response(completion)\n",
    "\n",
    "print(f\"===== 模型推理过程 =====\\n{reasoning_content}\")\n",
    "print(f\"\\n===== 最终回复 =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121ab5b-3273-4481-9197-993cff97eb25",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66fcdbea-faa7-4455-9f53-712172dd1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 12 tokens [缓存命中: 0 | 未命中: 12]\n",
      "输出: 38 tokens\n",
      "总消耗: 50 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0000 元\n",
      "输出成本: ￥0.0006 元\n",
      "预估总成本: ￥0.0007 元\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 推理模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 4元/百万 Tokens（缓存命中 1元/百万 Tokens）\n",
    "    - 输出: 16元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # 尝试获取推理过程详情\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # 尝试获取 reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # 仅在存在推理tokens数量字段时处理\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"├─ 推理过程: {reasoning} tokens\")\n",
    "            print(f\"└─ 最终回答: {final} tokens\")\n",
    "    \n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # 动态成本计算\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost_total:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost_total:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a5f80-bc05-4796-81a9-ccda08b2a9ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 百度智能云"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a0a47-8e24-4130-be11-abe9f5751249",
   "metadata": {},
   "source": [
    "## 认识输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a029e69-968f-4385-baf6-03653f1ed074",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acd60c76-161c-4793-8576-215b485afec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1：替换成对应的 API_Key，可以使用环境变量而非明文填写，即 api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://qianfan.baidubce.com/v2\" # 2：每个平台的 base_url 不同\n",
    ")\n",
    "\n",
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-v3\", # 3：模型标识（model_id）可能存在差异\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "921e0103-84b6-4401-ad5b-3cbedb810820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'normal',\n",
      "              'flag': 0,\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '我是一个人工智能助手，由OpenAI开发，旨在通过自然语言处理和机器学习技术来回答问题、提供信息和协助用户完成各种任务。你可以问我任何问题，我会尽力提供帮助！',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067928,\n",
      " 'id': 'as-ivpqpffkd1',\n",
      " 'model': 'deepseek-v3',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 36, 'prompt_tokens': 8, 'total_tokens': 44}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ebf29-e261-43cf-be7d-c67e38780a3d",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a7c199d-9bd1-4b6f-825f-a3522661d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，由OpenAI开发，旨在通过自然语言处理和机器学习技术来回答问题、提供信息和协助用户完成各种任务。你可以问我任何问题，我会尽力提供帮助！\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc439c-485e-4941-a39c-09c3cb059e3a",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20087743-44e9-4976-a23a-f903d58f1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 8 tokens [缓存命中: 0 | 未命中: 8]\n",
      "输出: 36 tokens\n",
      "总消耗: 44 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0000 元\n",
      "输出成本: ￥0.0003 元\n",
      "预估总成本: ￥0.0003 元\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 聊天模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 2元/百万 Tokens（缓存命中 0.5元/百万 Tokens）\n",
    "\t- 输出: 8元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # 动态成本计算\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4845a-2920-47d5-9ecf-2cee311444ab",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce09efe-a8a3-4a3a-be08-e34958958fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\", # 3：换成推理模型\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e93c7d4a-66df-4b0f-97ab-6fcab74ad229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'normal',\n",
      "              'flag': 0,\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '\\n'\n",
      "                                     '\\n'\n",
      "                                     '您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': '嗯，用户问“你是谁？”，这是一个常见的问题，可能他们想了解我的基本信息或者功能。首先，我需要保持回答简洁明了，但也要全面。用户可能是初次使用，所以应该详细介绍我的功能和用途，避免使用技术术语，让回答更易懂。同时，要强调我的限制，比如数据截止到2023年，不能联网等，这样可以管理用户的预期。另外，要保持友好和专业的语气，让用户感觉被重视。可能用户后续会有更具体的问题，所以最后可以邀请他们提出更多需求，促进互动。需要确保回答结构清晰，分点说明，但不要太机械，自然流畅最好。\\n',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067946,\n",
      " 'id': 'as-bxdt1ar9hb',\n",
      " 'model': 'deepseek-r1',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 165,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 131},\n",
      "           'prompt_tokens': 8,\n",
      "           'total_tokens': 173}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303550b9-95d6-4ec2-a114-432cbe79de9e",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9facdcd7-95e8-40d5-ab6c-38c8785db50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 模型推理过程 =====\n",
      "嗯，用户问“你是谁？”，这是一个常见的问题，可能他们想了解我的基本信息或者功能。首先，我需要保持回答简洁明了，但也要全面。用户可能是初次使用，所以应该详细介绍我的功能和用途，避免使用技术术语，让回答更易懂。同时，要强调我的限制，比如数据截止到2023年，不能联网等，这样可以管理用户的预期。另外，要保持友好和专业的语气，让用户感觉被重视。可能用户后续会有更具体的问题，所以最后可以邀请他们提出更多需求，促进互动。需要确保回答结构清晰，分点说明，但不要太机械，自然流畅最好。\n",
      "\n",
      "===== 模型回复 =====\n",
      "\n",
      "\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "# 获取推理思考过程（Reasoner特有字段）\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== 模型推理过程 =====\\n{reasoning_content}\")\n",
    "\n",
    "# 获取模型回复内容（与之前相同）\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== 模型回复 =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48cc16d-d179-417b-80a7-a4a70c550ccf",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06600d31-6f52-405d-ac22-674d5adc047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 8 tokens [缓存命中: 0 | 未命中: 8]\n",
      "输出: 165 tokens\n",
      "├─ 推理过程: 131 tokens\n",
      "└─ 最终回答: 34 tokens\n",
      "总消耗: 173 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0000 元\n",
      "输出成本: ￥0.0026 元\n",
      "预估总成本: ￥0.0027 元\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 推理模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 4元/百万 Tokens（缓存命中 1元/百万 Tokens）\n",
    "    - 输出: 16元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # 尝试获取推理过程详情\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # 尝试获取 reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # 仅在存在推理tokens数量字段时处理\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"├─ 推理过程: {reasoning} tokens\")\n",
    "            print(f\"└─ 最终回答: {final} tokens\")\n",
    "    \n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # 动态成本计算\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost_total:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost_total:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7306ffe-e8a6-495b-b93a-6c442b859150",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 字节火山引擎"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f4726-25bd-47e0-8076-c62dcc24915b",
   "metadata": {},
   "source": [
    "## 认识输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0d828-1ca6-4e60-9d63-3275e381a9a0",
   "metadata": {},
   "source": [
    "### DeepSeek-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99952546-851c-41df-8526-cd6fb0456fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"your-api-key\", # 1：替换成对应的 API_Key，可以使用环境变量而非明文填写，即 api_key=os.getenv(\"SILICONFLOW_API_KEY\")\n",
    "    base_url=\"https://ark.cn-beijing.volces.com/api/v3\" # 2：每个平台的 base_url 不同\n",
    ")\n",
    "\n",
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-v3-241226\", # 3：模型标识（model_id）可能存在差异\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18326f43-c920-4f80-b0b1-16feb9087bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '我是DeepSeek '\n",
      "                                     'Chat，一个由深度求索公司开发的智能助手，旨在通过自然语言处理和机器学习技术来提供信息查询、对话交流和解答问题等服务。如有任何疑问或需要帮助，请随时告诉我。',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067948,\n",
      " 'id': '0217390679463949666a785a9e88d5b0179ae9e4e1f0138c10560',\n",
      " 'model': 'deepseek-v3-241226',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 45,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 0},\n",
      "           'prompt_tokens': 11,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 56}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1acc6-a7ed-4d93-9c59-a371f17ee703",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "460539aa-b1a6-4562-ae68-2c6bdc1710fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是DeepSeek Chat，一个由深度求索公司开发的智能助手，旨在通过自然语言处理和机器学习技术来提供信息查询、对话交流和解答问题等服务。如有任何疑问或需要帮助，请随时告诉我。\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9caa83-5d62-4f8c-98da-07bce9ed76ad",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "637b7d02-343c-4193-8c3a-13d7c28ed53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 11 tokens [缓存命中: 0 | 未命中: 11]\n",
      "输出: 45 tokens\n",
      "总消耗: 56 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0000 元\n",
      "输出成本: ￥0.0004 元\n",
      "预估总成本: ￥0.0004 元\n"
     ]
    }
   ],
   "source": [
    "def print_chat_usage(completion, input_cost=2.0, output_cost=8.0, cache_hit_cost=0.5):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 聊天模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 2元/百万 Tokens（缓存命中 0.5元/百万 Tokens）\n",
    "\t- 输出: 8元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "\n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "\n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "\n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "\n",
    "    # 动态成本计算\n",
    "    input_cost = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_chat_usage(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7be81a-745f-468c-8e2b-84db9d9d47af",
   "metadata": {},
   "source": [
    "### DeepSeek-Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b323e6d-31f2-41d3-9606-1bade6780599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单轮对话示例\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1-250120\", # 3：换成推理模型\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80c8acac-05ea-46ac-bdf2-cde82ac18516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '\\n'\n",
      "                                     '\\n'\n",
      "                                     '您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。',\n",
      "                          'function_call': None,\n",
      "                          'reasoning_content': '好的，用户问我“你是谁？”，我需要用中文回答。首先，我应该介绍自己的身份，说明我是由DeepSeek开发的智能助手。接着，可以提到我的主要功能是提供信息、解答问题和协助完成任务。要保持回答简洁明了，符合用户的需求。可能用户想知道我的开发背景或者用途，所以需要涵盖这些方面。同时，要确保语气友好，让用户感到被帮助。然后，要检查有没有遗漏的重要信息，比如是否需要提到具体的服务范围或技术特点。最后，用自然的口语化表达，避免使用过于正式或复杂的句子结构，让用户更容易理解。\\n',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1739067957,\n",
      " 'id': '0217390679487739666a785a9e88d5b0179ae9e4e1f0138eb752d',\n",
      " 'model': 'deepseek-r1-250120',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 163,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 125},\n",
      "           'prompt_tokens': 13,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 176}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc2343-5945-4d3c-8cb5-05667c2acc06",
   "metadata": {},
   "source": [
    "#### 获取模型回复（choices）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a873452-370d-4e51-ae2c-a42c0536b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 模型推理过程 =====\n",
      "好的，用户问我“你是谁？”，我需要用中文回答。首先，我应该介绍自己的身份，说明我是由DeepSeek开发的智能助手。接着，可以提到我的主要功能是提供信息、解答问题和协助完成任务。要保持回答简洁明了，符合用户的需求。可能用户想知道我的开发背景或者用途，所以需要涵盖这些方面。同时，要确保语气友好，让用户感到被帮助。然后，要检查有没有遗漏的重要信息，比如是否需要提到具体的服务范围或技术特点。最后，用自然的口语化表达，避免使用过于正式或复杂的句子结构，让用户更容易理解。\n",
      "\n",
      "===== 模型回复 =====\n",
      "\n",
      "\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "# 获取推理思考过程（Reasoner特有字段）\n",
    "reasoning_content = completion.choices[0].message.reasoning_content\n",
    "print(f\"===== 模型推理过程 =====\\n{reasoning_content}\")\n",
    "\n",
    "# 获取模型回复内容（与之前相同）\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"===== 模型回复 =====\\n{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08821e68-c3b7-4e28-b83f-3f9961102704",
   "metadata": {},
   "source": [
    "#### 获取用量信息（usage）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19d1ff7d-c761-41af-bd52-f0615c048138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TOKEN 消耗明细 =====\n",
      "输入: 13 tokens [缓存命中: 0 | 未命中: 13]\n",
      "输出: 163 tokens\n",
      "├─ 推理过程: 125 tokens\n",
      "└─ 最终回答: 38 tokens\n",
      "总消耗: 176 tokens\n",
      "\n",
      "===== 成本明细 =====\n",
      "输入成本: ￥0.0001 元\n",
      "输出成本: ￥0.0026 元\n",
      "预估总成本: ￥0.0027 元\n"
     ]
    }
   ],
   "source": [
    "def print_reasoner_usage(completion, input_cost=4.0, output_cost=16.0, cache_hit_cost=1.0):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - input_cost: 输入价格（元/百万 Tokens）\n",
    "    - output_cost: 输出价格（元/百万 Tokens）\n",
    "    - cache_hit_cost: 缓存命中价格（当平台不支持时自动退化到全价模式）\n",
    "\n",
    "    按 DeepSeek 推理模型定价设定默认成本（单位：元）：\n",
    "    - 输入: 4元/百万 Tokens（缓存命中 1元/百万 Tokens）\n",
    "    - 输出: 16元/百万 Tokens\n",
    "    官方价格文档：https://api-docs.deepseek.com/zh-cn/quick_start/pricing/\n",
    "    \"\"\"\n",
    "    stats = completion.usage\n",
    "    \n",
    "    # 尝试获取字段（兼容其他平台）\n",
    "    hit = getattr(stats, 'prompt_cache_hit_tokens', 0)\n",
    "    miss = getattr(stats, 'prompt_cache_miss_tokens', \n",
    "                  stats.prompt_tokens - hit if hasattr(stats, 'prompt_tokens') else 0)\n",
    "    \n",
    "    print(f\"===== TOKEN 消耗明细 =====\")\n",
    "    # 仅在存在缓存机制时显示细节\n",
    "    if hit + miss > 0:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens [缓存命中: {hit} | 未命中: {miss}]\")\n",
    "    else:\n",
    "        print(f\"输入: {stats.prompt_tokens} tokens\")\n",
    "    \n",
    "    print(f\"输出: {stats.completion_tokens} tokens\")\n",
    "\n",
    "    # 尝试获取推理过程详情\n",
    "    details = getattr(stats, 'completion_tokens_details', None)\n",
    "    reasoning = 0\n",
    "    if details:\n",
    "        if not isinstance(details, dict):\n",
    "            details = getattr(details, 'dict', lambda: {})()\n",
    "        # 尝试获取 reasoning_tokens\n",
    "        reasoning = details.get('reasoning_tokens', 0)\n",
    "        \n",
    "        # 仅在存在推理tokens数量字段时处理\n",
    "        if reasoning > 0:\n",
    "            final = stats.completion_tokens - reasoning\n",
    "            print(f\"├─ 推理过程: {reasoning} tokens\")\n",
    "            print(f\"└─ 最终回答: {final} tokens\")\n",
    "    \n",
    "    print(f\"总消耗: {stats.total_tokens} tokens\")\n",
    "    \n",
    "    # 动态成本计算\n",
    "    input_cost_total = (hit * cache_hit_cost + miss * input_cost) / 1_000_000\n",
    "    output_cost_total = stats.completion_tokens * output_cost / 1_000_000\n",
    "    total_cost = input_cost_total + output_cost_total\n",
    "    \n",
    "    print(f\"\\n===== 成本明细 =====\")\n",
    "    print(f\"输入成本: ￥{input_cost_total:.4f} 元\")\n",
    "    print(f\"输出成本: ￥{output_cost_total:.4f} 元\")\n",
    "    print(f\"预估总成本: ￥{total_cost:.4f} 元\")\n",
    "\n",
    "print_reasoner_usage(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}