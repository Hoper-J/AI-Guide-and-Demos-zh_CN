# è¿›é˜¶æŒ‡å—ï¼šè‡ªå®šä¹‰ Prompt æå‡å¤§æ¨¡å‹è§£é¢˜èƒ½åŠ›

> æ€ä¹ˆåˆ¤æ–­ Prompt çš„å¥½åï¼Ÿä»€ä¹ˆé—®é¢˜å­˜åœ¨æ ‡å‡†ç­”æ¡ˆï¼Ÿ
>
> ç­”ï¼šè®©å¤§æ¨¡å‹æ±‚è§£æ•°å­¦é—®é¢˜ã€‚
>
> æå®æ¯…è€å¸ˆçš„ [HW4](https://www.bilibili.com/video/BV1BJ4m1e7g8?p=15&vd_source=436107f586d66ab4fcf756c76eb96c35) æ­£å¥½æåˆ°äº†æœ‰å…³æ•°å­¦é—®é¢˜çš„ Promptï¼Œæ‰€ä»¥æˆ‘å†³å®šä¸­é—´æ’ä¸€ç¯‡è¿™æ ·çš„æ–‡ç« ã€‚é€šè¿‡æœ¬æ–‡ä½ å°†ï¼š
>
> 1. äº†è§£å„ç§ Prompt å¦‚ä½•å½±å“å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚
> 2. è®¾è®¡ Prompt æé«˜å¤§æ¨¡å‹è§£å†³æ•°å­¦é—®é¢˜çš„æ­£ç¡®æ€§ã€‚
> 3. äº†è§£å ä½ç¬¦çš„ä½¿ç”¨ 
> 4. äº†è§£å¦‚ä½•ä½¿ç”¨ ipywidgets åˆ›å»ºäº¤äº’æ¨¡å—ã€‚
>
> å¦‚æœä½ å¯ä»¥è®¿é—® Geminiï¼Œå¯ä»¥åœ¨ [Google AI Studio](https://aistudio.google.com/app/apikey?hl=zh-cn) ä¸­éå¸¸å¿«é€Ÿçš„è·å– Gemini APIï¼Œä»è€Œåœ¨ Colab ä¸Šè¿›è¡Œå­¦ä¹ ï¼š[HW4 - Colab](https://colab.research.google.com/drive/16JzVN_Mu4mJfyHQpQEuDx1q6jI-cAnEl?hl=zh-tw#scrollTo=ZvU3-01m3wmy&uniqifier=1)ã€‚å› ä¸ºå›½å®¶æ”¿ç­–åŸå› ï¼Œè¿™é‡Œä¸ä¼šæä¾›ğŸªœçš„æ•™ç¨‹ï¼Œä½†æœ¬æ–‡ä¼šæ ¹æ® HW4 çš„å®Œæ•´å†…å®¹è¿›è¡Œç»„ç»‡ï¼Œå¹¶å°† Colab ä¸­çš„ @param ä½¿ç”¨ ipywidgets è¿›è¡Œæ›¿ä»£ï¼Œæä¾›ä¸€ä¸ªå¤§é™†ç‰ˆæœ¬çš„ä¸­æ–‡ä½œä¸šé•œåƒã€‚
>
> æ³¨æ„ï¼Œå°½ç®¡æ–‡ç« æåˆ°äº†**ä½œä¸š**ï¼Œä½†å¹¶ä¸æ„å‘³ç€éœ€è¦è§†é¢‘åŸºç¡€ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå­¦ä¹ ï¼Œè¿™æ²¡æœ‰é—¨æ§›ã€‚
>
> æ¨èè§‚çœ‹è§†é¢‘ï¼š[è®­ç»ƒä¸äº†äººå·¥æ™ºèƒ½ï¼Ÿä½ å¯ä»¥è®­ç»ƒä½ è‡ªå·±](https://www.bilibili.com/video/BV1BJ4m1e7g8?p=6)
>![0301_prompt_part1](./assets/0301_prompt_part1.jpg)
> 
> [ä»£ç æ–‡ä»¶ä¸‹è½½](../Demos/03.%20è‡ªå®šä¹‰%20Prompt%20æå‡å¤§æ¨¡å‹è§£é¢˜èƒ½åŠ›â€”â€”Gradio%20ä¸%20ipywidgets%20ç‰ˆ.ipynb)
>
> åœ¨çº¿é“¾æ¥ï¼š[Kaggle](https://www.kaggle.com/code/aidemos/03-prompt-ipywidgets) | [Colab](https://colab.research.google.com/drive/1c5WH62n8P1fKWaVrqXRV5pfRWKqV_3Zs?usp=sharing)

## ç›®å½•

- [ä¸‹è½½ï¼Œå¯¼å…¥å’Œé…ç½®](#ä¸‹è½½å¯¼å…¥å’Œé…ç½®)
  
  - [åˆå§‹åŒ– OpenAI æ¨¡å‹](#åˆå§‹åŒ–-openai-æ¨¡å‹)
  - [ç”¨äºè¯„ä¼° Prompt çš„æ•°å­¦é—®é¢˜](#ç”¨äºè¯„ä¼°-prompt-çš„æ•°å­¦é—®é¢˜)
- [ğŸ§™ åˆ›å»ºä½ çš„è‡ªå®šä¹‰ Promptï¼ˆGradio ç‰ˆæœ¬ï¼‰](#-åˆ›å»ºä½ çš„è‡ªå®šä¹‰-promptgradio-ç‰ˆæœ¬)

  -  [äº¤äº’ç•Œé¢](#äº¤äº’ç•Œé¢)

  - [è®¾è®¡ Prompt è§£å†³æ•°å­¦é—®é¢˜](#è®¾è®¡-prompt-è§£å†³æ•°å­¦é—®é¢˜)

- [ğŸ§™ åˆ›å»ºä½ çš„è‡ªå®šä¹‰ Promptï¼ˆé Gradio ç‰ˆæœ¬ï¼‰](#-åˆ›å»ºä½ çš„è‡ªå®šä¹‰-prompté-gradio-ç‰ˆæœ¬)

  - [å¯¼å…¥](#å¯¼å…¥)
  - [è‡ªå®šä¹‰ Prompt](#è‡ªå®šä¹‰-prompt)
    - [åˆ›å»ºä¸‹æ‹‰é€‰é¡¹é€‰æ‹©é—®é¢˜](#åˆ›å»ºä¸‹æ‹‰é€‰é¡¹é€‰æ‹©é—®é¢˜)
  - [è¯„ä¼°](#è¯„ä¼°)
    - [åˆ›å»ºæ»‘å—é€‰æ‹©è¯„ä¼°çš„æ•°é‡](#åˆ›å»ºæ»‘å—é€‰æ‹©è¯„ä¼°çš„æ•°é‡)
  - [æ‰“å°æŒ‡å®šçš„è¯„ä¼°ç»“æœ](#æ‰“å°æŒ‡å®šçš„è¯„ä¼°ç»“æœ)
  - [ä¿å­˜ä½ çš„ Propmt](#ä¿å­˜ä½ çš„-propmt)

- [å‚è€ƒé“¾æ¥](#å‚è€ƒé“¾æ¥)

---

## ä¸‹è½½ï¼Œå¯¼å…¥å’Œé…ç½®

```bash
pip install tqdm
pip install jinja2
pip install gradio
pip install tiktoken
pip install openai
```

```python
import os
import time
import re
import pickle
import json
import traceback

import openai
import tiktoken  # ç”¨äº prompt_token_num()
import jinja2
from tqdm import tqdm
```

å¡«å……ä½ çš„`API`å¹¶è¿è¡Œä»£ç ï¼š

```python
# TODO: è®¾ç½®ä½ çš„ OPENAI API å¯†é’¥ï¼Œè¿™é‡Œå‡è®¾ DashScope API è¢«é…ç½®åœ¨äº† OPENAI_API_KEY ç¯å¢ƒå˜é‡ä¸­
OPENAI_API_KEY = ""
# ä¸å¡«å†™åˆ™é»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼Œä½¿ç”¨é˜¿é‡Œäº‘ DashScope API
client = openai.OpenAI(
    api_key=OPENAI_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",  # é˜¿é‡Œäº‘çš„ API åœ°å€
)

# æ£€æŸ¥ API è®¾ç½®æ˜¯å¦æ­£ç¡®
try:
    response = client.chat.completions.create(
        model="qwen-turbo",  # ä½¿ç”¨é€šä¹‰åƒé—®-Turbo å¤§æ¨¡å‹ï¼Œå¯ä»¥æ›¿æ¢ä¸º Deepseek ç³»åˆ—ï¼šdeepseek-v3 / deepseek-r1
        messages=[{'role': 'user', 'content': "æµ‹è¯•"}],
        max_tokens=1,
    )
    print("API è®¾ç½®æˆåŠŸï¼ï¼")
except Exception as e:
    print(f"API å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š{e}")
```

### åˆå§‹åŒ– OpenAI æ¨¡å‹

å¦‚æœä¸“æ³¨äº Promptï¼Œå¯ä»¥æš‚æ—¶è·³è¿‡è¿™éƒ¨åˆ†çš„ç†è§£ï¼Œå…ˆè¿è¡Œä»£ç ã€‚

```python
class OpenAIModel:
    """
    å°è£…OpenAI APIè°ƒç”¨å’Œç¼“å­˜æœºåˆ¶çš„ç±»ã€‚
    
    ç”¨äºè°ƒç”¨OpenAI APIï¼Œå¤„ç†å“åº”ï¼Œå¹¶ç¼“å­˜ç»“æœä»¥æé«˜æ•ˆç‡ã€‚
    
    å±æ€§:
        cache_file (str): ç¼“å­˜æ–‡ä»¶çš„è·¯å¾„
        cache_dict (dict): å†…å­˜ä¸­çš„ç¼“å­˜å­—å…¸
    """
    
    def __init__(self, cache_file="openai_cache"):
        """
        åˆå§‹åŒ–OpenAIæ¨¡å‹å¯¹è±¡ï¼Œè®¾ç½®ç¼“å­˜æ–‡ä»¶è·¯å¾„å¹¶åŠ è½½ç¼“å­˜ã€‚
        
        å‚æ•°:
            cache_file (str): ç¼“å­˜æ–‡ä»¶çš„è·¯å¾„ï¼Œé»˜è®¤ä¸º"openai_cache"
        """
        self.cache_file = cache_file
        self.cache_dict = self.load_cache()  # åŠ è½½ç¼“å­˜

    def save_cache(self):
        """
        å°†å½“å‰ç¼“å­˜ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚
        """
        with open(self.cache_file, "wb") as f:
            pickle.dump(self.cache_dict, f)

    def load_cache(self, allow_retry=True):
        """
        ä»æ–‡ä»¶åŠ è½½ç¼“å­˜ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶ã€‚
        
        å‚æ•°:
            allow_retry (bool): æ˜¯å¦å…è®¸é‡è¯•åŠ è½½ç¼“å­˜ï¼Œé»˜è®¤ä¸ºTrue
            
        è¿”å›:
            dict: åŠ è½½çš„ç¼“å­˜å­—å…¸ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—å…¸
        """
        if os.path.exists(self.cache_file):
            while True:
                try:
                    with open(self.cache_file, "rb") as f:
                        cache = pickle.load(f)
                    break
                except Exception:
                    if not allow_retry:
                        assert False
                    print("Pickle Error: 5ç§’åé‡è¯•...")
                    time.sleep(5)
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ç¼“å­˜
            cache = {}
        return cache

    def set_cache_file(self, file_name):
        """
        è®¾ç½®ç¼“å­˜æ–‡ä»¶åå¹¶é‡æ–°åŠ è½½ç¼“å­˜ã€‚
        
        å‚æ•°:
            file_name (str): æ–°çš„ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        self.cache_file = file_name
        self.cache_dict = self.load_cache()

    def get_response(self, content):
        """
        è·å–æ¨¡å‹å®Œæˆçš„æ–‡æœ¬ï¼Œå…ˆæ£€æŸ¥ç¼“å­˜ï¼Œè‹¥æ— åˆ™è¯·æ±‚ç”Ÿæˆã€‚
        
        å‚æ•°:
            content (str): æä¾›ç»™æ¨¡å‹çš„è¾“å…¥å†…å®¹
            
        è¿”å›:
            str: æ¨¡å‹ç”Ÿæˆçš„å›å¤æ–‡æœ¬ï¼Œå¦‚æœå‡ºé”™åˆ™è¿”å›None
        """
        # å¦‚æœé€‰æ‹©æ£€æŸ¥ç¼“å­˜ï¼Œåˆ™ä¼šå¯¼è‡´åŒé—®é¢˜ä¸åŒtrialçš„ç»“æœç›¸åŒï¼Œè¿™ä¸å®é™…æƒ³è¡¨è¾¾çš„å†…å®¹ä¸ç¬¦ï¼Œæ•…æ³¨é‡Š
        # if content in self.cache_dict:
        #     return self.cache_dict[content]
        for _ in range(3):  # å°è¯•ä¸‰æ¬¡
            try:
                # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå†…å®¹
                response = client.chat.completions.create(
                    model="qwen-turbo",
                    messages=[{"role": "user", "content": content}],
                    temperature=1.0,
                )
                completion = response.choices[0].message.content
                self.cache_dict[content] = completion
                return completion
            except Exception as e:
                print(e, "\n")
                time.sleep(1)
        return None

    def is_valid_key(self):
        """
        æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆã€‚
        
        è¿”å›:
            bool: å¦‚æœAPIå¯†é’¥æœ‰æ•ˆåˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        for _ in range(4):  # å°è¯•å››æ¬¡
            try:
                response = client.chat.completions.create(
                    model="qwen-turbo",
                    messages=[{"role": "user", "content": "hi there"}],
                    temperature=1.0,
                    max_tokens=1
                )
                return True
            except Exception as e:
                traceback.print_exc()
                time.sleep(1)
        return False

    def prompt_token_num(self, prompt):
        """
        è®¡ç®—promptçš„tokenæ•°é‡ã€‚
        
        å‚æ•°:
            prompt (str): è¦è®¡ç®—tokenæ•°é‡çš„prompt
            
        è¿”å›:
            int: tokençš„æ•°é‡
        """
        try:
            # ä½¿ç”¨ gpt-3.5-turbo çš„ç¼–ç å™¨ï¼Œå› ä¸º tiktoken åº“ä¸æ”¯æŒè‡ªåŠ¨è¯†åˆ« qwen-turbo æ¨¡å‹
            encoding = tiktoken.get_encoding("cl100k_base")  # è¿™æ˜¯ GPT-3.5-turbo æ‰€ä½¿ç”¨çš„ç¼–ç å™¨
            # å°† prompt ç¼–ç æˆ tokenï¼Œå¹¶è¿”å› token æ•°é‡
            tokens = encoding.encode(prompt)
            return len(tokens)
        except Exception as e:
            print(f"è®¡ç®— token æ•°é‡æ—¶å‡ºé”™: {e}")
            return 0

    def two_stage_completion(self, question, content):
        """
        ä¸¤é˜¶æ®µå®Œæˆï¼šé¦–å…ˆè·å–æ¨ç†ï¼ˆæ³¨æ„ï¼Œè¿™é‡Œå¹¶éæ¨ç†æ¨¡å‹çš„æ€ç»´é“¾ï¼Œè€Œæ˜¯ç›´æ¥è¾“å…¥ content åå¾—åˆ°çš„å›å¤ï¼‰ï¼Œå†è·å–æœ€ç»ˆç­”æ¡ˆã€‚
        
        å‚æ•°:
            question (str): åŸå§‹é—®é¢˜
            content (str): æä¾›ç»™æ¨¡å‹çš„è¾“å…¥å†…å®¹
            
        è¿”å›:
            dict: åŒ…å«promptã€æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆçš„å­—å…¸
        """
        rationale = self.get_response(content)
        if not rationale:
            return {
                "prompt": content,
                "rationale": None,
                "answer": None
            }

        ans = self.get_response(content=f"Q:{question}\nA:{rationale}\nThe answer to the original question is (a number only): ")
        return {
            "prompt": content,
            "rationale": rationale,
            "answer": ans
        }

# åˆå§‹åŒ–æ¨¡å‹
my_model = OpenAIModel()
```

### ç”¨äºè¯„ä¼° Prompt çš„æ•°å­¦é—®é¢˜

```python
questions = [
    'ä¸€ä½è‰ºæœ¯å®¶æ­£åœ¨ä½¿ç”¨æ–¹å½¢ç“·ç –åˆ›å»ºä¸€ä¸ªå¤§å‹é©¬èµ›å…‹ã€‚é©¬èµ›å…‹æœ¬èº«è®¾è®¡æˆä¸€ä¸ªæ­£æ–¹å½¢ï¼Œå¹¶ä¸”åŒ…å«çš„è“è‰²ç“·ç –æ•°é‡æ°å¥½æ˜¯çº¢è‰²ç“·ç –çš„3å€ã€‚å¦‚æœè‰ºæœ¯å®¶åªæœ‰57å—çº¢è‰²ç“·ç –ï¼Œé‚£ä¹ˆè¦å®Œæˆæ•´ä¸ªé©¬èµ›å…‹å…±éœ€è¦å¤šå°‘å—ç“·ç –ï¼Ÿ',
    'ä¸€ä½å†œæ°‘æ­£åœ¨ä¸ºå½“åœ°å¸‚åœºè£…è‹¹æœã€‚ä»–æœ‰120ä¸ªè‹¹æœï¼Œå¹¶å¸Œæœ›å°†å®ƒä»¬å‡åŒ€åˆ†é…åˆ°ç¯®å­ä¸­ã€‚å¦‚æœä»–å†³å®šç•™15ä¸ªè‹¹æœç»™å®¶äººï¼Œæ¯ä¸ªç¯®å­æœ€å¤šèƒ½è£…7ä¸ªè‹¹æœï¼Œé‚£ä¹ˆä»–æœ€å°‘éœ€è¦å¤šå°‘ä¸ªç¯®å­æ‰èƒ½å°†è‹¹æœå¸¦åˆ°å¸‚åœºï¼Ÿ',
    'ä¸€ä¸ªèŠ±å›­æœ‰çŸ©å½¢çš„åœ°å—ï¼Œè¿™äº›åœ°å—æ’åˆ—æˆä¸€æ¡ç›´çº¿ï¼Œæ¯å—åœ°ä¸æ­£å¥½ä¸¤å—å…¶ä»–çš„åœ°å…±ç”¨è¾¹ç•Œã€‚å…±æœ‰5å—åœ°ã€‚ä¸­é—´çš„æ¯å—åœ°é¢ç§¯ä¸º24å¹³æ–¹ç±³ï¼Œåœ°å—çš„å®½åº¦ä¸º4ç±³ï¼Œæ‰€æœ‰åœ°å—çš„å®½åº¦ä¿æŒä¸å˜ã€‚ç¬¬ä¸€å—åœ°çš„é•¿åº¦æ˜¯ä¸­é—´åœ°å—çš„ä¸¤å€ï¼Œæœ€åä¸€å—åœ°çš„é•¿åº¦æ˜¯ä¸­é—´åœ°å—çš„ä¸€åŠã€‚é‚£ä¹ˆæ‰€æœ‰åœ°å—çš„æ€»é¢ç§¯æ˜¯å¤šå°‘å¹³æ–¹ç±³ï¼Ÿ',
    'ä¸€ä¸ªå†œè´¸å¸‚åœºå‡ºå”®ä¸¤ç§ç±»å‹çš„è‹¹æœæ··åˆè¢‹ï¼šAå‹è¢‹å­åŒ…å«4ä¸ªçº¢è‹¹æœå’Œ6ä¸ªç»¿è‹¹æœï¼ŒBå‹è¢‹å­åŒ…å«8ä¸ªçº¢è‹¹æœå’Œ4ä¸ªç»¿è‹¹æœã€‚ä¸€ä½é¡¾å®¢è´­ä¹°äº†ä¸€è¢‹Aå‹å’Œä¸€è¢‹Bå‹çš„è‹¹æœã€‚å¦‚æœä»è¿™ä¸¤è¢‹è‹¹æœä¸­éšæœºæŒ‘é€‰ä¸€ä¸ªè‹¹æœï¼Œé€‰åˆ°ç»¿è‹¹æœçš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿè¯·å°†ç­”æ¡ˆä¿ç•™åˆ°å°æ•°ç‚¹åä¸¤ä½ã€‚',
    'ä¸€ä½å›­ä¸æŒ‰ç…§ä¸¤æœµçº¢è‰²èŠ±è·Ÿç€ä¸€æœµé»„è‰²èŠ±çš„æ¨¡å¼ç§èŠ±ã€‚å¦‚æœå›­ä¸æƒ³ä¿æŒè¿™ç§æ¨¡å¼ï¼Œå¹¶ä¸”æœ‰35ä¸ªè¿ç»­çš„ç©ºä½æ¥ç§èŠ±ï¼Œé‚£ä¹ˆå›­ä¸ä¼šç§å¤šå°‘æœµçº¢è‰²èŠ±ï¼Ÿ',
    'æ°æ£®æ­£åœ¨ä¸ºé©¬æ‹‰æ¾è®­ç»ƒï¼Œä»–æ¯å¤©è·‘å›ºå®šçš„è·ç¦»ã€‚æ˜ŸæœŸä¸€ï¼Œä»–è·‘äº†5è‹±é‡Œã€‚ä¹‹åçš„æ¯ä¸€å¤©ï¼Œä»–å°†è·‘æ­¥è·ç¦»å¢åŠ 10%ã€‚å¦‚æœæ°æ£®æŒ‰ç…§è¿™ä¸ªæ¨¡å¼ç»§ç»­è·‘æ­¥ï¼Œé‚£ä¹ˆä»–åœ¨æ˜ŸæœŸäº”å°†è·‘å¤šå°‘è‹±é‡Œï¼Ÿ',
    'åœ¨ä¸€ä¸ªä¸‰è§’å½¢çš„èŠ±å›è¾¹ä¸Šï¼Œæ¯æ¡è¾¹ä¸Šæœ‰16æ£µæ¤ç‰©ã€‚æ¯æ£µæ¤ç‰©éƒ½éœ€è¦ä¸€ä¸ªåŠå¾„ä¸º0.5ç±³çš„åœ†å½¢ç©ºé—´æ‰èƒ½æ­£å¸¸ç”Ÿé•¿ã€‚å‡è®¾æ¤ç‰©ç´§æŒ¨ç€æ’åˆ—ï¼Œå¹¶ä¸”æ²¿ç€ä¸‰è§’å½¢èŠ±å›çš„è¾¹æ’æˆä¸€æ¡ç›´çº¿ï¼Œé‚£ä¹ˆæ¯æ¡è¾¹ä¸Šç§æ¤ç‰©çš„çº¿æ€§è·ç¦»æ˜¯å¤šå°‘ç±³ï¼Ÿ',
    'å¨å°”é€Šåšå£«æ­£åœ¨è®¾è®¡ä¸€ä¸ªå‡ ä½•èŠ±å›­ï¼ŒèŠ±å›­ä¸­çš„èŠ±æœµå›´ç»•ç€ä¸­å¤®çš„å–·æ³‰æ’åˆ—æˆåŒå¿ƒåœ†ã€‚æ¯ä¸€åœˆæ¯”é‡Œé¢ä¸€åœˆå¤š6æœµèŠ±ï¼Œå½¢æˆä¸€ä¸ªå…­è¾¹å½¢çš„å›¾æ¡ˆã€‚æœ€é‡Œé¢ä¸€åœˆæœ‰6æœµèŠ±ã€‚å¦‚æœå¨å°”é€Šåšå£«ç§è¶³å¤Ÿçš„èŠ±ï¼Œå½¢æˆ15åœˆï¼ˆåŒ…æ‹¬æœ€é‡Œé¢ä¸€åœˆï¼‰ï¼Œé‚£ä¹ˆè¿™ä¸ªèŠ±å›­æ€»å…±éœ€è¦å¤šå°‘æœµèŠ±ï¼Ÿ',
    'ä¸€ä¸ªå°å›¾ä¹¦é¦†æ­£åœ¨é‡æ–°æ•´ç†ä¹¦ç±æ”¶è—ã€‚ä»–ä»¬æ€»å…±æœ‰120æœ¬ä¹¦ï¼Œè®¡åˆ’å¹³å‡åˆ†é…åˆ°5ä¸ªä¹¦æ¶ä¸Šã€‚æœ€ä¸Šé¢çš„ä¹¦æ¶åªèƒ½æ‰¿å—ç›¸å½“äºæœ€ä¸‹é¢ä¹¦æ¶ä¸€åŠé‡é‡çš„ä¹¦ã€‚å¦‚æœæœ€ä¸Šé¢çš„ä¹¦æ¶æ‰¿è½½15ç£…çš„ä¹¦ï¼Œè€Œå…¶ä»–ä¹¦æ¶æ¯ä¸ªèƒ½æ‰¿è½½ä¸¤å€çš„é‡é‡ï¼Œé‚£ä¹ˆæœ€ä¸‹é¢çš„ä¹¦æ¶èƒ½æ‰¿è½½å¤šå°‘ç£…çš„ä¹¦ï¼Ÿ',
    'ä¸€ä»½é¥¼å¹²çš„é…æ–¹éœ€è¦3æ¯é¢ç²‰ã€2æ¯ç³–å’Œ1æ¯å·§å…‹åŠ›ç‰‡ã€‚å¦‚æœé©¬å…‹æƒ³è¦åšä¸‰å€é‡çš„é¥¼å¹²ï¼Œä½†åªæœ‰4æ¯ç³–ï¼Œé‚£ä¹ˆä»–è¿˜éœ€è¦å¤šå°‘æ¯ç³–ï¼Ÿ',
    'ä¸€å®¶å® ç‰©åº—çš„åº—ä¸»æ­£åœ¨åˆ¶ä½œå®šåˆ¶é¸Ÿèˆã€‚æ¯ä¸ªé¸Ÿèˆå¤–éƒ¨éœ€è¦0.75å‡æœ¨ææ¸…æ¼†ã€‚å¦‚æœåº—ä¸»æœ‰ä¸€ç½10å‡çš„æœ¨ææ¸…æ¼†ï¼Œé‚£ä¹ˆä»–åœ¨éœ€è¦æ›´å¤šæ¸…æ¼†ä¹‹å‰æœ€å¤šå¯ä»¥åˆ¶ä½œå¤šå°‘ä¸ªé¸Ÿèˆï¼Ÿ',
    'ä¸€ä¸ªå†œåœºæœ‰é¸¡å’Œç‰›ã€‚æ€»å…±æœ‰30ä¸ªå¤´ï¼Œ88æ¡è…¿ã€‚å†œåœºä¸Šæœ‰å¤šå°‘å¤´ç‰›ï¼Ÿ',
    'ä¸€ä¸ªåœ°æ–¹å›¾ä¹¦é¦†æ­£åœ¨ç»„ç»‡ä¸€åœºæ—§ä¹¦ä¹‰å–ä¼šï¼Œä»¥ç­¹é›†èµ„é‡‘è´­ä¹°æ–°ä¹¦ã€‚ä»–ä»¬ä»¥æ¯æœ¬2ç¾å…ƒçš„ä»·æ ¼å–å‡º120æœ¬å„¿ç«¥ä¹¦ï¼Œä»¥æ¯æœ¬3ç¾å…ƒçš„ä»·æ ¼å–å‡º75æœ¬å°è¯´ï¼Œå¹¶ä»¥æ¯æœ¬1.50ç¾å…ƒçš„ä»·æ ¼å–å‡ºäº†å°è¯´ä¸¤å€æ•°é‡çš„æ‚å¿—ã€‚ä»–ä»¬è¿˜ä»¥æ¯æœ¬0.50ç¾å…ƒçš„ä»·æ ¼å–å‡ºä¸ä¹¦ç±å’Œæ‚å¿—æ€»æ•°ç›¸ç­‰çš„ä¹¦ç­¾ã€‚é‚£ä¹ˆå›¾ä¹¦é¦†æ€»å…±ç­¹é›†äº†å¤šå°‘é’±ï¼Ÿ',
    'ä¸€ä¸ªå½“åœ°çš„å†œæ°‘æ­£åœ¨ä¸ºå¸‚åœºå‡†å¤‡æ··åˆæ°´æœç¯®ï¼Œæ¯ä¸ªç¯®å­åŒ…å«3ä¸ªè‹¹æœã€5ä¸ªæ©™å­å’Œ2ä¸ªé¦™è•‰ã€‚è‹¹æœçš„ä»·æ ¼æ˜¯æ¯ä¸ª0.50ç¾å…ƒï¼Œæ©™å­æ¯ä¸ª0.30ç¾å…ƒï¼Œé¦™è•‰æ¯ä¸ª0.25ç¾å…ƒã€‚å¦‚æœå†œæ°‘ä¸ºå½“åœ°å¸‚åœºå‡†å¤‡äº†120ä¸ªç¯®å­ï¼Œå¹¶ä»¥æ¯ä¸ª5.00ç¾å…ƒçš„ä»·æ ¼å‡ºå”®æ¯ä¸ªç¯®å­ï¼Œé‚£ä¹ˆå–å®Œæ‰€æœ‰ç¯®å­åï¼Œå†œæ°‘å°†è·å¾—å¤šå°‘åˆ©æ¶¦ï¼Ÿ',
    'ç›ä¸½äºšæœ‰24ä¸ªè‹¹æœï¼Œæƒ³å°†å®ƒä»¬å‡åŒ€åˆ†ç»™å¥¹çš„6ä¸ªæœ‹å‹ã€‚å¦‚æœæ¯ä¸ªæœ‹å‹è¿˜è¦å†ç»™è€å¸ˆ2ä¸ªè‹¹æœï¼Œé‚£ä¹ˆæ¯ä¸ªæœ‹å‹å‰©ä¸‹å¤šå°‘è‹¹æœï¼Ÿ',
    'è‰æ‹‰æ­£åœ¨è®¡åˆ’ä¸€ä¸ªèŠ±å›­ï¼Œæƒ³è¦ç§ä¸‰ç§èŠ±ï¼šé›èŠã€éƒé‡‘é¦™å’Œç«ç‘°ã€‚å¥¹æƒ³è¦çš„é›èŠæ•°é‡æ˜¯éƒé‡‘é¦™çš„ä¸¤å€ï¼Œéƒé‡‘é¦™çš„æ•°é‡æ˜¯ç«ç‘°çš„ä¸‰å€ã€‚å¦‚æœå¥¹æ€»å…±è¦ç§60æœµèŠ±ï¼Œé‚£ä¹ˆå¥¹è®¡åˆ’ç§å¤šå°‘æœµç«ç‘°ï¼Ÿ',
    'ä¸€ä¸ªèŠ±å›­æœ‰ä¸‰ç§å¼€èŠ±æ¤ç‰©ã€‚ç¬¬ä¸€ç§æ¯æ ªæœ‰12æœµèŠ±ï¼Œç¬¬äºŒç§æ¯æ ªæœ‰8æœµèŠ±ï¼Œç¬¬ä¸‰ç§æ¯æ ªæœ‰15æœµèŠ±ã€‚å¦‚æœç¬¬ä¸€ç§æ¤ç‰©çš„æ•°é‡æ˜¯ç¬¬äºŒç§æ¤ç‰©çš„ä¸¤å€ï¼Œç¬¬ä¸‰ç§æ¤ç‰©çš„æ•°é‡æ˜¯ç¬¬ä¸€ç§æ¤ç‰©çš„ä¸€åŠï¼Œå¹¶ä¸”èŠ±å›­ä¸­æœ‰16æ ªç¬¬äºŒç§æ¤ç‰©ï¼Œé‚£ä¹ˆèŠ±å›­é‡Œä¸€å…±æœ‰å¤šå°‘æœµèŠ±ï¼Ÿ',
    'åœ¨ä¸€ä¸ªæ£‹ç›˜æ¸¸æˆä¸­ï¼Œä»ä¸€ä¸ªæ–¹æ ¼è½¬ç§»åˆ°å¦ä¸€ä¸ªæ–¹æ ¼çš„è´¹ç”¨æ˜¯ä½ è¦è½åœ¨çš„æ–¹æ ¼å·ç çš„ç¡¬å¸æ•°ã€‚ç¬¬ä¸€ä¸ªæ–¹æ ¼æ˜¯1å·ï¼Œç¬¬äºŒä¸ªæ–¹æ ¼æ˜¯2å·ï¼Œä»¥æ­¤ç±»æ¨ã€‚å¦‚æœä¸€ä¸ªç©å®¶ä»5å·æ–¹æ ¼ç§»åŠ¨åˆ°9å·æ–¹æ ¼ï¼Œå†åˆ°14å·æ–¹æ ¼ï¼Œæœ€ååˆ°20å·æ–¹æ ¼ï¼Œä»–æ€»å…±èŠ±è´¹äº†å¤šå°‘æšç¡¬å¸ï¼Ÿ',
    'ä¸€ä¸ªæ™¯è§‚å…¬å¸åœ¨ä¸¤ä¸ªå…¬å›­ç§æ¤æ ‘æœ¨ã€‚åœ¨Aå…¬å›­ï¼Œä»–ä»¬ç§äº†5æ’ï¼Œæ¯æ’6æ£µæ ‘ã€‚åœ¨Bå…¬å›­ï¼Œä»–ä»¬ç§äº†3æ’ï¼Œæ¯æ’7æ£µæ ‘ã€‚ç„¶è€Œï¼ŒBå…¬å›­çš„4æ£µæ ‘æ²¡æœ‰æˆæ´»ï¼Œå¿…é¡»ç§»é™¤ã€‚ç§»é™¤ä¹‹åï¼Œæ€»å…±å‰©ä¸‹å¤šå°‘æ£µæ ‘ï¼Ÿ',
    'æ¬§æ‹‰åšå£«æ­£åœ¨è®¡åˆ’ä¸€åœºæ•°å­¦æ¯”èµ›ï¼Œä»–å†³å®šå°†å‚ä¸è€…åˆ†æˆå‡ ç»„ã€‚ä¸ºäº†ä¿è¯å…¬å¹³ï¼Œæ¯ç»„å¿…é¡»æœ‰ç›¸åŒæ•°é‡çš„å‚ä¸è€…ã€‚å¦‚æœæ¬§æ‹‰åšå£«å¯ä»¥é€‰æ‹©å°†å‚ä¸è€…åˆ†æˆ4äººã€5äººæˆ–6äººçš„ç»„ï¼Œå¹¶ä¸”å‚ä¸è€…æ€»æ•°å°‘äº100äººï¼Œé‚£ä¹ˆä»–æœ€å¤šå¯ä»¥æœ‰å¤šå°‘å‚ä¸è€…ï¼Œç¡®ä¿æ— è®ºæ€ä¹ˆåˆ†ç»„éƒ½ä¸ä¼šæœ‰å‰©ä½™ï¼Ÿ',
    'ä¸€ä¸ªå†œæ°‘ä¸ºä¸‡åœ£èŠ‚ç§æ¤å—ç“œã€‚ä»–ç§äº†8æ’ï¼Œæ¯æ’15æ£µå—ç“œæ¤æ ªã€‚æ¯æ£µæ¤æ ªå¹³å‡äº§å‡º3ä¸ªå—ç“œã€‚æ”¶è·åï¼Œå†œæ°‘å°†20%çš„å—ç“œå–ç»™å½“åœ°å¸‚åœºï¼Œå‰©ä¸‹çš„åœ¨ä»–çš„å†œåœºæ‘Šä½ä¸Šå‡ºå”®ã€‚å¦‚æœæ¯ä¸ªå—ç“œå–4ç¾å…ƒï¼Œå†œæ°‘é€šè¿‡é”€å”®å—ç“œæ€»å…±èµšäº†å¤šå°‘é’±ï¼Ÿ',
    'ä¸€ä¸ªä¸‰è§’å½¢å…¬å›­ABCçš„è¾¹ç¼˜ä¸Šç§æ¤äº†æ ‘æœ¨ã€‚è¾¹ABä¸Šçš„æ ‘æœ¨æ•°é‡ç­‰äºè¾¹BCçš„é•¿åº¦ï¼Œè¾¹BCä¸Šçš„æ ‘æœ¨æ•°é‡ç­‰äºè¾¹CAçš„é•¿åº¦ï¼Œè¾¹CAä¸Šçš„æ ‘æœ¨æ•°é‡ç­‰äºè¾¹ABçš„é•¿åº¦ã€‚å¦‚æœè¾¹ABã€BCå’ŒCAï¼ˆä»¥ç±³ä¸ºå•ä½ï¼‰çš„é•¿åº¦æ„æˆä¸€ä¸ªå…¬æ¯”ä¸º2çš„å‡ ä½•çº§æ•°ï¼Œå¹¶ä¸”æ€»å…±ç§æ¤äº†77æ£µæ ‘ï¼Œæ±‚è¾¹ABçš„é•¿åº¦ã€‚',
    'ä¸€ç¾¤æœ‹å‹æ­£åœ¨æ”¶é›†å¯å›æ”¶çš„ç½å­ã€‚ç›é›…æ”¶é›†çš„ç½å­æ˜¯åˆ©äºšå§†çš„ä¸¤å€ã€‚åˆ©äºšå§†æ”¶é›†äº†15ä¸ªç½å­ã€‚å¦‚æœä½ä¼Šæ¯”ç›é›…å¤šæ”¶é›†äº†5ä¸ªç½å­ï¼Œå¹¶ä¸”è¿™ç¾¤æœ‹å‹æƒ³æŠŠç½å­å¹³åˆ†ç»™4å®¶æ…ˆå–„æœºæ„ï¼Œæ¯å®¶ä¼šæ”¶åˆ°å¤šå°‘ä¸ªç½å­ï¼Ÿ',
    'åœ¨ä¸€åœºç§‘å­¦æ¯”èµ›ä¸­ï¼Œæ¯ä¸ªå›¢é˜Ÿéœ€è¦åˆ¶ä½œä¸€ä¸ªæ¨¡å‹ç«ç®­ã€‚æœ‰6ä¸ªå›¢é˜Ÿï¼Œæ¯ä¸ªå›¢é˜Ÿéœ€è¦ä¸€å¥—ææ–™ã€‚ææ–™åŒ…æ‹¬ç«ç®­çš„ä¸»ä½“ç®¡ã€å¼•æ“å’Œé™è½ä¼ã€‚ä¸»ä½“ç®¡æ¯ä¸ª12.50ç¾å…ƒï¼Œå¼•æ“æ¯ä¸ª18.75ç¾å…ƒï¼Œé™è½ä¼æ¯ä¸ª6.25ç¾å…ƒã€‚è´­ä¹°æ‰€æœ‰å›¢é˜Ÿçš„ææ–™åï¼Œæ€»è´¹ç”¨ä¸º225ç¾å…ƒã€‚åˆ¶ä½œä¸€æ”¯ç«ç®­çš„ææ–™è´¹ç”¨æ˜¯å¤šå°‘ï¼Ÿ',
    'è‰¾ç±³ä¸½æœ‰ä¸€ä¸ªå°èœå›­ï¼Œç§æ¤äº†ç•ªèŒ„ã€èƒ¡èåœå’Œé»„ç“œã€‚å¥¹çš„ç•ªèŒ„æ¤æ ªæ•°é‡æ˜¯é»„ç“œæ¤æ ªçš„ä¸¤å€ï¼Œè€Œèƒ¡èåœæ¤æ ªæ¯”ç•ªèŒ„å°‘5æ£µã€‚å¦‚æœè‰¾ç±³ä¸½æœ‰4æ£µé»„ç“œæ¤æ ªï¼Œé‚£ä¹ˆå¥¹æ€»å…±æœ‰å¤šå°‘æ£µèœå›­æ¤ç‰©ï¼Ÿ',
    'åœ¨ä¸€ä¸ªå°æ‘åº„ï¼Œå½“åœ°è£ç¼åˆ¶ä½œå¤–å¥—å’Œè£¤å­ã€‚åˆ¶ä½œä¸€ä»¶å¤–å¥—éœ€è¦3ç å¸ƒæ–™ï¼Œè€Œåˆ¶ä½œä¸€æ¡è£¤å­éœ€è¦2ç å¸ƒæ–™ã€‚ä»–æ¥åˆ°äº†ä¸€ä»½å‰§é™¢åˆ¶ä½œçš„è®¢å•ï¼Œè¦æ±‚çš„è£¤å­æ•°é‡æ˜¯å¤–å¥—çš„ä¸¤å€ï¼Œè€Œå‰§é™¢è¦æ±‚äº†4ä»¶å¤–å¥—ã€‚å¦‚æœå¸ƒæ–™çš„ä»·æ ¼æ˜¯æ¯ç 15ç¾å…ƒï¼Œé‚£ä¹ˆå‰§é™¢åœ¨è¿™ä¸ªè®¢å•ä¸Šéœ€è¦èŠ±è´¹å¤šå°‘å¸ƒæ–™è´¹ç”¨ï¼Ÿ',
    'ä¸€ä¸ªå°é•‡çš„äººå£ä»¥æ’å®šçš„é€Ÿç‡å¢é•¿ã€‚å¦‚æœ2010å¹´å°é•‡çš„äººå£æ˜¯5000äººï¼Œ2020å¹´æ˜¯8000äººï¼Œé‚£ä¹ˆå¦‚æœè¿™ç§å¢é•¿è¶‹åŠ¿ç»§ç»­ï¼Œåˆ°2025å¹´å°é•‡çš„äººå£ä¼šæ˜¯å¤šå°‘ï¼Ÿ',
    'ä¸€ä½æ•°å­¦è€å¸ˆæ­£åœ¨ç»„ç»‡ä¸€åœºæµ‹éªŒæ¯”èµ›ï¼Œå¹¶å†³å®šç”¨é“…ç¬”ä½œä¸ºå¥–å“ã€‚æ¯ä½å‚ä¸è€…å°†è·å¾—2æ”¯é“…ç¬”ï¼Œè€Œå¾—åˆ†è¶…è¿‡80%çš„å­¦ç”Ÿå°†é¢å¤–è·å¾—3æ”¯é“…ç¬”ã€‚å¦‚æœç­ä¸Šæœ‰30åå­¦ç”Ÿï¼Œå…¶ä¸­1/5çš„å­¦ç”Ÿå¾—åˆ†è¶…è¿‡80%ï¼Œé‚£ä¹ˆè€å¸ˆéœ€è¦å‡†å¤‡å¤šå°‘æ”¯é“…ç¬”ï¼Ÿ',
    'ä¸€ä¸ªé•¿æ–¹å½¢çš„èŠ±å›­è¢«120ç±³çš„å›´æ åŒ…å›´ã€‚å¦‚æœèŠ±å›­çš„é•¿åº¦æ˜¯å…¶å®½åº¦çš„ä¸‰å€ï¼Œé‚£ä¹ˆèŠ±å›­çš„é¢ç§¯æ˜¯å¤šå°‘å¹³æ–¹ç±³ï¼Ÿ',
    'ä¸€ä¸ªé•¿10ç±³ã€å®½15ç±³çš„èŠ±å›­å°†ç”¨æ–¹å½¢ç“·ç –é“ºè®¾ã€‚æ¯å—ç“·ç –çš„è¾¹é•¿ä¸º25å˜ç±³ã€‚å¦‚æœæ¯å—ç“·ç –çš„ä»·æ ¼æ˜¯3ç¾å…ƒï¼Œè€Œé“ºè®¾ç“·ç –çš„äººå·¥è´¹ç”¨æ˜¯æ¯å¹³æ–¹ç±³8ç¾å…ƒï¼Œé‚£ä¹ˆé“ºè®¾æ•´ä¸ªèŠ±å›­çš„æ€»è´¹ç”¨æ˜¯å¤šå°‘ï¼Ÿ'
]
answers = [
    228, 15, 132, 0.45, 24, 7.3205, 16, 720, 30, 2, 13, 14, 862.5, 180, 2, 6, 752, 
    43, 47, 60, 1440, 11, 20, 37.5, 15, 420, 9500, 78, 675, 8400
]
```

## ğŸ§™ åˆ›å»ºä½ çš„è‡ªå®šä¹‰ Promptï¼ˆGradio ç‰ˆæœ¬ï¼‰

### äº¤äº’ç•Œé¢

å¤åˆ¶ä»£ç è¿è¡Œï¼ˆå¿½ç•¥ä»£ç ç»†èŠ‚ï¼‰ï¼š

```python
# ä½¿ç”¨gradioè¿›è¡Œè‡ªå®šä¹‰promptæ“ä½œ
import gradio as gr

def reset_prompt(chatbot):
    """
    ResetæŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šé‡ç½®prompt
    
    å‚æ•°:
        chatbot (List): èŠå¤©è®°å½•
        
    è¿”å›:
        Tuple: æ›´æ–°åçš„èŠå¤©è®°å½•å’Œæ¸…ç©ºçš„æç¤ºè¯æ–‡æœ¬
    """
    gr.Info("å·²æ¸…é™¤æç¤ºè¯")
    chatbot.extend([["æ¸…é™¤æç¤ºè¯", "æç¤ºè¯å·²æˆåŠŸé‡ç½®"]])
    return chatbot, "", 0

def assign_prompt(chatbot, prompt, template, example_number):
    """
    AssignæŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šåˆ†é…æœ‰æ•ˆpromptå¹¶è®¾ç½®template
    
    å‚æ•°:
        chatbot (List): èŠå¤©è®°å½•
        prompt (str): ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        template: å½“å‰çš„æ¨¡æ¿å¯¹è±¡
        example_number (int): é€‰æ‹©çš„ç¤ºä¾‹ç¼–å·
        
    è¿”å›:
        Tuple: æ›´æ–°åçš„èŠå¤©è®°å½•ã€æç¤ºè¯æ–‡æœ¬ã€æ¨¡æ¿å¯¹è±¡å’Œé€‰æ‹©çš„ç¤ºä¾‹ç¼–å·
    """
    gr.Info("æ­£åœ¨åˆ†é…æç¤ºè¯")
    example_number = int(example_number)
    token_num = my_model.prompt_token_num(prompt)
    
    if token_num > 1024:
        template = None
        gr.Warning("æ— æ•ˆçš„æç¤ºè¯ï¼ˆå¤ªé•¿ï¼Œè¶…è¿‡1024ä¸ªtokenï¼‰")
        chatbot.append([None, "æç¤ºè¯å¤ªé•¿ï¼ˆè¶…è¿‡1024ä¸ªtokenï¼‰ã€‚è¾ƒçŸ­çš„æç¤ºè¯å¯ä»¥æ›´å¿«ä¸”æ›´ç¨³å®šåœ°è¯„ä¼°ï¼"])
    elif example_number < 1 or example_number > len(questions):
        template = None
        prompt_ex = f"é”™è¯¯ï¼šè¯·é€‰æ‹©ä¸€ä¸ª1åˆ°{len(questions)}ä¹‹é—´çš„æ•°å­—"
        gr.Warning(prompt_ex)
        chatbot.extend([[None, prompt_ex]])
    elif "{{question}}" not in prompt:
        template = None
        prompt_ex = "ä½ éœ€è¦åœ¨æç¤ºè¯ä¸­åŒ…å«å ä½ç¬¦{{question}}ã€‚"
        gr.Warning(prompt_ex)
        chatbot.extend([[None, prompt_ex]])
    else:
        environment = jinja2.Environment()
        template = environment.from_string(prompt)
        prompt_ex = f"""{template.render(question=questions[example_number - 1])}"""
        chatbot.extend([["åˆ†é…æç¤ºè¯", "æç¤ºè¯å·²æˆåŠŸåˆ†é…\n\nè‡ªå®šä¹‰æç¤ºè¯ç¤ºä¾‹ï¼š"], [None, prompt_ex]])
        
    return chatbot, prompt, template, example_number, token_num

def clean_commas(text):
    """
    å¤„ç†æ•°å­—ä¸­çš„é€—å·ï¼ˆåƒä½åˆ†éš”ç¬¦ï¼‰
    
    å‚æ•°:
        text (str): åŒ…å«æ•°å­—çš„æ–‡æœ¬
        
    è¿”å›:
        str: å¤„ç†åçš„æ–‡æœ¬
    """
    def process_match(match):
        number = match.group(0)
        if '.' in number:
            return number
        else:
            number_list = number.split(",")
            new_string = number_list[0]
            for i in range(1, len(number_list)):
                if len(number_list[i]) == 3:
                    new_string += number_list[i]
                else:
                    new_string += f",{number_list[i]}"
            return new_string
            
    pattern = r'\d+(?:,\d+)*(?:\.\d+)?'
    return re.sub(pattern, process_match, text)

def find_and_match_floats(input_string, ground_truth):
    """
    æ£€æŸ¥è¾“å…¥ä¸­çš„æ•°å­—æ˜¯å¦ä¸é¢„æœŸåŒ¹é…
    
    å‚æ•°:
        input_string (str): åŒ…å«æ•°å­—çš„è¾“å…¥å­—ç¬¦ä¸²
        ground_truth (float): é¢„æœŸçš„æ­£ç¡®æ•°å€¼
        
    è¿”å›:
        bool: å¦‚æœæ‰¾åˆ°åŒ¹é…çš„æ•°å€¼åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    pattern = re.compile(r"[-+]?\d*\.\d+|[-+]?\d+")
    found_numbers = pattern.findall(input_string)
    found_floats = [float(num) for num in found_numbers]
    return ground_truth in found_floats

def assess_prompt(chatbot, template, test_num):
    """
    TestæŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šè¯„ä¼°è‡ªå®šä¹‰prompt
    
    å‚æ•°:
        chatbot (List): èŠå¤©è®°å½•
        template: å½“å‰çš„æ¨¡æ¿å¯¹è±¡
        test_num (int): è¦æµ‹è¯•çš„é—®é¢˜æ•°é‡
        
    è¿”å›:
        Tuple: æ›´æ–°åçš„èŠå¤©è®°å½•ã€ç»“æœåˆ—è¡¨ã€ç»“æœç»Ÿè®¡å’ŒUIç»„ä»¶
    """
    if template is None:
        chatbot.extend([[None, "è¯„ä¼°å¤±è´¥ï¼Œå› ä¸ºæç¤ºè¯æ¨¡æ¿ä¸ºç©ºï¼ˆå³æ— æ•ˆçš„æç¤ºè¯ï¼‰"]])
        gr.Warning("æç¤ºè¯æœªè®¾ç½®")
        return chatbot, [], "æç¤ºè¯æœªè®¾ç½®", gr.Slider(label="Result Number", value=0, minimum=0, maximum=0, step=1), gr.Textbox(label="Result", value="", interactive=False)

    gr.Info("æ­£åœ¨è¯„ä¼°æç¤ºè¯")
    ans_template = "æç¤ºè¯å’Œé—®é¢˜ï¼š\n\n{{question}}\n\n--------------------\n\nè§£é¢˜è¿‡ç¨‹ï¼š\n\n{{rationale}}\n\n--------------------\n\næœ€ç»ˆç­”æ¡ˆ\n\n{{answer}}"
    res_list = []
    total_count = test_num
    environment = jinja2.Environment()
    ans_template = environment.from_string(ans_template)
    trial_num = 3
    trials = [[] for _ in range(trial_num)]
    res_stats_str = ""

    for i in range(trial_num):
        gr.Info(f"å¼€å§‹ç¬¬{i+1}æ¬¡æµ‹è¯•")
        accurate_count = 0
        for idx, example in enumerate(questions[:test_num]):
            test_res = ""
            result = my_model.two_stage_completion(example, template.render(question=example))

            if not result["answer"]:
                trials[i].append(0)
                test_res += f"ç¬¬{i+1}æ¬¡æµ‹è¯•\n\nè·³è¿‡é—®é¢˜ {idx + 1}ã€‚"
                test_res += "\n" + "<"*6 + "="*30 + ">"*6 + "\n\n"
                res_list.append(f"ç¬¬{i+1}æ¬¡æµ‹è¯•\n\nè·³è¿‡é—®é¢˜ {idx + 1}ã€‚")
                continue

            cleaned_result = clean_commas(result["answer"])
            if find_and_match_floats(cleaned_result, answers[idx]):
                accurate_count += 1
                trials[i].append(1)
            else:
                trials[i].append(0)

            my_model.save_cache()
            test_res += f"ç¬¬{i + 1}æ¬¡æµ‹è¯•\n\n"
            test_res += f"é—®é¢˜ {idx + 1}:\n" + '-'*20
            test_res += f'''\n\n{ans_template.render(question=result['prompt'], rationale=result['rationale'], answer=result['answer'])}\n'''
            test_res += "\n" + "<"*6 + "="*30 + ">"*6 + "\n\n"
            res_list.append(test_res)

        res_stats_str += f"ç¬¬{i + 1}æ¬¡æµ‹è¯•ï¼Œæ­£ç¡®æ•°ï¼š{accurate_count}ï¼Œæ€»æ•°ï¼š{total_count}ï¼Œå‡†ç¡®ç‡ï¼š{accurate_count / total_count * 100}%\n"
        my_model.save_cache()

    voting_acc = 0
    for i in range(total_count):
        count = 0
        for j in range(trial_num):
            if trials[j][i] == 1:
                count += 1
        if count >= 2:
            voting_acc += 1

    res_stats_str += f"æœ€ç»ˆå‡†ç¡®ç‡ï¼š{voting_acc / total_count * 100}%"
    chatbot.extend([["æµ‹è¯•", "æµ‹è¯•å®Œæˆã€‚ç»“æœå¯ä»¥åœ¨â€œç»“æœâ€å’Œâ€œç»“æœç»Ÿè®¡â€ä¸­æ‰¾åˆ°ã€‚"]])
    chatbot.extend([[None, "æµ‹è¯•ç»“æœ"], [None, ''.join(res_list)], [None, "ç»“æœç»Ÿè®¡"], [None, res_stats_str]])
    
    return chatbot, res_list, res_stats_str, gr.Slider(label="Result Number", value=1, minimum=1, maximum=len(res_list), step=1, visible=False), gr.Textbox(label="Result", value=res_list[0], interactive=False)

def save_prompt(chatbot, prompt):
    """
    SaveæŒ‰é’®ç‚¹å‡»å¤„ç†ï¼šä¿å­˜æç¤ºè¯
    
    å‚æ•°:
        chatbot (List): èŠå¤©è®°å½•
        prompt (str): ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        
    è¿”å›:
        List: æ›´æ–°åçš„èŠå¤©è®°å½•
    """
    gr.Info("æ­£åœ¨ä¿å­˜æç¤ºè¯")
    prompt_dict = {
        "prompt": prompt
    }
    with open("prompt.json", "w") as f:
        json.dump(prompt_dict, f)
    chatbot.extend([["ä¿å­˜æç¤ºè¯", f"æç¤ºè¯å·²ä¿å­˜ä¸ºprompt.json"]])
    return chatbot

# Gradioç•Œé¢
with gr.Blocks() as demo:
    my_magic_prompt = "ä»»åŠ¡ï¼š\nè§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ã€‚\n\né—®é¢˜ï¼š{{question}}\n\nç­”æ¡ˆï¼š"
    my_magic_prompt = my_magic_prompt.strip('\n')
    template = gr.State(None)
    res_list = gr.State(list())

    # ç»„ä»¶
    with gr.Tab(label="Console"):
        with gr.Group():
            example_num_box = gr.Dropdown(
                label="Demo Example (Please choose one example for demo)",
                value=1,
                info=questions[0],
                choices=[i+1 for i in range(len(questions))],
                filterable=False
            )
            prompt_textbox = gr.Textbox(
                label="Custom Prompt",
                placeholder=f"åœ¨è¿™é‡Œè¾“å…¥ä½ çš„è‡ªå®šä¹‰æç¤ºè¯ã€‚ä¾‹å¦‚ï¼š\n\n{my_magic_prompt}",
                value="",
                info="è¯·ç¡®ä¿åŒ…å«`{{question}}`æ ‡ç­¾ã€‚"
            )
            with gr.Row():
                set_button = gr.Button(value="Set Prompt")
                reset_button = gr.Button(value="Clear Prompt")
            prompt_token_num = gr.Textbox(
                label="Number of prompt tokens",
                value=0,
                interactive=False,
                info="è‡ªå®šä¹‰æç¤ºè¯çš„Tokenæ•°é‡ã€‚"
            )
        with gr.Group():
            test_num = gr.Slider(
                label="Number of examples used for evaluation",
                minimum=1,
                maximum=len(questions),
                step=1,
                value=1
            )
            assess_button = gr.Button(value="Evaluate")
        with gr.Group():
            with gr.Row():
                with gr.Column():
                    with gr.Row():
                        trial_no = gr.Slider(
                            label="Trial ID",
                            value=1,
                            minimum=1,
                            maximum=3,
                            step=1
                        )
                        ques_no = gr.Slider(
                            label="Question ID",
                            value=1,
                            minimum=1,
                            maximum=1,
                            step=1
                        )
                    res_num = gr.Slider(
                        label="Result Number",
                        value=0,
                        minimum=0,
                        maximum=0,
                        step=1,
                        visible=False
                    )
                    res = gr.Textbox(
                        label="Result",
                        value="",
                        placeholder="æš‚æ— ç»“æœ",
                        interactive=False
                    )
                with gr.Column():
                    res_stats = gr.Textbox(label="Result Stats", interactive=False)
            save_button = gr.Button(value="Save Custom Prompt")
    with gr.Tab(label="Log"):
        chatbot = gr.Chatbot(label="Log")

    # äº‹ä»¶å¤„ç†
    example_num_box.input(
        lambda example_number: gr.Dropdown(
            label="Example (Please choose one example for demo)",
            value=example_number,
            info=questions[example_number - 1],
            choices=[i+1 for i in range(len(questions))]
        ),
        inputs=[example_num_box],
        outputs=[example_num_box]
    )
    
    res_num.change(
        lambda results, result_num, test_num: (
            gr.Textbox(label="Result", value=results[result_num-1], interactive=False) 
            if len(results) != 0 
            else gr.Textbox(label="Result", value="", placeholder="æš‚æ— ç»“æœ", interactive=False),
            (int)((result_num-1)/test_num)+1,
            gr.Slider(
                label="Question Number", 
                minimum=1, 
                maximum=test_num, 
                value=(result_num-1)%test_num+1, 
                step=1
            )
        ),
        inputs=[res_list, res_num, test_num],
        outputs=[res, trial_no, ques_no]
    )
    
    trial_ques_no_input = lambda t_val, q_val, test_num: (t_val - 1) * test_num + q_val
    trial_no.input(trial_ques_no_input, inputs=[trial_no, ques_no, test_num], outputs=[res_num])
    ques_no.input(trial_ques_no_input, inputs=[trial_no, ques_no, test_num], outputs=[res_num])
    set_button.click(assign_prompt, inputs=[chatbot, prompt_textbox, template, example_num_box], outputs=[chatbot, prompt_textbox, template, example_num_box, prompt_token_num])
    reset_button.click(reset_prompt, inputs=[chatbot], outputs=[chatbot, prompt_textbox, prompt_token_num])
    assess_button.click(assess_prompt, inputs=[chatbot, template, test_num], outputs=[chatbot, res_list, res_stats, res_num, res])
    save_button.click(save_prompt, inputs=[chatbot, prompt_textbox], outputs=[chatbot])

demo.queue().launch(debug=True)
```

**äº¤äº’ç•Œé¢**ï¼š

![image-20240911180721090](./assets/image-20240911180721090.png)

> å¦‚æœä½ ä¸‹è½½äº†ä»£ç æ–‡ä»¶æˆ–è€…ä½¿ç”¨åœ¨çº¿å¹³å°è¿è¡Œä»£ç ï¼ŒåŒæ ·éœ€è¦æš‚æ—¶å¿½ç•¥ä»£ç ç»†èŠ‚ï¼Œä¸“æ³¨äº Prompt è®¾è®¡ã€‚ä¸€ç›´è¿è¡Œæä¾›çš„ä»£ç ï¼š
>
> ![image-20240911203422857](./assets/image-20240911203422857.png)
>
> ç›´åˆ°çœ‹åˆ°äº¤äº’ç•Œé¢ã€‚
>

### è®¾è®¡ Prompt è§£å†³æ•°å­¦é—®é¢˜

ç°åœ¨éœ€è¦è®¾è®¡ä½ è‡ªå·±çš„  Promptï¼Œå¡«å†™åœ¨ `Custom Prompt` ä¸­ï¼Œæ³¨æ„ï¼Œä½ çš„ Prompt ä¸­éœ€è¦åŒ…å« `{{question}}`ï¼Œè¿™å°†ä½œä¸ºä¸€ä¸ªå ä½ç¬¦ï¼Œåç»­è¢« `Demo Example` æ˜¾ç¤ºçš„é—®é¢˜æ›¿æ¢ã€‚

![å ä½ç¬¦](./assets/%E5%8D%A0%E4%BD%8D%E7%AC%A6-6055722.png)

ä½¿ç”¨ `Shift+Enter` å¯ä»¥åœ¨æ–‡æœ¬æ¡†ä¸­æ¢è¡Œã€‚åœ¨è®¾è®¡å®Œæˆä¹‹åï¼Œç‚¹å‡» `Set Prompt`è®¾ç½®å½“å‰ Promptã€‚

![image-20240911191726959](./assets/image-20240911191726959.png)

è®¾ç½®çš„ç»“æœå¯ä»¥ç‚¹å‡» `Log` æŸ¥çœ‹ï¼š

![image-20240911192313607](./assets/image-20240911192313607.png)

å›åˆ° `Console` ç•Œé¢ï¼Œå¦‚æœæƒ³é‡æ–°è®¾ç½® Promptï¼Œç‚¹å‡» `Clear Prompt` æ¸…é™¤å·²è¾“å…¥çš„ä»»ä½•è‡ªå®šä¹‰æç¤ºè¯ï¼š

![image-20240911192803999](./assets/image-20240911192803999.png)

åœ¨ç‚¹å‡» `Evalute` è¿›è¡Œè¯„ä¼°ä¹‹å‰ï¼Œä½ éœ€è¦äº†è§£å¯¹åº”çš„æ¦‚å¿µï¼š

- `Number of prompt tokens`
  æ˜¾ç¤ºå½“å‰ Prompt çš„ Token æ•°é‡ï¼Œä½œä¸šä¼šé™åˆ¶æœ€å¤§é•¿åº¦ä¸º 1024ã€‚

- `Number of examples used for evaluation` 
  æ„å‘³ç€æˆ‘ä»¬å°†å»è¯„ä¼°å¤šå°‘ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚

- `Trail ID`
  å¯¹æŒ‡å®šè¯„ä¼°çš„é—®é¢˜ï¼Œå°†è¿›è¡Œä¸‰æ¬¡æµ‹è¯•ã€‚

- `Question ID`

  å— `Number of examples used for evaluation `é™åˆ¶ï¼Œä¸ºé—®é¢˜æ•°é‡ã€‚

å‡è®¾æˆ‘ä»¬ä»…è¯„ä¼°å‰10ä¸ªé—®é¢˜ï¼Œè®¾ç½®`Number of examples used for evaluation` ä¸º10ï¼Œç‚¹å‡» `Evaluate`ã€‚

![image-20240911202157024](./assets/image-20240911202157024.png)

ä½ å¯ä»¥æ”¹å˜`Trail ID`å’Œ`Question ID`æ¥æŸ¥çœ‹æŸæ¬¡æµ‹è¯•ä¸‹å¯¹åº”é—®é¢˜çš„ç»“æœï¼Œå¹¶å¯ä»¥å¾—åˆ° 3 æ¬¡æµ‹è¯•ä¸‹ Prompt çš„å‡†ç¡®ç‡ã€‚

![image-20240911202343357](./assets/image-20240911202343357.png)

ä½ è¿˜å¯ä»¥ç‚¹å‡» `Log` è¿›ä¸€æ­¥æŸ¥çœ‹ç»†èŠ‚ï¼š

![image-20240911202538505](./assets/image-20240911202538505.png)

## ğŸ§™ åˆ›å»ºä½ çš„è‡ªå®šä¹‰ Promptï¼ˆé Gradio ç‰ˆæœ¬ï¼‰

è¿™ä¸ªç‰ˆæœ¬å°†ä¸æ¶‰åŠ Gradioï¼Œä½¿ç”¨ ipywidgets æ¥åˆ›å»ºäº¤äº’ç•Œé¢ã€‚

å®é™…ä¸Šè¿™é‡Œåªæ˜¯ä¸€ä¸ªæ‹“å±•ï¼Œå¦‚æœåªæ˜¯æƒ³ç»ƒä¹  Prompt çš„ä½¿ç”¨ï¼ŒæŸ¥çœ‹ Gradio ç‰ˆæœ¬å³å¯ã€‚

### å¯¼å…¥

```python
import ipywidgets as widgets
from IPython.display import display
```

### è‡ªå®šä¹‰ Prompt

```python
# åˆ›å»ºæ–‡æœ¬åŒºåŸŸã€æŒ‰é’®å’Œè¾“å‡ºåŒºåŸŸ
prompt_area = widgets.Textarea(placeholder="åœ¨æ­¤è¾“å…¥ä½ çš„è‡ªå®šä¹‰æç¤ºè¯")
prompt_area_desc = widgets.HTML(value="<p><b>Custom Prompt:</b></p>")
setprompt_btn = widgets.Button(description="Set Prompt")
resetprompt_btn = widgets.Button(description="Clear Prompt")
display_output = widgets.Output()

# åˆå§‹åŒ–è‡ªå®šä¹‰æç¤ºè¯
custom_prompt = ""

def set_prompt_clk(b):
    """
    "Assign Prompt"æŒ‰é’®ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
    
    å‚æ•°:
        b: æŒ‰é’®å¯¹è±¡
    """
    global custom_prompt
    custom_prompt = prompt_area.value  # è·å–è¾“å…¥æ¡†ä¸­çš„æç¤ºè¯
    prompt_area.disabled = True  # ç¦ç”¨è¾“å…¥æ¡†
    with display_output:
        display_output.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º
        print("Prompt å·²åˆ†é…ï¼š", custom_prompt)  # æ‰“å°å·²åˆ†é…çš„æç¤ºè¯

def reset_prompt_clk(b):
    """
    "Clear Prompt"æŒ‰é’®ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
    
    å‚æ•°:
        b: æŒ‰é’®å¯¹è±¡
    """
    prompt_area.disabled = False  # é‡æ–°å¯ç”¨è¾“å…¥æ¡†
    prompt_area.value = ""  # æ¸…ç©ºè¾“å…¥æ¡†
    with display_output:
        display_output.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º
        print("æç¤ºè¯å·²é‡ç½®")  # æç¤ºå·²é‡ç½®

# ç»‘å®šæŒ‰é’®ç‚¹å‡»äº‹ä»¶
setprompt_btn.on_click(set_prompt_clk)
resetprompt_btn.on_click(reset_prompt_clk)

# æ˜¾ç¤ºç»„ä»¶
display(prompt_area_desc, prompt_area, setprompt_btn, resetprompt_btn, display_output)
```

åœ¨æ–‡æœ¬æ¡†ä¸­å¡«å†™ä½ çš„ Promptï¼š

![image-20240911203200685](./assets/image-20240911203200685.png)

#### åˆ›å»ºä¸‹æ‹‰é€‰é¡¹é€‰æ‹©é—®é¢˜

è¿™éƒ¨åˆ†å®ç° Colab ä¸­çš„ `Demo_Example = "7" # @param [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30] {type:"string"}`

```python
# åˆ›å»ºä¸‹æ‹‰èœå•ï¼Œå…è®¸ç”¨æˆ·é€‰æ‹© 1 åˆ° 30 ä¹‹é—´çš„æ•°å­—
demo_example_dropdown = widgets.Dropdown(
    options=[str(i) for i in range(1, 31)],  # é€‰é¡¹ä¸ºå­—ç¬¦ä¸²
    value="7",  # é»˜è®¤å€¼
    description='ç¤ºä¾‹ç¼–å·:',
)

# åˆ›å»ºè¾“å‡ºåŒºåŸŸ
output_demo_example = widgets.Output()

# åˆå§‹åŒ–ä¸ºä¸‹æ‹‰èœå•çš„é»˜è®¤å€¼
Demo_Example = demo_example_dropdown.value

def on_dropdown_change(change):
    """
    ä¸‹æ‹‰èœå•å€¼å˜åŒ–æ—¶çš„å›è°ƒå‡½æ•°
    
    å‚æ•°:
        change (dict): åŒ…å«æ–°æ—§å€¼çš„å­—å…¸
    """
    global Demo_Example  # ä½¿ç”¨å…¨å±€å˜é‡
    Demo_Example = change['new']  # è·å–ä¸‹æ‹‰èœå•çš„æ–°å€¼
    with output_demo_example:
        output_demo_example.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º
        print(f"å·²é€‰æ‹©çš„ç¤ºä¾‹ç¼–å·æ˜¯: {Demo_Example}")

# ç›‘å¬ä¸‹æ‹‰èœå•çš„å˜åŒ–
demo_example_dropdown.observe(on_dropdown_change, names='value')

# æ˜¾ç¤ºä¸‹æ‹‰èœå•å’Œè¾“å‡ºåŒºåŸŸ
display(demo_example_dropdown, output_demo_example)
```

é»˜è®¤é€‰æ‹©ç¤ºä¾‹7:

![image-20240911210412806](./assets/image-20240911210412806.png)

æŸ¥çœ‹å ä½ç¬¦çš„ä½œç”¨ï¼š

```python
# ä»æ–‡æœ¬æ¡†è·å–ç”¨æˆ·è¾“å…¥çš„è‡ªå®šä¹‰æç¤ºè¯
custom_prompt = prompt_area.value
assert "{{question}}" in custom_prompt, "æç¤ºè¯ä¸­å¿…é¡»åŒ…å« '{{question}}' å ä½ç¬¦ï¼"

# é€šè¿‡ä¸Šé¢çš„ä¸‹æ‹‰é€‰é¡¹é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹ï¼Œå¯ä»¥é€‰æ‹©1åˆ°30ä¹‹é—´çš„ç¼–å· 
demo_index = int(Demo_Example)  # å°†å­—ç¬¦ä¸²å½¢å¼çš„æ•°å­—è½¬ä¸ºæ•´æ•°

# åˆå§‹åŒ– jinja2 ç¯å¢ƒå¹¶æ¸²æŸ“æ¨¡æ¿
environment = jinja2.Environment()
template = environment.from_string(custom_prompt)

# è¾“å‡ºç”Ÿæˆçš„è‡ªå®šä¹‰æç¤ºè¯ç¤ºä¾‹
print(f"è‡ªå®šä¹‰æç¤ºè¯ç¤ºä¾‹ï¼š\n\n{template.render(question=questions[demo_index-1])}")
```

å¯ä»¥çœ‹åˆ°åŸæ¥å ä½ç¬¦çš„ä½ç½®è¢«æ›¿æ¢ä¸ºäº†ç¬¬7ä¸ªé—®é¢˜ã€‚

![image-20240911210824494](./assets/image-20240911210824494.png)

### è¯„ä¼°

#### åˆ›å»ºæ»‘å—é€‰æ‹©è¯„ä¼°çš„æ•°é‡

è¿™éƒ¨åˆ†ç”¨äºå®ç° Colab ä¸­çš„ `eval_num = 5 # @param {type:"slider", min:1, max:30, step:1}`

```python
# åˆ›å»ºæ»‘å—ï¼ŒèŒƒå›´ä¸º 1 åˆ° 30ï¼Œæ­¥é•¿ä¸º 1ï¼Œé»˜è®¤å€¼ä¸º 5
eval_slider = widgets.IntSlider(
    value=5,
    min=1,
    max=30,
    step=1,
    description='é€‰æ‹©è¯„ä¼°æ•°:', 
    continuous_update=False  # æ»‘å—æ”¾å¼€åæ‰æ›´æ–°
)

# åˆ›å»ºè¾“å‡ºåŒºåŸŸ
output = widgets.Output()

# åˆå§‹åŒ–ä¸ºæ»‘å—çš„é»˜è®¤å€¼
eval_num = eval_slider.value  

def on_slider_change(change):
    """
    æ»‘å—å€¼å˜åŒ–æ—¶çš„å›è°ƒå‡½æ•°
    
    å‚æ•°:
        change (dict): åŒ…å«æ–°æ—§å€¼çš„å­—å…¸
    """
    global eval_num
    eval_num = change['new']  # è·å–æ»‘å—çš„æ–°å€¼
    with output:
        output.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º
        print(f"å·²é€‰æ‹©çš„è¯„ä¼°æ•°æ˜¯: {eval_num}")

# ç›‘å¬æ»‘å—çš„å˜åŒ–
eval_slider.observe(on_slider_change, names='value')

# æ˜¾ç¤ºæ»‘å—å’Œè¾“å‡ºåŒºåŸŸ
display(eval_slider, output)
```

è¿™é‡Œçš„æ¼”ç¤ºé€‰æ‹©10ã€‚

![image-20240911211603141](./assets/image-20240911211603141.png)

å¼€å§‹è¯„ä¼°å‰10ä¸ªé—®é¢˜ä¸‹ Prompt çš„æ­£ç¡®ç‡ï¼š

```python
assert 1 <= eval_num <= 30

# å®šä¹‰æ˜¾ç¤ºç»“æœçš„æ¨¡æ¿
ans_template = """Prompt with Question:\n\n{{question}}\n\n--------------------\n\nProblem-solving Process:\n\n{{rationale}}\n\n--------------------\n\nFinal Answer\n\n{{answer}}"""

res_list = []
test_num = eval_num  # è¦è¯„ä¼°çš„é—®é¢˜æ•°é‡
total_count = test_num

# å°† ans_template å­—ç¬¦ä¸²è½¬æ¢ä¸º jinja2 æ¨¡æ¿å¯¹è±¡
environment = jinja2.Environment()
ans_template = environment.from_string(ans_template)

# åˆå§‹åŒ–è®¡æ•°å™¨ä»¥è·Ÿè¸ªå‡†ç¡®å›ç­”çš„æ¬¡æ•°
trial_num = 3  # è¿›è¡Œä¸‰æ¬¡è¯•éªŒ
trials = [[] for _ in range(trial_num)]
res_stats_str = ""


def clean_commas(text):
    """
    æ¸…ç†æ•°å­—ä¸­çš„é€—å·ï¼Œå¹¶ä¿ç•™æµ®ç‚¹æ•°ä¸­çš„é€—å·
    
    å‚æ•°:
        text (str): è¦å¤„ç†çš„æ–‡æœ¬
        
    è¿”å›:
        str: å¤„ç†åçš„æ–‡æœ¬
    """
    def process_match(match):
        number = match.group(0)
        if '.' in number:
            return number  # ä¿ç•™æµ®ç‚¹æ•°
        else:
            # å»æ‰æ•°å­—ä¸­çš„é€—å·
            number_list = number.split(",")
            new_string = number_list[0]
            for i in range(1, len(number_list)):
                if len(number_list[i]) == 3:  # è¿™æ˜¯åƒä½åˆ†éš”ç¬¦
                    new_string += number_list[i]
                else:
                    new_string += f",{number_list[i]}"
            return new_string

    pattern = r'\d+(?:,\d+)*(?:\.\d+)?'
    return re.sub(pattern, process_match, text)


def find_and_match_floats(input_string, ground_truth):
    """
    åŒ¹é…è¾“å…¥å­—ç¬¦ä¸²ä¸­çš„æ‰€æœ‰æµ®ç‚¹æ•°å’Œæ•´æ•°å¹¶ä¸ç›®æ ‡å€¼æ¯”è¾ƒ
    
    å‚æ•°:
        input_string (str): è¾“å…¥å­—ç¬¦ä¸²
        ground_truth (float): æ­£ç¡®ç­”æ¡ˆ
        
    è¿”å›:
        bool: å¦‚æœæ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆåˆ™è¿”å›True
    """
    pattern = re.compile(r"[-+]?\d*\.\d+|[-+]?\d+")
    found_numbers = pattern.findall(input_string)
    found_floats = [float(num) for num in found_numbers]
    return ground_truth in found_floats


for i in range(trial_num):
    print(f"Start trial {i+1}")
    my_model.set_cache_file(f"gemini_cache_trial_{i+1}")
    accurate_count = 0

    # éå†æ¯ä¸ªè¦è¯„ä¼°çš„ç¤ºä¾‹
    for idx, example in enumerate(questions[:test_num]):
        test_res = ""

        result = my_model.two_stage_completion(example, template.render(question=example))

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿”å›äº†æœ‰æ•ˆç­”æ¡ˆ
        if not result["answer"]:
            trials[i].append(0)
            test_res += f"Trial {i+1}\n\n Skip question {idx + 1}."
            test_res += "\n" + "<"*6 + "="*30 + ">"*6 + "\n\n"
            res_list.append(f"Trial {i+1}\n\n Skip question {idx + 1}.")
            continue

        # æ¸…ç†ç­”æ¡ˆä¸­çš„é€—å·å¹¶ä¸åœ°é¢çœŸå€¼è¿›è¡Œæ¯”è¾ƒ
        cleaned_result = clean_commas(result["answer"])
        if find_and_match_floats(cleaned_result, answers[idx]) or idx in [0, 26]:
            accurate_count += 1
            trials[i].append(1)
        else:
            trials[i].append(0)

        # ä¿å­˜æ¨¡å‹çš„ç¼“å­˜
        my_model.save_cache()

        test_res += f"Trial {i + 1}\n\n"
        test_res += f"Question {idx + 1}:\n" + '-'*20
        test_res += f'''\n\n{ans_template.render(question=result['prompt'], rationale=result['rationale'], answer=result['answer'])}\n'''
        test_res += "\n" + "<"*6 + "="*30 + ">"*6 + "\n\n"
        res_list.append(test_res)

        time.sleep(1)

    # æ‰“å°å‡†ç¡®ç‡ç»Ÿè®¡
    res_stats_str += f"Trial {i + 1}, accurate_count: {accurate_count}, total_count: {total_count}, accuracy: {accurate_count / total_count * 100}%\n"
    my_model.save_cache()

# å¤šæ•°æŠ•ç¥¨è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡
voting_acc = 0
for i in range(total_count):
    count = 0
    for j in range(trial_num):
        if trials[j][i] == 1:
            count += 1
    if count >= 2:
        voting_acc += 1

res_stats_str += f"Final Accuracy: {voting_acc / total_count * 100}%"

print(f"Final accuracy: {res_stats_str}")
```

ç”¨å¤šæ•°æŠ•ç¥¨æ¥è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡ï¼š

![image-20240911221309441](./assets/image-20240911221309441.png)

### æ‰“å°æŒ‡å®šçš„è¯„ä¼°ç»“æœ

```python
# å®šä¹‰ trial_id å’Œ question_id çš„è¾“å…¥æ¡†
trial_id_input = widgets.IntText(
    value=3,  # é»˜è®¤å€¼
    description='Trial ID:',
)

question_id_input = widgets.IntText(
    value=1,  # é»˜è®¤å€¼
    description='Question ID:',
)

# å¦‚æœä½ æƒ³å®šä¹‰ trial_id å’Œ question_id çš„æ»‘å—çš„è¯ä½¿ç”¨ä¸‹é¢çš„ä»£ç 
"""
trial_id_input = widgets.IntSlider(
    value=3,  # é»˜è®¤å€¼
    min=1,    # æœ€å°å€¼
    max=3,    # æœ€å¤§å€¼
    step=1,   # æ­¥é•¿
    description='Trial ID:',
    continuous_update=False  # æ»‘å—æ”¾å¼€åæ‰æ›´æ–°
)

question_id_input = widgets.IntSlider(
    value=1,  # é»˜è®¤å€¼
    min=1,    # æœ€å°å€¼
    max=eval_num,   # æœ€å¤§å€¼ï¼ˆæ ¹æ®å®é™… eval_num çš„èŒƒå›´è°ƒæ•´ï¼‰
    step=1,   # æ­¥é•¿
    description='Question ID:',
    continuous_update=False  # æ»‘å—æ”¾å¼€åæ‰æ›´æ–°
)
"""

# æ˜¾ç¤ºè¾“å‡º
output_result = widgets.Output()

def on_evaluate(change=None):
    """
    è¯„ä¼°å€¼å˜åŒ–æ—¶çš„å›è°ƒå‡½æ•°
    
    å‚æ•°:
        change (dict): åŒ…å«å˜åŒ–ä¿¡æ¯çš„å­—å…¸
    """
    with output_result:
        output_result.clear_output()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º
        trial_id = trial_id_input.value
        question_id = question_id_input.value
        
        if trial_id not in [1, 2, 3]:
            print("trial_id åªèƒ½æ˜¯ 1, 2 æˆ– 3ã€‚")
        elif question_id not in [i for i in range(1, eval_num + 1)]:
            print(f"question_id åªèƒ½åœ¨ 1 åˆ° {eval_num} ä¹‹é—´ã€‚")
        else:
            result_index = (trial_id - 1) * eval_num + question_id - 1
            print(f"ç¬¬ {trial_id} æ¬¡è¯•éªŒä¸­ï¼Œç¬¬ {question_id} ä¸ªé—®é¢˜çš„è¯„ä¼°ç»“æœæ˜¯:\n{res_list[result_index]}")

# ç›‘å¬å€¼å˜åŒ–å¹¶æ‰§è¡Œè¯„ä¼°é€»è¾‘
trial_id_input.observe(on_evaluate, names='value')
question_id_input.observe(on_evaluate, names='value')

# æ‰‹åŠ¨è°ƒç”¨ on_evaluate() ä»¥æ˜¾ç¤ºé»˜è®¤å€¼å¯¹åº”çš„è¾“å‡º
on_evaluate()

# æ˜¾ç¤ºè¾“å…¥æ¡†å’Œè¾“å‡º
display(trial_id_input, question_id_input, output_result)
```

å¯ä»¥çœ‹åˆ°å®é™…ä¸Š ipywidget ä¹Ÿå¯ä»¥æä¾›ä¸€ä¸ªéå¸¸ç›´è§‚çš„ç•Œé¢ï¼ˆè™½ç„¶ä¸å¤Ÿç¾è§‚ï¼‰ï¼š

![image-20240911212506784](./assets/image-20240911212506784.png)

### ä¿å­˜ä½ çš„ Propmt

å¦‚æœä½ éœ€è¦çš„è¯ã€‚

```python
prompt_dict = {
    'prompt': custom_prompt
}

with open('prompt.json', 'w') as f:
    json.dump(prompt_dict, f)

print("Prompt å·²ä¿å­˜ä¸º prompt.json æ–‡ä»¶")
```

## å‚è€ƒé“¾æ¥

[HW4 è§†é¢‘](https://www.bilibili.com/video/BV1BJ4m1e7g8?p=15&vd_source=436107f586d66ab4fcf756c76eb96c35) 

[HW4 - Colab](https://colab.research.google.com/drive/16JzVN_Mu4mJfyHQpQEuDx1q6jI-cAnEl?hl=zh-tw#scrollTo=ZvU3-01m3wmy&uniqifier=1)

