# ç”¨ API å®ç° AI è§†é¢‘æ‘˜è¦ï¼šåŠ¨æ‰‹åˆ¶ä½œå±äºä½ çš„ AI è§†é¢‘å°åŠ©æ‰‹

> AI è§†é¢‘æ‘˜è¦æƒ³å¿…ä½ ä¸€å®šä¸é™Œç”Ÿï¼Œåœ¨å„å¤§è§†é¢‘å¹³å°ï¼Œæ¯”å¦‚ B ç«™ï¼Œè¯„è®ºåŒºçš„ AI è§†é¢‘å°åŠ©æ‰‹å°±å¦‚é›¨åæ˜¥ç¬‹èˆ¬éåœ°éƒ½æ˜¯ã€‚
>
> ä»Šå¤©ï¼Œè®©æˆ‘ä»¬æ¥å¡«äº†è¿™â€œæŠ¤åŸæ²³â€ï¼Œç«™åˆ°å¢™ä¸Šçœ‹ä¸€çœ‹å®ƒçš„å…¨è²Œã€‚
>
> **ç®€è€Œè¨€ä¹‹ï¼ŒAI è§†é¢‘æ‘˜è¦çš„å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š**
>
> 1. **è§†é¢‘ â†’ éŸ³é¢‘ï¼ˆMP3ï¼‰**
> 2. **éŸ³é¢‘ â†’ å­—å¹•ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰**
> 3. **å­—å¹• â†’ AI æ‘˜è¦**
>
> æ˜¯ä¸æ˜¯å¾ˆç®€å•ï¼Ÿä½ å¯èƒ½ä¼šå¥½å¥‡ï¼ŒAI è§†é¢‘å°åŠ©æ‰‹çœŸçš„â€œçœ‹â€è§†é¢‘äº†å—ï¼Ÿå…¶å®å¤§æ¦‚ç‡æ˜¯æ²¡æœ‰çš„ï¼Œå®ƒåªæ˜¯åˆ†æäº†å­—å¹•å’Œå¯¹åº”çš„æ—¶é—´æˆ³ã€‚å“¦ï¼Œå¯¹äº†ï¼Œæ—¶é—´æˆ³å¯¹åº”å­—å¹•å‘ç”Ÿçš„æ—¶é—´ã€‚
>
> AI è§†é¢‘æ‘˜è¦çœ‹ä¼¼æœ‰äº›å¤¸å¤§å…¶è¯ï¼Œä½†å®é™…ä¸Šå´åå‰¯å…¶å®ã€‚å› ä¸ºå¯¹äºç»å¤§å¤šæ•°ä¿¡æ¯é‡ä¸°å¯Œï¼Œéœ€è¦æ€»ç»“çš„è§†é¢‘æ¥è¯´ï¼ŒéŸ³é¢‘è•´å«çš„ä¿¡æ¯è¶³ä»¥è´¯ç©¿å…¨æ–‡ï¼ˆå®é™…ä¸Šï¼Œå®ƒæ›´åƒæ˜¯â€œAI éŸ³é¢‘æ‘˜è¦â€ï¼Œä¸è¿‡â€œAI è§†é¢‘æ‘˜è¦â€æ˜¾ç„¶æ›´æœ‰å™±å¤´ï¼‰ã€‚
>
> è¿™ç¯‡æ–‡ç« å°†å¸¦ä½ ä¸€æ­¥æ­¥çš„å®ç° AI æ‘˜è¦åŠŸèƒ½ã€‚åŒæ—¶ï¼Œä¹Ÿä¸º[ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯¼è®º](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)è¯¾ç¨‹ä¸­ [HW9: Quick Summary of Lecture Video](https://colab.research.google.com/drive/1Ysr25kz6lP7gR8DNTkJMAqOuMp2bhXes?usp=sharing#scrollTo=UULEr1GpDAl6) æä¾›ä¸­æ–‡å¼•å¯¼ã€‚
>
> **å»ºè®®æ­é…ä»£ç æ–‡ä»¶é€å—è¿è¡Œçš„åŒæ—¶ç†è§£æ–‡ç« ã€‚ **
> **æ³¨æ„ï¼Œè¿™é‡Œæ²¡æœ‰ä»»ä½•æ¨¡å‹ä¼šè¢«è®­ç»ƒã€‚** 
>
> ä»£ç æ–‡ä»¶ä¸‹è½½: [äº¤äº’å®Œæ•´ç‰ˆ](../Demos/13a.%20è½»æ¾å¼€å§‹ä½ çš„ç¬¬ä¸€æ¬¡%20AI%20è§†é¢‘æ€»ç»“ï¼ˆAPI%20ç‰ˆï¼‰%20-%20å®Œæ•´ç‰ˆ.ipynb) | [éäº¤äº’ç²¾ç®€ç‰ˆ](../Demos/13b.%20è½»æ¾å¼€å§‹ä½ çš„ç¬¬ä¸€æ¬¡%20AI%20è§†é¢‘æ€»ç»“ï¼ˆAPI%20ç‰ˆï¼‰-%20ç²¾ç®€ç‰ˆ.ipynb) |  [ğŸ¡AI Summarizer è„šæœ¬](../CodePlayground/summarizer.py)
>
> åœ¨çº¿é“¾æ¥ï¼ˆç²¾ç®€ç‰ˆï¼‰ï¼š[Kaggle](https://www.kaggle.com/code/aidemos/13b-ai-api) | [Colab](https://colab.research.google.com/drive/1yh2J4_Cy45fqvydH34LLtDpw10kuWutO?usp=sharing)

## ç›®å½•

- [ç¬¬ 0 éƒ¨åˆ† - è¿è¡Œè„šæœ¬ï¼ˆæ¨èï¼Œä½†å¯ä»¥è·³è¿‡ï¼‰](#ç¬¬-0-éƒ¨åˆ†---è¿è¡Œè„šæœ¬æ¨èä½†å¯ä»¥è·³è¿‡)
- [ç¬¬ 1 éƒ¨åˆ† - å‡†å¤‡å·¥ä½œ](#ç¬¬-1-éƒ¨åˆ†---å‡†å¤‡å·¥ä½œ)
  - [è§†é¢‘è½¬éŸ³é¢‘](#è§†é¢‘è½¬éŸ³é¢‘)
     - [Linuxï¼š](#linux)
     - [MacOS](#macos)
     - [Windowsï¼š](#windows)
  - [å‡†å¤‡éŸ³é¢‘æ–‡ä»¶](#å‡†å¤‡éŸ³é¢‘æ–‡ä»¶)
  - [å®‰è£…å¿…è¦çš„åº“](#å®‰è£…å¿…è¦çš„åº“)
  - [å¯¼å…¥åº“](#å¯¼å…¥åº“)
  - [åŠ è½½æ•°æ®](#åŠ è½½æ•°æ®)
     - [ç›´æ¥åŠ è½½ .mp3 æ–‡ä»¶](#ç›´æ¥åŠ è½½-mp3-æ–‡ä»¶)
- [ç¬¬ 2 éƒ¨åˆ† - è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR)](#ç¬¬-2-éƒ¨åˆ†---è‡ªåŠ¨è¯­éŸ³è¯†åˆ«-asr)
  - [å®šä¹‰è¯­éŸ³è¯†åˆ«å‡½æ•°](#å®šä¹‰è¯­éŸ³è¯†åˆ«å‡½æ•°)
  - [è®¾ç½®å‚æ•°](#è®¾ç½®å‚æ•°)
  - [è¿è¡Œè¯­éŸ³è¯†åˆ«](#è¿è¡Œè¯­éŸ³è¯†åˆ«)
  - [æ£€æŸ¥ç»“æœ](#æ£€æŸ¥ç»“æœ)
- [ç¬¬ 3 éƒ¨åˆ† - å¤„ç†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çš„ç»“æœ](#ç¬¬-3-éƒ¨åˆ†---å¤„ç†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çš„ç»“æœ)
  - [æå–å­—å¹•æ–‡æœ¬](#æå–å­—å¹•æ–‡æœ¬)
  - [æ‹†åˆ†æ–‡æœ¬](#æ‹†åˆ†æ–‡æœ¬)
  - [æ‰§è¡Œæ–‡æœ¬å¤„ç†](#æ‰§è¡Œæ–‡æœ¬å¤„ç†)
- [ç¬¬ 4 éƒ¨åˆ† - æ–‡æœ¬æ‘˜è¦](#ç¬¬-4-éƒ¨åˆ†---æ–‡æœ¬æ‘˜è¦)
  - [è®¾ç½® OpenAI API](#è®¾ç½®-openai-api)
  - [è®¾ç½®å‚æ•°](#è®¾ç½®å‚æ•°-1)
  - [å®šä¹‰æ‘˜è¦å‡½æ•°](#å®šä¹‰æ‘˜è¦å‡½æ•°)
  - [è¿™é‡Œæ¼”ç¤ºä¸¤ç§æ‘˜è¦æ–¹å¼](#è¿™é‡Œæ¼”ç¤ºä¸¤ç§æ‘˜è¦æ–¹å¼)
     - [æ–¹æ³•ä¸€ï¼šæ‹†åˆ†ä¸ºå¤šæ®µè¿›è¡Œæ‘˜è¦ï¼ˆMulti-Stage Summarizationï¼‰- MapReduce](#æ–¹æ³•ä¸€æ‹†åˆ†ä¸ºå¤šæ®µè¿›è¡Œæ‘˜è¦multi-stage-summarization--mapreduce)
     - [æ–¹æ³•äºŒï¼šç²¾ç‚¼æ–¹æ³•ï¼ˆthe method of Refinement) - Refine](#æ–¹æ³•äºŒç²¾ç‚¼æ–¹æ³•the-method-of-refinement---refine)
- [æ€»ç»“ä¸å±•æœ›](#æ€»ç»“ä¸å±•æœ›)
  - [å¯¹æ·±åº¦å­¦ä¹ ä¸€çªä¸é€šä¹Ÿå¯ä»¥åšå‡º AI åº”ç”¨å—ï¼Ÿ](#å¯¹æ·±åº¦å­¦ä¹ ä¸€çªä¸é€šä¹Ÿå¯ä»¥åšå‡º-ai-åº”ç”¨å—)
  - [å¯èƒ½çš„ç–‘é—®](#å¯èƒ½çš„ç–‘é—®)

## ç¬¬ 0 éƒ¨åˆ† - è¿è¡Œè„šæœ¬ï¼ˆæ¨èï¼Œä½†å¯ä»¥è·³è¿‡ï¼‰

> å¦‚æœä½ å°šæœªé…ç½®è¿è¡Œç¯å¢ƒï¼Œè¯·å‚ç…§ [README](../CodePlayground#codeplayground)ã€‚

å»ºè®®è¿è¡Œ [ğŸ¡AI Summarizer è„šæœ¬](../CodePlayground/summarizer.py)è·å¾—ç›´è§‚çš„ä½“éªŒã€‚

![Pipeline](./assets/image-20240926154540268.png)

1. å…‹éš†æ•´ä¸ªä»“åº“ï¼Œç¡®ä¿ç›¸å…³é…ç½®æ–‡ä»¶å’Œæ ·ä¾‹è§†é¢‘è¢«ä¸‹è½½ï¼š

    ```bash
    git clone https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN.git
    cd AI-Guide-and-Demos-zh_CN/CodePlayground
    ```

2. å‘½ä»¤è¡Œè¿è¡Œï¼š

    ```bash
    python summarizer.py examples/summarizer.mp4
    ```

    ä½ ä¼šè¢«è¦æ±‚è¾“å…¥ä½ çš„ API å¯†é’¥ï¼Œéšåä½ å°†è·å¾—ä»¥ä¸‹ä¸‰ä¸ªæ–‡ä»¶ï¼š

    - `output/summarizer.mp3` - éŸ³é¢‘æ–‡ä»¶
    - `output/summarizer.srt` - å­—å¹•æ–‡ä»¶
    - `output/summarizer.summary.txt` - æ‘˜è¦æ–‡ä»¶

    ä½ å¯ä»¥æ£€æŸ¥è¿™äº›æ–‡ä»¶ï¼Œå¹¶åœ¨åç»­æ­¥éª¤ä¸­ä½¿ç”¨å®ƒä»¬ï¼ˆå¦‚æœä½ æƒ³çš„è¯ï¼‰ã€‚
    

## ç¬¬ 1 éƒ¨åˆ† - å‡†å¤‡å·¥ä½œ

> ä¹‹å‰è£…è¿‡çš„æ¨¡å—å¯ä»¥è·³è¿‡ã€‚

### è§†é¢‘è½¬éŸ³é¢‘

ä½ å¯ä»¥è‡ªå·±å‡†å¤‡ä¸€ä¸ªè§†é¢‘æ–‡ä»¶è¿›è¡Œå®éªŒï¼Œä¹Ÿå¯ä»¥è·³è¿‡è¿™ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»ä¸ºä½ æä¾›äº†ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚å‡è®¾ä½ å‡†å¤‡çš„æ˜¯ `.mp4` æ ¼å¼çš„è§†é¢‘æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ `ffmpeg` è½»æ¾å°†å…¶è½¬æ¢ä¸º `.mp3` æ ¼å¼ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… `ffmpeg`ã€‚é€‰æ‹©ä½ çš„æ“ä½œç³»ç»Ÿè¿›è¡Œï¼š

#### Linuxï¼š

```bash
sudo apt-get install ffmpeg
```

#### MacOS

```bash
brew install ffmpeg
```

#### Windowsï¼š

1. å‰å¾€ [FFmpeg å®˜ç½‘](https://ffmpeg.org/download.html) ä¸‹è½½å¯¹åº”çš„å®‰è£…åŒ…ã€‚
2. æŒ‰ç…§æ•™ç¨‹å®‰è£…å¹¶å°† `ffmpeg` è·¯å¾„æ·»åŠ åˆ°ç¯å¢ƒå˜é‡ã€‚

å®‰è£…å®Œæˆåï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†è§†é¢‘æ–‡ä»¶ï¼ˆinput_video.mp4ï¼‰è½¬ä¸º MP3 éŸ³é¢‘ï¼ˆoutput_audio.mp3ï¼‰ï¼Œä½ éœ€è¦ä¿®æ”¹å¯¹åº”æ–‡ä»¶åï¼š

```bash
ffmpeg -i input_video.mp4 -q:a 0 -map a output_audio.mp3
```

å‚æ•°è§£é‡Šï¼š

- `-i input_video.mp4`ï¼šæŒ‡å®šè¾“å…¥çš„è§†é¢‘æ–‡ä»¶ã€‚
- `-q:a 0`ï¼šè®¾ç½®éŸ³é¢‘è´¨é‡ï¼Œ`0` ä¸ºæœ€é«˜éŸ³é¢‘è´¨é‡ã€‚
- `-map a`ï¼šåªæå–éŸ³é¢‘éƒ¨åˆ†ã€‚
- `output_audio.mp3`ï¼šæŒ‡å®šè¾“å‡ºçš„éŸ³é¢‘æ–‡ä»¶åã€‚

### å‡†å¤‡éŸ³é¢‘æ–‡ä»¶

ä¸ºäº†å¯¹é½è¯¾ç¨‹ä½œä¸šï¼Œæˆ‘ä»¬ä½¿ç”¨æç³å±±æ•™æˆã€Šä¿¡å·ä¸äººç”Ÿ (2023)ã€‹æ¼”è®²çš„ä¸€ä¸ªç‰‡æ®µï¼ˆä» 1:43:24 åˆ° 2:00:49ï¼‰ï¼Œå·²ç»ä¸Šä¼ äº†å¯¹åº”çš„ [MP3 æ–‡ä»¶](../Demos/data/13/audio.mp3)ã€‚

å¦‚æœä½ æ„Ÿå…´è¶£ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ä»¥ä¸‹é“¾æ¥æŸ¥çœ‹åŸå§‹è§†é¢‘ï¼š

- **è§†é¢‘é“¾æ¥**ï¼š
  - [Bilibili](https://www.bilibili.com/video/BV14P411B7Le)
  - [YouTube](https://www.youtube.com/watch?v=MxoQV4M0jY8)

### å®‰è£…å¿…è¦çš„åº“

åœ¨å¼€å§‹ä¹‹å‰ï¼Œéœ€è¦å®‰è£…ä¸€äº›å¿…è¦çš„ Python åº“ï¼š

```bash
pip install srt
pip install datasets
pip install DateTime
pip install OpenCC==1.1.6
pip install opencv-contrib-python
pip install opencv-python
pip install opencv-python-headless
pip install openpyxl
pip install openai
pip install git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab
pip install numpy
pip install soundfile
pip install ipywidgets
pip install librosa
#pip install 'httpx<0.28.0' # é™çº§ httpx ä»¥è§£å†³å…³é”®å­— 'proxies' è¢«ç§»é™¤çš„é—®é¢˜ï¼Œæœ€æ–°çš„ openai åº“ä¸ä¼šå¼•å‘è¯¥é—®é¢˜ï¼Œæ•…é»˜è®¤æ³¨é‡Š
```

### å¯¼å…¥åº“

```python
# æ ‡å‡†åº“
import os
import time
import re
import pathlib
import textwrap
import datetime

# ç¬¬ä¸‰æ–¹åº“
import numpy as np
import srt
import soundfile as sf
from tqdm import tqdm

# é¡¹ç›®ç›¸å…³åº“
import whisper
from datasets import load_dataset
from openai import OpenAI
```

### åŠ è½½æ•°æ®

å¯¹åº”çš„æ•°æ®æ–‡ä»¶æ¥è‡ªäºï¼š[kuanhuggingface/NTU-GenAI-2024-HW9](https://huggingface.co/datasets/kuanhuggingface/NTU-GenAI-2024-HW9/tree/main)ã€‚

[Parquet](../Demos/data/13/test-00000-of-00001.parquet) æ–‡ä»¶ä¹Ÿå·²ç»ä¸Šä¼ è‡³ `data` æ–‡ä»¶å¤¹ï¼Œæ— éœ€å†ä¸‹è½½ã€‚

```python
# åŠ è½½æœ¬åœ° Parquet æ ¼å¼çš„æ•°æ®é›†
dataset = load_dataset('parquet', data_files={'test': './data/13/test-00000-of-00001.parquet'})

# å‡†å¤‡éŸ³é¢‘
input_audio = dataset["test"]["audio"][0]
input_audio_name = input_audio["path"]
input_audio_array = input_audio["array"].astype(np.float32)
sampling_rate = input_audio["sampling_rate"]
```

åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œ`input_audio_array` åŒ…å«äº†éŸ³é¢‘æ•°æ®ï¼Œ`input_audio_name` æ˜¯éŸ³é¢‘æ–‡ä»¶åï¼Œ`sampling_rate` æ˜¯é‡‡æ ·ç‡ã€‚

#### ç›´æ¥åŠ è½½ .mp3 æ–‡ä»¶

é‚£å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨ .mp3 æ–‡ä»¶è€Œä¸æ˜¯è¿™ä¸ªä»æ¥æ²¡è§è¿‡çš„æ–‡ä»¶æ ¼å¼çš„è¯ï¼Œåº”è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ

ä»¥ `Demos/data/13/audio.mp3` çš„æ–‡ä»¶ä¸ºä¾‹ï¼š

```python
import librosa

# æŒ‡å®š MP3 æ–‡ä»¶è·¯å¾„
mp3_file_path = './data/13/audio.mp3'

input_audio_name = os.path.basename(mp3_file_path)

# åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼ŒæŒ‡å®šé‡‡æ ·ç‡ä¸º 16000
input_audio_array, sampling_rate = librosa.load(mp3_file_path, sr=16000)

# æ‰“å°éŸ³é¢‘æ•°æ®çš„é‡‡æ ·ç‡å’Œå½¢çŠ¶ï¼Œç¡®ä¿åŠ è½½æˆåŠŸ
print(f"é‡‡æ ·ç‡: {sampling_rate}")
print(f"éŸ³é¢‘æ•°æ®å½¢çŠ¶: {input_audio_array.shape}")

print(f"ç°åœ¨æˆ‘ä»¬å°†è½¬å½•éŸ³é¢‘: ({input_audio_name})ã€‚")
```

å…·ä½“å˜é‡å’Œå‚æ•°è§£é‡Šï¼š

- `input_audio_array`ï¼šéŸ³é¢‘æ•°æ®çš„ NumPy æ•°ç»„è¡¨ç¤ºã€‚
- `sampling_rate`ï¼šéŸ³é¢‘çš„é‡‡æ ·ç‡ï¼ˆHzï¼‰ã€‚
- `input_audio_name`ï¼šéŸ³é¢‘æ–‡ä»¶åï¼Œä»…ä¿ç•™æ–‡ä»¶åï¼Œä¸åŒ…å«è·¯å¾„ã€‚
- **æ³¨æ„**ï¼šæˆ‘ä»¬ä½¿ç”¨ `sr=16000`ï¼Œå°†éŸ³é¢‘é‡‡æ ·ç‡è½¬æ¢ä¸º Whisper æ¨¡å‹è¦æ±‚çš„ 16000 Hzï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ­£ç¡®å¤„ç†éŸ³é¢‘æ•°æ®ã€‚

è¿™æ ·ï¼Œæˆ‘ä»¬å°±å®Œæˆäº†éŸ³é¢‘æ–‡ä»¶çš„å¯¼å…¥ã€‚ä½ å¯ä»¥è¿›ä¸€æ­¥æ›¿æ¢æˆä½ è‡ªå·±çš„ .mp3 æ–‡ä»¶ã€‚

## ç¬¬ 2 éƒ¨åˆ† - è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR)

> **Automatic Speech Recognition**
> ![image-20240926155151471](./assets/image-20240926155151471.png)
>
> Whisper æ˜¯ OpenAI å¼€æºçš„é€šç”¨è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œæ”¯æŒå¤šç§è¯­è¨€çš„è¯­éŸ³è¯†åˆ«ä»»åŠ¡ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¸ºéŸ³é¢‘æ–‡ä»¶ç”Ÿæˆå¸¦æœ‰æ—¶é—´æˆ³çš„å­—å¹•ï¼Œåœ¨[è®ºæ–‡](https://arxiv.org/abs/2212.04356)ä¸­ï¼Œä½œè€…æåˆ°ï¼šâ€œæˆ‘ä»¬ä½¿ç”¨äº† 68 ä¸‡å°æ—¶çš„å¤šè¯­è¨€å’Œå¤šä»»åŠ¡ç›‘ç£æ•°æ®è®­ç»ƒäº†è¯¥æ¨¡å‹ã€‚â€
>
> æ‰€ä»¥ä½ å¯ä»¥ç›¸ä¿¡å®ƒçš„èƒ½åŠ›ï¼Œæ„Ÿè°¢å¼€æºç²¾ç¥ã€‚

æ¥ä¸‹æ¥ï¼Œä½ å¯ä»¥å°†æŸæ®µä¼šè®®çš„éŸ³é¢‘å½•åˆ¶ä½œä¸ºè¾“å…¥ï¼ŒæŸ¥çœ‹è½¬å½•åçš„æ•ˆæœã€‚æˆ‘ä»¬å°†åˆ©ç”¨ Whisper æ¨¡å‹æ¥å¸¦ä½ å®Œæˆ ASRã€‚ä¸‹å›¾æ˜¯å¤„ç†çš„æ ·ä¾‹è¿‡ç¨‹ï¼š

![image-20240926155512340](./assets/image-20240926155512340.png)

### å®šä¹‰è¯­éŸ³è¯†åˆ«å‡½æ•°

```python
def speech_recognition(model_name, input_audio, output_subtitle_path, decode_options, cache_dir="./"):
    # åŠ è½½æ¨¡å‹
    model = whisper.load_model(name=model_name, download_root=cache_dir)

    # è½¬å½•éŸ³é¢‘
    transcription = model.transcribe(
        audio=input_audio,
        language=decode_options["language"],
        verbose=False,
        initial_prompt=decode_options["initial_prompt"],
        temperature=decode_options["temperature"]
    )

    # å¤„ç†è½¬å½•ç»“æœï¼Œç”Ÿæˆå­—å¹•æ–‡ä»¶
    subtitles = []
    for i, segment in enumerate(transcription["segments"]):
        start_time = datetime.timedelta(seconds=segment["start"])
        end_time = datetime.timedelta(seconds=segment["end"])
        text = segment["text"]
        subtitles.append(srt.Subtitle(index=i, start=start_time, end=end_time, content=text))

    srt_content = srt.compose(subtitles)

    # ä¿å­˜å­—å¹•æ–‡ä»¶
    with open(output_subtitle_path, "w", encoding="utf-8") as file:
        file.write(srt_content)

    print(f"å­—å¹•å·²ä¿å­˜åˆ° {output_subtitle_path}")
```

### è®¾ç½®å‚æ•°

æ³¨æ„ï¼Œè¿™é‡Œè®¾ç½®çš„å‚æ•°éƒ½æ˜¯ Whisper ç›¸å…³çš„ï¼Œä¸åç»­çš„ AI æ‘˜è¦ä¸åŒã€‚

ä½ å¯ä»¥é€šè¿‡ model_name è®¾ç½®ä¸åŒçš„æ¨¡å‹ï¼Œä½¿ç”¨**æ ‡è¯†**æŒ‡å®šã€‚é€šè¿‡[å®˜æ–¹ä»“åº“](https://github.com/openai/whisper)æ‰€æä¾›çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸åŒæ¨¡å‹éœ€è¦çš„æ˜¾å­˜å¤§å°ï¼š

| Size   | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |
| ------ | ---------- | ------------------ | ------------------ | ------------- | -------------- |
| tiny   | 39 M       | `tiny.en`          | `tiny`             | ~1 GB         | ~32x           |
| base   | 74 M       | `base.en`          | `base`             | ~1 GB         | ~16x           |
| small  | 244 M      | `small.en`         | `small`            | ~2 GB         | ~6x            |
| medium | 769 M      | `medium.en`        | `medium`           | ~5 GB         | ~2x            |
| large  | 1550 M     | N/A                | `large`            | ~10 GB        | 1x             |

**è§£é‡Šï¼š**

- **Size (å¤§å°)**ï¼šè¡¨ç¤ºæ¨¡å‹çš„å°ºå¯¸ï¼Œä¸åŒå¤§å°çš„æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„æ•°æ®é‡ä¸åŒï¼Œå› æ­¤æ€§èƒ½å’Œç²¾åº¦ä¹Ÿä¸åŒã€‚è¾ƒå¤§çš„æ¨¡å‹é€šå¸¸ä¼šæœ‰æ›´é«˜çš„ç²¾åº¦ã€‚`Medium` æ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ï¼Œ`tiny` å’Œ `base` æ•ˆæœä¸€èˆ¬ï¼Œç”¨äºå­¦ä¹ çš„è¯ä¹Ÿå¯ä»¥ã€‚
- **Parameters (å‚æ•°é‡)**ï¼šæ¨¡å‹çš„å‚æ•°æ•°é‡ï¼Œè¡¨ç¤ºæ¨¡å‹çš„å¤æ‚åº¦ã€‚å‚æ•°è¶Šå¤šï¼Œæ¨¡å‹çš„æ€§èƒ½é€šå¸¸è¶Šå¥½ï¼Œä½†ä¹Ÿä¼šå ç”¨æ›´å¤šçš„è®¡ç®—èµ„æºã€‚
- **English-only model (ä»…é™è‹±æ–‡æ¨¡å‹)**ï¼šæ¨¡å‹çš„**æ ‡è¯†**åç§°ï¼Œåªç”¨äºå¤„ç†è‹±æ–‡éŸ³é¢‘è½¬å½•ï¼Œé€‚ç”¨äºä»…éœ€è¦å¤„ç†è‹±æ–‡è¯­éŸ³çš„åœºæ™¯ã€‚
- **Multilingual model (å¤šè¯­è¨€æ¨¡å‹)**ï¼šæ¨¡å‹çš„**æ ‡è¯†**åç§°ï¼Œç”¨äºåœ¨ä»£ç ä¸­åŠ è½½ç›¸åº”çš„æ¨¡å‹ï¼Œå¯¹åº”äºæ¥ä¸‹æ¥çš„ `model_name` å‚æ•°ã€‚
- **Required VRAM (æ‰€éœ€æ˜¾å­˜)**ï¼šæŒ‡è¿è¡Œè¯¥æ¨¡å‹æ—¶æ‰€éœ€çš„æ˜¾å­˜å¤§å°ã€‚å¦‚æœä½ å¯¹å‚æ•°å’Œæ˜¾å­˜çš„å¯¹åº”å…³ç³»æ„Ÿå…´è¶£ï¼Œå¯ä»¥é˜…è¯»ä¹‹å‰çš„æ–‡ç« ï¼š[ã€Š07. æ¢ç©¶æ¨¡å‹å‚æ•°ä¸æ˜¾å­˜çš„å…³ç³»ä»¥åŠä¸åŒç²¾åº¦é€ æˆçš„å½±å“.mdã€‹](../Guide/07.%20æ¢ç©¶æ¨¡å‹å‚æ•°ä¸æ˜¾å­˜çš„å…³ç³»ä»¥åŠä¸åŒç²¾åº¦é€ æˆçš„å½±å“.md)ã€‚
- **Relative speed (ç›¸å¯¹é€Ÿåº¦)**ï¼šç›¸å¯¹é€Ÿåº¦è¡¨ç¤ºæ¨¡å‹å¤„ç†è¯­éŸ³è½¬å½•ä»»åŠ¡çš„æ•ˆç‡ã€‚æ•°å­—è¶Šå¤§ï¼Œæ¨¡å‹å¤„ç†é€Ÿåº¦è¶Šå¿«ï¼Œä¸æ¨¡å‹çš„å‚æ•°é‡æˆåæ¯”ã€‚

```python
# æ¨¡å‹åç§°ï¼Œå¯é€‰ 'tiny', 'base', 'small', 'medium', 'large-v3'
model_name = 'medium'

# è¯­è¨€
language = 'zh'  # é€‰æ‹©è¯­éŸ³è¯†åˆ«çš„ç›®æ ‡è¯­è¨€ï¼Œå¦‚ 'zh' è¡¨ç¤ºä¸­æ–‡

# åˆå§‹ promptï¼Œå¯é€‰
initial_prompt = 'è¯·ç”¨ä¸­æ–‡'  # å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä¸º Whisper æ¨¡å‹è®¾ç½®åˆå§‹ prompt è¯­å¥

# é‡‡æ ·æ¸©åº¦ï¼Œæ§åˆ¶æ¨¡å‹çš„è¾“å‡ºå¤šæ ·æ€§
temperature = 0.0  # 0 è¡¨ç¤ºæœ€ç¡®å®šæ€§çš„è¾“å‡ºï¼ŒèŒƒå›´ä¸º 0-1

# è¾“å‡ºæ–‡ä»¶åç¼€
suffix = 'ä¿¡å·ä¸äººç”Ÿ'

# å­—å¹•æ–‡ä»¶è·¯å¾„
output_subtitle_path = f"./output-{suffix}.srt"

# æ¨¡å‹ç¼“å­˜ç›®å½•
cache_dir = './'
```

**initial_prompt**ï¼šè¿™ä¸ªå‚æ•°ç”¨äºè®¾ç½® Whisper æ¨¡å‹è½¬å½•ä»»åŠ¡çš„åˆå§‹æç¤ºï¼Œä¸ºæ¨¡å‹æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å¯¹äºä¸è¿ç»­çš„å¯¹è¯æˆ–è€…éœ€è¦ä¿æŒä¸€è‡´æ€§çš„è½¬å½•ä»»åŠ¡ï¼Œ`initial_prompt` å¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹åç»­çš„è¯­éŸ³å†…å®¹ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ä¸€ä¸ªåˆ†æ®µçš„é•¿è§†é¢‘ï¼Œå¹¶ä¸”æ¯æ®µè§†é¢‘ä¹‹é—´æœ‰ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä½ å¯ä»¥ä½¿ç”¨ `initial_prompt` æ¥å‘ŠçŸ¥æ¨¡å‹å½“å‰çš„è¯­å¢ƒã€‚

### è¿è¡Œè¯­éŸ³è¯†åˆ«

```python
# æ„å»ºè§£ç é€‰é¡¹
decode_options = {
    "language": language,
    "initial_prompt": initial_prompt,
    "temperature": temperature
}

# è¿è¡Œ ASR
speech_recognition(
    model_name=model_name,
    input_audio=input_audio_array,
    output_subtitle_path=output_subtitle_path,
    decode_options=decode_options,
    cache_dir=cache_dir
)
```

è¿è¡ŒæˆåŠŸåï¼ŒWhisper æ¨¡å‹ä¼šç”Ÿæˆå¸¦æœ‰æ—¶é—´æˆ³çš„å­—å¹•æ–‡ä»¶ï¼ˆ.srt æ ¼å¼ï¼‰ï¼Œä¿å­˜åœ¨ä½ æŒ‡å®šçš„è·¯å¾„ä¸­ã€‚

![image-20240924133743569](./assets/image-20240924133743569.png)

### æ£€æŸ¥ç»“æœ

```python
# è¯»å–å¹¶æ‰“å°å­—å¹•å†…å®¹
with open(output_subtitle_path, 'r', encoding='utf-8') as file:
    content = file.read()
print(content)
```

ä½ å°†çœ‹åˆ°ç”Ÿæˆçš„å­—å¹•å†…å®¹ï¼ŒåŒ…æ‹¬æ—¶é—´æˆ³å’Œå¯¹åº”çš„æ–‡å­—ã€‚

![image-20240924133837165](./assets/image-20240924133837165.png)

**JUST DO IT**

## ç¬¬ 3 éƒ¨åˆ† - å¤„ç†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çš„ç»“æœ

åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å¤„ç†é€šè¿‡ Whisper æ¨¡å‹ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶ï¼ˆSRT æ–‡ä»¶ï¼‰ï¼Œæå–å…¶ä¸­çš„çº¯æ–‡æœ¬å†…å®¹ï¼Œå¹¶å¯¹æ–‡æœ¬è¿›è¡Œæ‹†åˆ†ä»¥ä¾¿åç»­çš„å¤„ç†ã€‚

### æå–å­—å¹•æ–‡æœ¬

SRT æ–‡ä»¶åŒ…å«äº†å­—å¹•çš„ç´¢å¼•ã€æ—¶é—´æˆ³ï¼ˆå­—å¹•æ˜¾ç¤ºçš„èµ·å§‹å’Œç»“æŸæ—¶é—´ï¼‰ä»¥åŠå­—å¹•æ–‡æœ¬å†…å®¹ã€‚æˆ‘ä»¬è¿™é‡Œåšçš„æ˜¯ç®€å•å¤„ç†ï¼Œåªä¿ç•™äº†æ¯ä¸ªå­—å¹•æ¡ç›®çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œå»é™¤äº†æ—¶é—´æˆ³å’Œç´¢å¼•ä¿¡æ¯ã€‚

```python
def extract_and_save_text(srt_filename, output_filename):
    # è¯»å– SRT æ–‡ä»¶
    with open(srt_filename, 'r', encoding='utf-8') as file:
        content = file.read()

    # å»é™¤æ—¶é—´æˆ³å’Œç´¢å¼•
    pure_text = re.sub(r'\d+\n\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}\n', '', content)
    pure_text = re.sub(r'\n\n+', '\n', pure_text)

    # ä¿å­˜çº¯æ–‡æœ¬
    with open(output_filename, 'w', encoding='utf-8') as output_file:
        output_file.write(pure_text)

    print(f'æå–çš„æ–‡æœ¬å·²ä¿å­˜åˆ° {output_filename}')

    return pure_text
```

### æ‹†åˆ†æ–‡æœ¬

è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨äº† textwrap.wrap å‡½æ•°ï¼Œå°†çº¯æ–‡æœ¬æŒ‰ max_length ä¸ªå­—ç¬¦çš„é•¿åº¦è¿›è¡Œåˆ’åˆ†ã€‚

```python
def chunk_text(text, max_length):
    return textwrap.wrap(text, max_length)
```

æ¯ä¸ªç”Ÿæˆçš„æ–‡æœ¬å—éƒ½ä¼šåŒ…å«æœ€å¤š 512 ä¸ªå­—ç¬¦ï¼ˆåŒ…æ‹¬ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•çš„åˆ†å‰²æ–¹æ³•ã€‚

### æ‰§è¡Œæ–‡æœ¬å¤„ç†

è°ƒç”¨ä¹‹å‰çš„å‡½æ•°è¿›è¡Œæ–‡æœ¬æå–å’Œæ‹†åˆ†ã€‚

```python
# æ–‡æœ¬å—é•¿åº¦
chunk_length = 512

# æå–æ–‡æœ¬å¹¶æ‹†åˆ†
pure_text = extract_and_save_text(
    srt_filename=output_subtitle_path,
    output_filename=f"./output-{suffix}.txt",
)

chunks = chunk_text(text=pure_text, max_length=chunk_length)
```

## ç¬¬ 4 éƒ¨åˆ† - æ–‡æœ¬æ‘˜è¦

### è®¾ç½® OpenAI API

é¦–å…ˆï¼Œéœ€è¦è®¾ç½® OpenAI API å¯†é’¥ï¼Œè¿™é‡Œæ¼”ç¤ºä½¿ç”¨çš„æ˜¯**é˜¿é‡Œäº‘çš„å¤§æ¨¡å‹ API**ï¼Œä½ å¯ä»¥é€šè¿‡[ã€Š00. å¤§æ¨¡å‹APIè·å–æ­¥éª¤ã€‹](../Guide/00.%20å¤§æ¨¡å‹APIè·å–æ­¥éª¤.md)è·å– API å¯†é’¥ã€‚

å¦‚æœéœ€è¦ä½¿ç”¨å…¶ä»–å¹³å°ï¼Œè¯·å‚è€ƒå¯¹åº”çš„å¼€å‘æ–‡æ¡£åå¯¹åº”ä¿®æ”¹ `base_url`ã€‚

```python
# TODO: è®¾ç½®ä½ çš„ OPENAI API å¯†é’¥ï¼Œè¿™é‡Œä»¥é˜¿é‡Œäº‘ DashScope API ä¸ºä¾‹è¿›è¡Œæ¼”ç¤º
OPENAI_API_KEY = ""
# ä¸è®¾ç½®åˆ™é»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    
# æ„å»º OpenAI å®¢æˆ·ç«¯
client = OpenAI(
    api_key=openai_api_key,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1", 
)
```

### è®¾ç½®å‚æ•°

è¿™é‡Œå°±æ˜¯ AI æ‘˜è¦ç›¸å…³çš„å‚æ•°äº†ã€‚

```python
# æ¨¡å‹åç§°
model_name = 'qwen-turbo'

# æ§åˆ¶å“åº”çš„éšæœºæ€§
temperature = 0.0

# æ§åˆ¶å¤šæ ·æ€§
top_p = 1.0

# æœ€å¤§ç”Ÿæˆæ ‡è®°æ•°
max_tokens = 512
```

é»˜è®¤ä½¿ç”¨ qwen-turboï¼Œå…¶ä»–æ¨¡å‹å¯ä»¥å‚é˜…[æ¨¡å‹å¹¿åœº -- é˜¿é‡Œäº‘ç™¾ç‚¼](https://bailian.console.aliyun.com/?spm=5176.29619931.J__Z58Z6CX7MY__Ll8p1ZOR.1.4d1d59fcWwSqvr#/model-market)ï¼Œç‚¹å‡»å¯¹åº”æ¨¡å‹çš„`æŸ¥çœ‹è¯¦æƒ…`ã€‚

![image-20240924091151684](./assets/image-20240924091151684.png)

ä½ å¯ä»¥åœ¨ç•Œé¢å·¦ä¸Šè§’çœ‹åˆ°å¯¹åº”çš„è‹±æ–‡åç§°ï¼Œå¤åˆ¶å®ƒï¼Œç„¶åæ›¿æ¢ `model_name`ã€‚

![image-20240924091414350](./assets/image-20240924091414350.png)

ä½ å¯ä»¥éšæ„æ›´æ¢ä¸ºä½ æƒ³è¦çš„æ¨¡å‹ï¼Œä¸è¿‡å¯èƒ½è¦å…ˆç”³è¯·ä½¿ç”¨ï¼ˆé€šè¿‡å¤§æ¦‚è¦å‡ ä¸ªå°æ—¶ï¼Œä¼šæœ‰çŸ­ä¿¡æç¤ºï¼‰ã€‚

### å®šä¹‰æ‘˜è¦å‡½æ•°

```python
def summarization(client, summarization_prompt, model_name="qwen-turbo", temperature=0.0, top_p=1.0, max_tokens=512):
    response = client.chat.completions.create(
        messages=[{"role": "user", "content": summarization_prompt}],
        model=model_name,
        temperature=temperature,
        top_p=top_p,
        max_tokens=max_tokens
    )
    return response.choices[0].message.content
```

### è¿™é‡Œæ¼”ç¤ºä¸¤ç§æ‘˜è¦æ–¹å¼

åˆ†åˆ«å¯¹åº”äº `MapReduce` å’Œ `Refine`ï¼Œä½ å¯ä»¥é€šè¿‡æ¥ä¸‹æ¥çš„ä»£ç æ¥æ„Ÿå—äºŒè€…çš„åŒºåˆ«ã€‚

#### æ–¹æ³•ä¸€ï¼šæ‹†åˆ†ä¸ºå¤šæ®µè¿›è¡Œæ‘˜è¦ï¼ˆMulti-Stage Summarizationï¼‰- MapReduce

![image.png](./assets/image-20240924092040340.png)

1. å°†é•¿æ–‡æœ¬åˆ†æˆå¤šä¸ªè¾ƒå°çš„éƒ¨åˆ†ï¼Œå¹¶åˆ†åˆ«è·å–æ¯ä¸ªå°æ®µè½çš„æ‘˜è¦

    ```python
    # å®šä¹‰æ‘˜è¦æç¤ºæ¨¡æ¿
    summarization_prompt_template = "ç”¨ 300 ä¸ªå­—ä»¥å†…å†™å‡ºè¿™æ®µè§†é¢‘æ–‡æœ¬çš„æ‘˜è¦ï¼Œå…¶ä¸­åŒ…æ‹¬è¦ç‚¹å’Œæ‰€æœ‰é‡è¦ç»†èŠ‚ï¼š<text>"
    
    # å¯¹æ¯ä¸ªæ–‡æœ¬å—ç”Ÿæˆæ‘˜è¦
    paragraph_summaries = []
    for index, chunk in enumerate(chunks):
        print(f"\n========== æ­£åœ¨ç”Ÿæˆç¬¬ {index + 1} æ®µæ‘˜è¦ ==========\n")
        print(f"åŸå§‹æ–‡æœ¬ (ç¬¬ {index + 1} æ®µ):\n{chunk}\n")
        
        # æ„å»ºæ‘˜è¦æç¤º
        summarization_prompt = summarization_prompt_template.replace("<text>", chunk)
        
        # è°ƒç”¨æ‘˜è¦å‡½æ•°
        summary = summarization(
            client=client,
            summarization_prompt=summarization_prompt,
            model_name=model_name,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens
        )
        
        # æ‰“å°ç”Ÿæˆçš„æ‘˜è¦
        print(f"ç”Ÿæˆçš„æ‘˜è¦ (ç¬¬ {index + 1} æ®µ):\n{summary}\n")
        
        # å°†ç”Ÿæˆçš„æ‘˜è¦ä¿å­˜åˆ°åˆ—è¡¨
        paragraph_summaries.append(summary)
    ```

	![image-20240924141506642](./assets/image-20240924141506642.png)

2. åœ¨åˆ†åˆ«è·å–æ¯ä¸ªå°æ®µè½çš„æ‘˜è¦åï¼Œå¤„ç†è¿™äº›æ‘˜è¦ä»¥ç”Ÿæˆæœ€ç»ˆçš„æ‘˜è¦ã€‚

    ```python
    # åˆå¹¶æ®µè½æ‘˜è¦
    collected_summaries = "\n".join(paragraph_summaries)
    
    # å®šä¹‰æœ€ç»ˆæ‘˜è¦æç¤ºæ¨¡æ¿
    final_summarization_prompt = "åœ¨ 500 å­—ä»¥å†…å†™å‡ºä»¥ä¸‹æ–‡å­—çš„ç®€æ´æ‘˜è¦ï¼š<text>"
    final_summarization_prompt = final_summarization_prompt.replace("<text>", collected_summaries)
    
    # ç”Ÿæˆæœ€ç»ˆæ‘˜è¦
    final_summary = summarization(
        client=client,
        summarization_prompt=final_summarization_prompt,
        model_name=model_name,
        temperature=temperature,
        top_p=top_p,
        max_tokens=max_tokens
    )
    
    print(final_summary)
    ```
	![image-20240924141608944](./assets/image-20240924141608944.png)

#### æ–¹æ³•äºŒï¼šç²¾ç‚¼æ–¹æ³•ï¼ˆthe method of Refinement) - Refine

Refinement å°±æ˜¯æŠŠæ¯æ¬¡çš„æ–‡æœ¬å’Œä¹‹å‰çš„æ‘˜è¦ç»“åˆèµ·æ¥ä¸¢ç»™å¤§æ¨¡å‹ï¼Œç±»ä¼¼äºè¿­ä»£ï¼š

![image-20240924092753352](./assets/image-20240924092753352.png)

æ­¥éª¤ï¼ˆPipelineï¼‰å¦‚ä¸‹ï¼š

- ç¬¬1æ­¥ï¼šä»ä¸€å°éƒ¨åˆ†æ•°æ®å¼€å§‹ï¼Œè¿è¡Œpromptç”Ÿæˆåˆå§‹è¾“å‡ºã€‚
- ç¬¬2æ­¥ï¼šå¯¹åç»­æ¯ä¸ªæ–‡æ¡£ï¼Œå°†å‰ä¸€ä¸ªè¾“å‡ºä¸æ–°æ–‡æ¡£ç»“åˆè¾“å…¥ã€‚
- ç¬¬3æ­¥ï¼šLLM æ ¹æ®æ–°æ–‡æ¡£ä¸­çš„ä¿¡æ¯ç²¾ç‚¼è¾“å‡ºã€‚
- ç¬¬4æ­¥ï¼šæ­¤è¿‡ç¨‹æŒç»­è¿­ä»£ï¼Œç›´åˆ°å¤„ç†å®Œæ‰€æœ‰æ–‡æ¡£ã€‚

å¯¹åº”ä»£ç ï¼š

```python
# å®šä¹‰åˆå§‹æ‘˜è¦æç¤ºæ¨¡æ¿
summarization_prompt_template = "ç”¨ 300 ä¸ªå­—ä»¥å†…å†™å‡ºè¿™æ®µè§†é¢‘æ–‡æœ¬çš„æ‘˜è¦ï¼Œå…¶ä¸­åŒ…æ‹¬è¦ç‚¹å’Œæ‰€æœ‰é‡è¦ç»†èŠ‚:<text>"

# å®šä¹‰ç²¾ç‚¼æ‘˜è¦æç¤ºæ¨¡æ¿
summarization_prompt_refinement_template = "è¯·åœ¨ 500 å­—ä»¥å†…ï¼Œç»“åˆåŸå…ˆçš„æ‘˜è¦å’Œæ–°çš„å†…å®¹ï¼Œæä¾›ç®€æ´çš„æ‘˜è¦:<text>"

# åˆå§‹åŒ–ä¿å­˜æ‘˜è¦çš„åˆ—è¡¨
refined_summaries = []

# å¯¹æ–‡æœ¬å—é€æ­¥è¿›è¡Œç²¾ç‚¼æ‘˜è¦ï¼Œå¹¶æ‰“å°ä¸­é—´è¿‡ç¨‹
for index, chunk in enumerate(chunks):
    if index == 0:
        # ç¬¬ä¸€æ­¥ï¼šå¯¹ç¬¬ä¸€æ®µæ–‡æœ¬ç”Ÿæˆåˆå§‹æ‘˜è¦
        print(f"\n========== æ­£åœ¨ç”Ÿæˆç¬¬ {index + 1} æ®µçš„åˆå§‹æ‘˜è¦ ==========\n")
        print(f"åŸå§‹æ–‡æœ¬ (ç¬¬ {index + 1} æ®µ):\n{chunk}\n")
        
        # æ„å»ºåˆå§‹æ‘˜è¦æç¤º
        summarization_prompt = summarization_prompt_template.replace("<text>", chunk)
        
        # è°ƒç”¨æ‘˜è¦å‡½æ•°ç”Ÿæˆç¬¬ä¸€ä¸ªæ‘˜è¦
        first_summary = summarization(
            client=client,
            summarization_prompt=summarization_prompt,
            model_name=model_name,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens
        )
        
        # æ‰“å°ç”Ÿæˆçš„åˆå§‹æ‘˜è¦
        print(f"ç”Ÿæˆçš„æ‘˜è¦ (ç¬¬ {index + 1} æ®µ):\n{first_summary}\n")
        
        # ä¿å­˜ç”Ÿæˆçš„æ‘˜è¦
        refined_summaries.append(first_summary)

    else:
        # åç»­æ­¥éª¤ï¼šç»“åˆå‰ä¸€ä¸ªæ‘˜è¦ä¸å½“å‰æ®µè½è¿›è¡Œç²¾ç‚¼
        print(f"\n========== æ­£åœ¨ç”Ÿæˆç¬¬ {index + 1} æ®µçš„ç²¾ç‚¼æ‘˜è¦ ==========\n")
        print(f"åŸå§‹æ–‡æœ¬ (ç¬¬ {index + 1} æ®µ):\n{chunk}\n")
        
        # æ„å»ºç²¾ç‚¼æ‘˜è¦çš„è¾“å…¥æ–‡æœ¬ï¼Œå°†å‰ä¸€ä¸ªæ‘˜è¦ä¸å½“å‰æ®µè½å†…å®¹ç»“åˆ
        chunk_with_previous_summary = f"å‰ {index} æ®µçš„æ‘˜è¦: {refined_summaries[-1]}\nç¬¬ {index + 1} æ®µçš„å†…å®¹: {chunk}"
        
        # æ„å»ºç²¾ç‚¼æ‘˜è¦æç¤º
        summarization_prompt = summarization_prompt_refinement_template.replace("<text>", chunk_with_previous_summary)
        
        # è°ƒç”¨æ‘˜è¦å‡½æ•°ç”Ÿæˆç²¾ç‚¼æ‘˜è¦
        refined_summary = summarization(
            client=client,
            summarization_prompt=summarization_prompt,
            model_name=model_name,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens
        )
        
        # æ‰“å°ç”Ÿæˆçš„ç²¾ç‚¼æ‘˜è¦
        print(f"ç”Ÿæˆçš„æ‘˜è¦ (ç¬¬ {index + 1} æ®µ):\n{refined_summary}\n")
        
        # ä¿å­˜ç”Ÿæˆçš„ç²¾ç‚¼æ‘˜è¦
        refined_summaries.append(refined_summary)

# æœ€ç»ˆçš„ç²¾ç‚¼æ‘˜è¦ç»“æœå°±æ˜¯ refined_summaries åˆ—è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ 
final_refined_summary = refined_summaries[-1]

print("\n========== æœ€ç»ˆç²¾ç‚¼æ‘˜è¦ç»“æœ ==========\n")
print(final_refined_summary)
```

![image-20240924142344048](./assets/image-20240924142344048.png)

## æ€»ç»“ä¸å±•æœ›

### å¯¹æ·±åº¦å­¦ä¹ ä¸€çªä¸é€šä¹Ÿå¯ä»¥åšå‡º AI åº”ç”¨å—ï¼Ÿ

å½“ç„¶å¯ä»¥ï¼æˆ–è®¸ä½ æ›¾ç»çœ‹åˆ° AI è§†é¢‘å°åŠ©æ‰‹çš„æ—¶å€™ä¼šè§‰å¾—ï¼šâ€œå“‡ï¼Œè‚¯å®šå¾ˆå¤šæŠ€æœ¯ç»†èŠ‚åœ¨é‡Œé¢ï¼Œå­¦ä¹ æ›²çº¿ä¸€å®šå¾ˆé™¡å³­ã€‚â€ä½†å®é™…ä¸Šï¼Œåœ¨çœŸæ­£ç”¨åˆ°æ¨¡å‹çš„åœ°æ–¹ï¼Œä½ åªéœ€è¦åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œè°ƒç”¨ API å°±å¯ä»¥äº†ï¼Œå®Œå…¨ä¸éœ€è¦è‡ªå·±è®­ç»ƒæ¨¡å‹ï¼š

- **éŸ³é¢‘æå–**ï¼šä»è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼Œè¿™ä¸€æ­¥å¯ä»¥é€šè¿‡å„ç§å·¥å…·å®ç°ï¼Œæ¯”å¦‚ `ffmpeg`ã€‚
- **è¯­éŸ³è¯†åˆ«**ï¼šä½¿ç”¨å¼€æºçš„ ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰æ¨¡å‹ï¼Œå¦‚ OpenAI çš„ Whisperï¼Œå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—ã€‚
- **æ–‡æœ¬æ‘˜è¦**ï¼šå€ŸåŠ©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹æ–‡æœ¬è¿›è¡Œæ‘˜è¦ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨ OpenAI API æˆ–å…¶ä»–å¤§æ¨¡å‹ API å®ç°ã€‚

å› æ­¤ï¼Œæ‰€æœ‰è¿™äº›çœ‹ä¼¼å¤æ‚çš„ä»»åŠ¡å…¶å®éƒ½æ˜¯ä½ å¯ä»¥è½»æ¾åšåˆ°çš„ã€‚AI åº”ç”¨å¹¶æ²¡æœ‰æƒ³è±¡ä¸­é‚£ä¹ˆç¥ç§˜ï¼Œåªè¦ä½ äº†è§£å·¥å…·çš„ä½¿ç”¨æ–¹æ³•ï¼Œå°±å¯ä»¥è½»æ¾å»å®ç°ä½ çš„æƒ³æ³•ã€‚

ğŸ¤”**å†æ‰“å¼€ä¸€ä¸‹æ€è·¯**ï¼šç°åœ¨ï¼Œå¤§å¤šæ•°çš„è§†é¢‘éƒ½æœ‰å­—å¹•æˆ–è€… AI å­—å¹•ï¼Œè¿™ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ·å¾„ã€‚é€šè¿‡ç›´æ¥ä¸‹è½½è¿™äº›å­—å¹•ï¼Œä½ çš„ AI åº”ç”¨å°±èƒ½è·³è¿‡éŸ³é¢‘è½¬å½•ç­‰æ­¥éª¤ï¼Œç›´æ¥è¿›å…¥å®ƒæœ€æ“…é•¿çš„ç¯èŠ‚ï¼šç”Ÿæˆæ‘˜è¦ã€‚

Soï¼Œè®©æˆ‘ä»¬å†æ¬¡å›åˆ°æœ€åˆçš„ç–‘é—®ï¼š**AI è§†é¢‘å°åŠ©æ‰‹çœŸçš„â€œçœ‹â€è§†é¢‘äº†å—ï¼Ÿ**

**ç­”**ï¼šä¸ä»…æ²¡çœ‹ï¼Œè¿˜å¤§æ¦‚ç‡æ²¡å¬ã€‚å¦‚æœæŸä¸ªçº¿ä¸Šçš„ AI å°åŠ©æ‰‹åœ¨å¯ä»¥æ­£å¸¸ä¸‹è½½åˆ°éŸ³é¢‘çš„æƒ…å†µä¸‹å´ä¸èƒ½åšæ€»ç»“ï¼Œè¿™å°±è¡¨ç¤ºï¼šå®ƒè¯»çš„æ˜¯å­—å¹•ã€‚

### å¯èƒ½çš„ç–‘é—®

**æ‘˜è¦æ²¡æœ‰æä¾›æ—¶é—´æ®µï¼Œè¿˜æ˜¯åšä¸åˆ°å’Œè¯„è®ºåŒºçš„å°åŠ©æ‰‹ä¸€æ ·çš„äº‹æƒ…ã€‚**

ç¡®å®ï¼Œç›®å‰æˆ‘ä»¬ç”Ÿæˆçš„æ‘˜è¦å¹¶æ²¡æœ‰åŒ…å«å…·ä½“çš„æ—¶é—´æˆ³ä¿¡æ¯ï¼Œä¸åƒä¸€äº›è¯„è®ºåŒºçš„ AI å°åŠ©æ‰‹é‚£æ ·ï¼Œä¸ºæ¯ä¸ªæ‘˜è¦æ®µè½æä¾›å¯¹åº”çš„è§†é¢‘æ—¶é—´ç‚¹ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬åœ¨ `extract_and_save_text()` å¤„ç†çš„æ—¶å€™å°±æŠŠæ—¶é—´æˆ³ä¿¡æ¯æ‹¿æ‰äº†ï¼Œä¸ºä»€ä¹ˆè¿™æ ·åšå‘¢ï¼Ÿ

**ç­”**ï¼šæä¾›ä¸€ä¸ªç®€å•çš„å¤„ç†æ¦‚è§ˆï¼Œä»¥åŠ**å¯¹é½**ä½œä¸š :)

**å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿ**

**ç­”**ï¼šæ–‡æœ¬å¤„ç†æ—¶ä¿ç•™æ—¶é—´æˆ³ + ä¿®æ”¹ prompt æ¨¡ç‰ˆï¼Œå¢åŠ  <start_time> - <end_time> å ä½ç¬¦ã€‚

**è¿™ç¯‡æ–‡ç« æ›´å¤šçš„ä½œä¸ºä¸€ä¸ªå…¥é—¨æ–‡ç« ï¼Œå¸Œæœ›èƒ½å¸®ä½ æ­å¼€é¢çº±çš„ä¸€è§’ã€‚**

## å‚è€ƒé“¾æ¥

- [ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯¼è®º](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)
- [HW9 PDF](../GenAI_PDF/HW9.pdf) å½“å‰æ–‡ç« ä¸­çš„æœ‰è¶£çš„å›¾ç‰‡å¤§å¤šæ¥è‡ªäºæ­¤
- [Whisper - Paper](https://arxiv.org/abs/2212.04356)
- [Whisper - Github](https://github.com/openai/whisper)
