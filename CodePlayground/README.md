# CodePlayground

æ¬¢è¿æ¥åˆ° **CodePlayground** ğŸ¡ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯¾ç¨‹ç›¸å…³çš„è„šæœ¬æ¸¸ä¹åœºã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œç©è½¬å„ç§å·¥å…·å’Œè„šæœ¬ï¼Œäº«å—å­¦ä¹ å’Œå®éªŒçš„ä¹è¶£ã€‚

â€‹	æ³¨æ„âš ï¸ï¼Œæ‰€æœ‰çš„è„šæœ¬éƒ½æ˜¯ä¸€ä¸ª Toy çš„ç‰ˆæœ¬ã€‚

## æ­å»ºåœºåœ°

1. å…‹éš†ä»“åº“ï¼ˆå¦‚æœä¹‹å‰å…‹éš†è¿‡å¯ä»¥è·³è¿‡ï¼‰ï¼š

   ```bash
   git clone https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN.git
   cd AI-Guide-and-Demos-zh_CN/CodePlayground
   ```

2. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ï¼‰ï¼š

   ```bash
   conda create -n playground python=3.9
   conda activate playground
   ```

3. å®‰è£…ä¾èµ–

   ### PyTorch ä¾èµ–

   é€‰æ‹©ä»¥ä¸‹ä¸¤ç§æ–¹å¼ä¹‹ä¸€å®‰è£… PyTorchï¼š

   ```python
   # pip
   pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   
   # conda
   conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
   ```

   ### AI Summarizer ä¾èµ–

   a. **ffmpeg**ï¼ˆç”¨äºè§†é¢‘è½¬éŸ³é¢‘ï¼‰

   ```bash
   # Linux
   sudo apt-get update
   sudo apt-get install ffmpeg
   
   # Mac
   brew install ffmpeg
   ```
   
   b. **Python åº“**
   
   ```python
   pip install openai-whisper openai pyyaml librosa srt certifi
   pip install numpy==1.26.4  # >= 2.0.0 ä¼šæ— æ³•æ­£å¸¸æ‰§è¡Œ summarizer.py
   ```
   
   ### SD LoRA ä¾èµ–
   
   ```bash
   pip install transformers diffusers peft tqdm numpy pyyaml pillow
   ```
   
   ### AI Chat ä¾èµ–
   
   æ ¹æ®æ¨¡å‹æ–‡ä»¶å¯¹åº”é…ç½®ã€‚
   
   a. **GPTQ æ¨¡å‹æ–‡ä»¶**
   
   ```bash
   pip install optimum
   git clone https://github.com/PanQiWei/AutoGPTQ.git && %cd AutoGPTQ
   pip install -vvv --no-build-isolation -e .
   ```
   
   b. **AWQ æ¨¡å‹æ–‡ä»¶**
   
   ```bash
   pip install autoawq autoawq-kernels
   ```
   
   c. **GGUF æ¨¡å‹æ–‡ä»¶**
   
   ```bash
   CUDA_HOME="$(find /usr/local -name "cuda" -exec readlink -f {} \; \
             | awk '{print length($0), $0}' \
             | sort -n \
                | head -n1 \
                | cut -d ' ' -f 2)" && \
   CMAKE_ARGS="-DGGML_CUDA=on \
            -DCUDA_PATH=${CUDA_HOME} \
            -DCUDAToolkit_ROOT=${CUDA_HOME} \
            -DCUDAToolkit_INCLUDE_DIR=${CUDA_HOME} \
            -DCUDAToolkit_LIBRARY_DIR=${CUDA_HOME}/lib64 \
               -DCMAKE_CUDA_COMPILER=${CUDA_HOME}/bin/nvcc" \
   FORCE_CMAKE=1 \
   pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir --verbose
   ```
   


## å½“å‰çš„ç©å…·

<details> <summary> <strong>1. AI Summarizer</strong> </summary>

> [15. ç”¨ API å®ç° AI è§†é¢‘æ‘˜è¦ï¼šåŠ¨æ‰‹åˆ¶ä½œå±äºä½ çš„ AI è§†é¢‘åŠ©æ‰‹](../Guide/15.%20ç”¨%20API%20å®ç°%20AI%20è§†é¢‘æ‘˜è¦ï¼šåŠ¨æ‰‹åˆ¶ä½œå±äºä½ çš„%20AI%20è§†é¢‘åŠ©æ‰‹.md)

**[summarizer.py](./summarizer.py)** æ˜¯ä¸€ä¸ª AI æ‘˜è¦å·¥å…·ï¼Œç”¨äºä»è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶ä¸­æå–å­—å¹•å¹¶ç”Ÿæˆè§†é¢‘æ‘˜è¦ï¼Œä¹Ÿå¯ä»¥ç›´æ¥å¤„ç†ç°æœ‰çš„å­—å¹•æ–‡ä»¶ã€‚å®ƒé›†æˆäº† Whisper æ¨¡å‹å’Œ OpenAI API æ¥è‡ªåŠ¨åŒ–è¿™äº›è¿‡ç¨‹ã€‚

#### åŠŸèƒ½

- **è§†é¢‘è½¬éŸ³é¢‘**ï¼šä½¿ç”¨ FFmpeg å°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸º WAV æ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶ã€‚
- **éŸ³é¢‘è½¬å½•**ï¼šä½¿ç”¨ Whisper æ¨¡å‹å°†éŸ³é¢‘è½¬å½•ä¸ºæ–‡æœ¬å­—å¹•ã€‚
- **å­—å¹•ç”Ÿæˆ**ï¼šç”Ÿæˆ SRT æ ¼å¼çš„å­—å¹•æ–‡ä»¶ã€‚
- **è§†é¢‘æ‘˜è¦**ï¼šä½¿ç”¨ OpenAI çš„æ¨¡å‹ç”Ÿæˆè§†é¢‘å†…å®¹çš„æ‘˜è¦ã€‚

#### å¿«é€Ÿä½¿ç”¨

```bash
python summarizer.py examples/summarizer.mp4
```

ä»“åº“æä¾›äº†ä¸€ä¸ªæ ·ä¾‹è§†é¢‘ä¾›ä½ è¿è¡Œï¼Œä»¥é˜²æ­¢å¯èƒ½å­˜åœ¨çš„é€‰æ‹©å›°éš¾ç—‡ :)

#### ä½¿ç”¨æ–¹æ³•

ä½ å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œè¿è¡Œ `summarizer.py`ï¼Œå¹¶æŒ‡å®šè¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„ï¼š

   ```bash
python summarizer.py file_path [--api_key YOUR_API_KEY] [--output_dir OUTPUT_DIR] [å…¶ä»–å¯é€‰å‚æ•°]
   ```

   - `file_path`ï¼šæ›¿æ¢ä¸ºè¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„ï¼Œå¯ä»¥æ˜¯è§†é¢‘ã€éŸ³é¢‘æˆ–å­—å¹•æ–‡ä»¶ã€‚
   - `--api_key`ï¼šå¯é€‰å‚æ•°ï¼ŒæŒ‡å®š OpenAI API å¯†é’¥ã€‚å¦‚æœé…ç½®æ–‡ä»¶ä¸­å·²æœ‰å¯†é’¥ï¼Œåˆ™å¯ä»¥çœç•¥æ­¤å‚æ•°ã€‚å½“ä¸ä¼ å…¥æ—¶ï¼Œä¼šè¦æ±‚è¾“å…¥ï¼ŒéªŒè¯åä¼šè‡ªåŠ¨æ›´æ–° config.yamlã€‚
   - `--output_dir`ï¼šå¯é€‰å‚æ•°ï¼ŒæŒ‡å®šç”Ÿæˆæ–‡ä»¶ä¿å­˜çš„ç›®å½•ï¼Œé»˜è®¤ä¸º `./output/` æ–‡ä»¶å¤¹ã€‚
   - å…¶ä»–å‚æ•°è§[é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)æˆ–ä½¿ç”¨ `--help` è¿›è¡ŒæŸ¥çœ‹

   ä»¥ä¸Šå‘½ä»¤ä¼šä»æ ·ä¾‹è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼Œç”Ÿæˆå­—å¹•å¹¶è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ã€‚

   ç”Ÿæˆçš„æ–‡ä»¶é»˜è®¤ä¼šä¿å­˜åœ¨ `./output` æ–‡ä»¶å¤¹ä¸‹ï¼ŒåŒ…æ‹¬ï¼š
   - **å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶**ï¼ˆMP3æ ¼å¼ï¼‰
   - **è½¬å½•ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶**ï¼ˆSRT æ ¼å¼ï¼‰
   - **è§†é¢‘æ‘˜è¦æ–‡ä»¶**ï¼ˆTXT æ ¼å¼ï¼‰

#### é…ç½®ç®¡ç†

è„šæœ¬æ”¯æŒä» `config.yaml` æ–‡ä»¶ä¸­è¯»å–é»˜è®¤é…ç½®ï¼Œä½ å¯ä»¥é€šè¿‡ç¼–è¾‘è¯¥æ–‡ä»¶æ¥è‡ªå®šä¹‰å‚æ•°ï¼Œé¿å…æ¯æ¬¡è¿è¡Œè„šæœ¬æ—¶æ‰‹åŠ¨æŒ‡å®šã€‚

[config.yaml](./config.yaml#L1) ç¤ºä¾‹ï¼š

   ```yaml
summarizer:
  model_name: "medium"
  language: "zh"
  whisper_temperature: 0.2
  llm_temperature: 0.2
  timestamped: False
  max_tokens: 1000
  output_dir: "./output"
  api_key:
  api_base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
   ```

**é…ç½®è¯´æ˜**

- `model_name`: Whisper æ¨¡å‹åç§°ï¼ˆå¦‚ `tiny`, `base`, `small`, `medium`, `large-v3`ï¼‰ã€‚
- `language`: è½¬å½•è¯­è¨€ï¼Œé»˜è®¤è®¾ç½®ä¸º `zh`ï¼ˆä¸­æ–‡ï¼‰ã€‚
- `whisper_temperature`: Whisper æ¨¡å‹éŸ³é¢‘è½¬å­—å¹•æ—¶çš„æ¸©åº¦ï¼ŒèŒƒå›´ä¸º 0 åˆ° 1ã€‚
- `llm_temperature`: å¤§æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶çš„æ¸©åº¦ï¼ŒèŒƒå›´ä¸º 0 åˆ° 1ã€‚
- `timestamped`: æ˜¯å¦ä¿ç•™è½¬å½•æ–‡æœ¬çš„æ—¶é—´æˆ³ï¼Œå¸ƒå°”å€¼ã€‚
- `max_tokens:` æ‘˜è¦ç”Ÿæˆæ—¶çš„æœ€å¤§ token æ•°é‡ã€‚
- `output_dir`: ç”Ÿæˆæ–‡ä»¶çš„é»˜è®¤ä¿å­˜ç›®å½•ã€‚
- `api_key`: ä½ çš„ OpenAI API å¯†é’¥ï¼Œå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®æ–‡ä»¶æŒ‡å®šã€‚
- `api_base_url`: é»˜è®¤ä½¿ç”¨é˜¿é‡Œäº‘å¤§æ¨¡å‹å¹³å°ã€‚


#### æ³¨æ„äº‹é¡¹

- **ä¸­é—´æ–‡ä»¶ä¿ç•™**ï¼šé»˜è®¤æƒ…å†µä¸‹ï¼Œsummarizer.py ä¼šä¿ç•™æ‰€æœ‰ä¸­é—´è½¬æ¢æ–‡ä»¶ï¼Œå¦‚éŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶ã€‚å¦‚æœä½ éœ€è¦åˆ é™¤è¿™äº›ä¸­é—´æ–‡ä»¶ï¼Œå¯ä»¥åœ¨è„šæœ¬ä¸­è¿›è¡Œç›¸åº”ä¿®æ”¹ã€‚
- **æ¨¡å‹é€‰æ‹©**ï¼šåœ¨ `model_name` ä¸­é€‰æ‹© Whisper æ¨¡å‹æ—¶æ³¨æ„ï¼Œæ¨¡å‹è¶Šå¤§å¯¹æ˜¾å­˜çš„å ç”¨è¶Šé«˜ï¼Œå»ºè®®åœ¨æ˜¾å­˜å……è¶³çš„ç¯å¢ƒä¸‹ä½¿ç”¨ã€‚

</details>

<details> <summary> <strong>2. SD LoRA</strong> </summary>

> [16. ç”¨ LoRA å¾®è°ƒ Stable Diffusionï¼šæ‹†å¼€ç‚¼ä¸¹ç‚‰ï¼ŒåŠ¨æ‰‹å®ç°ä½ çš„ç¬¬ä¸€æ¬¡ AI ç»˜ç”»](../Guide/16.%20ç”¨%20LoRA%20å¾®è°ƒ%20Stable%20Diffusionï¼šæ‹†å¼€ç‚¼ä¸¹ç‚‰ï¼ŒåŠ¨æ‰‹å®ç°ä½ çš„ç¬¬ä¸€æ¬¡%20AI%20ç»˜ç”».md)

**[sd_lora.py](./sd_lora.py)** æ˜¯ä¸€ä¸ª AI ç»˜ç”»å·¥å…·ï¼Œå¯¹äºæŒ‡å®šæ•°æ®é›†å’Œ Stable Diffusion æ¨¡å‹ï¼Œè‡ªåŠ¨åº”ç”¨ LoRA å¾®è°ƒå¹¶ç”Ÿæˆå›¾åƒã€‚

### åŠŸèƒ½

- **æ¨¡å‹å¾®è°ƒ**ï¼šä½¿ç”¨ LoRA å¯¹é¢„è®­ç»ƒçš„ Stable Diffusion æ¨¡å‹è¿›è¡Œç®€å•çš„å¾®è°ƒï¼Œé€‚åº”ç‰¹å®šçš„æ•°æ®é›†æˆ–é£æ ¼ã€‚
- **å›¾åƒç”Ÿæˆ**ï¼šåœ¨è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒã€‚

### ä½¿ç”¨æ–¹æ³•

ä½ å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œè¿è¡Œ `sd_lora.py`ï¼Œå¹¶æ ¹æ®éœ€è¦æŒ‡å®šå‚æ•°ï¼š

```bash
python sd_lora.py [å¯é€‰å‚æ•°]
```

é»˜è®¤ä½¿ç”¨ `config.yaml` ä¸­çš„é…ç½®è¿›è¡Œè®­ç»ƒå’Œå›¾åƒç”Ÿæˆã€‚

### ç¤ºä¾‹

1. **å‡†å¤‡æ ·ä¾‹æ•°æ®é›†[^1]**ï¼š

   ```bash
   wget https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/raw/refs/heads/master/Demos/data/14/Datasets.zip
   unzip Datasets.zip
   ```

2. **ä½¿ç”¨æŒ‡å®šçš„æ•°æ®é›†å’Œæç¤ºæ–‡ä»¶**ï¼š

   ```bash
   # å› ä¸ºå·²ç»åœ¨ config.yaml ä¸­é…ç½®ï¼Œæ‰€ä»¥å¯ä»¥ä¸æŒ‡å®šå‚æ•°
   python sd_lora.py
   # python sd_lora.py -d ./Datasets/Brad -gp ./Datasets/prompts/validation_prompt.txt
   ```

   - `-d` æˆ– `--dataset_path`ï¼šæ•°æ®é›†è·¯å¾„ã€‚
   - `-gp` æˆ– `--prompts_path`ï¼šç”Ÿæˆå›¾åƒæ—¶ä½¿ç”¨çš„æ–‡æœ¬æç¤ºæ–‡ä»¶è·¯å¾„ã€‚

3. **è·³è¿‡è®­ç»ƒï¼Œä»…ç”Ÿæˆå›¾åƒ**ï¼Œä½¿ç”¨ `--no-train` å‚æ•°ï¼š

   ```bash
   python sd_lora.py --no-train
   ```

   è¯·ç¡®ä¿åœ¨ `args.model_path` æŒ‡å®šçš„è·¯å¾„ä¸‹å­˜åœ¨å·²å¾®è°ƒçš„æ¨¡å‹æƒé‡ã€‚

4. **è·³è¿‡å›¾åƒç”Ÿæˆï¼Œä»…è¿›è¡Œè®­ç»ƒ**ï¼Œä½¿ç”¨ `--no-generate` å‚æ•°ï¼š

   ```bash
   python sd_lora.py --no-generate
   ```

5. **æŒ‡å®šå…¶ä»–å‚æ•°**ï¼š

   ```bash
   python sd_lora.py -e 500 -b 4 -u 1e-4 -t 1e-5
   ```

   - `-e` æˆ– `--max_train_steps`ï¼šæ€»è®­ç»ƒæ­¥æ•°ã€‚
   - `-b` æˆ– `--batch_size`ï¼šè®­ç»ƒæ‰¹æ¬¡å¤§å°ã€‚
   - `-u` æˆ– `--unet_learning_rate`ï¼šUNet çš„å­¦ä¹ ç‡ã€‚
   - `-t` æˆ– `--text_encoder_learning_rate`ï¼šæ–‡æœ¬ç¼–ç å™¨çš„å­¦ä¹ ç‡ã€‚
   - å…¶ä»–å‚æ•°ä½¿ç”¨ `--help` è¿›è¡ŒæŸ¥çœ‹ã€‚

### é…ç½®ç®¡ç†

è„šæœ¬æ”¯æŒä» `config.yaml` æ–‡ä»¶ä¸­è¯»å–é»˜è®¤é…ç½®ï¼Œé¿å…æ¯æ¬¡è¿è¡Œæ—¶æ‰‹åŠ¨æŒ‡å®šæ‰€æœ‰å‚æ•°ã€‚

[config.yaml](./config.yaml#L12) ç¤ºä¾‹ï¼š

```yaml
train:
  root: "./SD"
  dataset_path: "./Datasets/Brad"
  captions_folder: # å­˜æ”¾æ–‡æœ¬æ ‡æ³¨çš„è·¯å¾„ï¼Œé»˜è®¤å’Œ dataset_path ä¸€è‡´
  model_path: # checkpoint-last è·¯å¾„é»˜è®¤ä¸º root + dataset_name + 'logs/checkpoint-last'ï¼Œå¦‚æœä½¿ç”¨äº† --no-trainï¼Œéœ€è¦ç¡®ä¿ model_path è·¯å¾„å­˜åœ¨
  pretrained_model_name_or_path: "digiplay/AnalogMadness-realistic-model-v7"
  resume: False
  batch_size: 2
  max_train_steps: 200
  unet_learning_rate: 1e-4
  text_encoder_learning_rate: 1e-4
  seed: 1126
  weight_dtype: "torch.bfloat16"
  snr_gamma: 5
  lr_scheduler_name: "cosine_with_restarts"
  lr_warmup_steps: 100
  num_cycles: 3
generate:
  save_folder: # å›¾åƒä¿å­˜è·¯å¾„é»˜è®¤ä¸º root + train.dataset_name + '/inference'
  prompts_path: "./Datasets/prompts/validation_prompt.txt"
  num_inference_steps: 50
  guidance_scale: 7.5
```

**é…ç½®è¯´æ˜**

- **train**
  - `root`ï¼šé¡¹ç›®çš„æ ¹è·¯å¾„ï¼Œç”¨äºç»„ç»‡æ¨¡å‹å’Œè¾“å‡ºæ–‡ä»¶ã€‚
  - `dataset_path`ï¼šæ•°æ®é›†è·¯å¾„ï¼ŒåŒ…å«å›¾åƒå’Œå¯¹åº”çš„æ–‡æœ¬æè¿°ã€‚
  - `captions_folder`: å­˜æ”¾æ–‡æœ¬æ ‡æ³¨çš„è·¯å¾„ï¼Œé»˜è®¤å’Œ `dataset_path` ä¸€è‡´ã€‚
  - `model_path`ï¼šæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼Œé»˜è®¤æ ¹æ® `root` å’Œ `dataset_name` è‡ªåŠ¨ç”Ÿæˆã€‚å¦‚æœä½¿ç”¨ `--no-train`ï¼Œéœ€è¦ç¡®ä¿è¯¥è·¯å¾„å­˜åœ¨å·²å¾®è°ƒçš„æ¨¡å‹ã€‚
  - `pretrained_model_name_or_path`ï¼šé¢„è®­ç»ƒçš„ Stable Diffusion æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„ã€‚
  - `resume`: æ˜¯å¦ä»ä¸Šä¸€æ¬¡è®­ç»ƒä¸­æ¢å¤ï¼Œé»˜è®¤ä¸ºå¦ã€‚
  - `batch_size`ï¼šè®­ç»ƒæ‰¹æ¬¡å¤§å°ã€‚
  - `max_train_steps`ï¼šæ€»è®­ç»ƒæ­¥æ•°ã€‚
  - `unet_learning_rate`ï¼šUNet çš„å­¦ä¹ ç‡ã€‚
  - `text_encoder_learning_rate`ï¼šæ–‡æœ¬ç¼–ç å™¨çš„å­¦ä¹ ç‡ã€‚
  - `seed`ï¼šéšæœºæ•°ç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°ã€‚
  - `weight_dtype`ï¼šæ¨¡å‹æƒé‡çš„æ•°æ®ç±»å‹ï¼Œå¦‚ `"torch.bfloat16"`ã€`"torch.float32"` ç­‰ã€‚
  - `snr_gamma`ï¼šä¿¡å™ªæ¯” (SNR) å‚æ•°ï¼Œç”¨äºè°ƒæ•´è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±è®¡ç®—ã€‚
  - `lr_scheduler_name`ï¼šå­¦ä¹ ç‡è°ƒåº¦å™¨çš„åç§°ã€‚
  - `lr_warmup_steps`ï¼šå­¦ä¹ ç‡é¢„çƒ­æ­¥æ•°ã€‚
  - `num_cycles`ï¼šå­¦ä¹ ç‡è°ƒåº¦å™¨çš„å‘¨æœŸæ•°é‡ã€‚
- **generate**
  - `save_folder`ï¼šç”Ÿæˆçš„å›¾åƒä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸º `root + dataset_name + '/inference'`ã€‚
  - `prompts_path`ï¼šæ–‡æœ¬æç¤ºæ–‡ä»¶è·¯å¾„ï¼Œæ¯è¡Œä¸€ä¸ªæç¤ºã€‚
  - `num_inference_steps`ï¼šç”Ÿæˆå›¾åƒæ—¶çš„æ¨ç†æ­¥éª¤æ•°ã€‚
  - `guidance_scale`ï¼šç”Ÿæˆå›¾åƒæ—¶çš„æŒ‡å¯¼å°ºåº¦ã€‚

### æ³¨æ„äº‹é¡¹

- **æ˜¾å­˜éœ€æ±‚**ï¼šå¾®è°ƒå’Œç”Ÿæˆè¿‡ç¨‹å¯¹æ˜¾å­˜æœ‰ä¸€å®šè¦æ±‚ã€‚
- **æ•°æ®é›†å‡†å¤‡**ï¼šç¡®ä¿æ•°æ®é›†ä¸­å›¾åƒå’Œå¯¹åº”çš„æ–‡æœ¬æè¿°æ•°é‡ä¸€è‡´ï¼Œä¸”æ–‡ä»¶åå¯¹åº”ï¼Œå¯ä»¥é€‰æ‹©ä¿®æ”¹ `Text2ImageDataset` ç±»æ¥é€‚é…ç‰¹å®šæ ¼å¼çš„æ•°æ®ã€‚

### ç›®å½•ç»“æ„

åœ¨æ ·ä¾‹æ•°æ®é›†ä¸Šè¿è¡Œè„šæœ¬åï¼š

```
CodePlayground/
â”‚
â”œâ”€â”€ Datasets/                   # æ•°æ®é›†æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ Brad/                   # ç¤ºä¾‹æ•°æ®é›†æ–‡ä»¶å¤¹ï¼ˆæ ·ä¾‹æ•°æ®é›†ä¸­ï¼Œæ–‡æœ¬æè¿°ä¸å›¾ç‰‡åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹ï¼‰
â”‚   â”‚   â”œâ”€â”€ image_001.jpg       # ç¤ºä¾‹å›¾ç‰‡
â”‚   â”‚   â”œâ”€â”€ image_001.txt       # ç¤ºä¾‹å›¾ç‰‡çš„æ–‡æœ¬æè¿°
â”‚   â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â”‚   â”œâ”€â”€ image_002.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ prompts/                # æ–‡æœ¬æç¤ºæ–‡ä»¶å¤¹
â”‚       â”œâ”€â”€ validation_prompt.txt # ç”Ÿæˆå›¾åƒæ—¶ä½¿ç”¨çš„æç¤º
â”‚
â”œâ”€â”€ SD/                         # é»˜è®¤è¾“å‡ºè·¯å¾„
â”‚   â”œâ”€â”€ Brad/                   # ä½¿ç”¨çš„æ•°æ®é›†åç§°ï¼Œè‡ªåŠ¨ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ logs/               # æ¨¡å‹è®­ç»ƒæ£€æŸ¥ç‚¹
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint-last/ # æœ€åä¿å­˜çš„å¾®è°ƒæ¨¡å‹
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ unet/       # å¾®è°ƒåçš„ UNet æ¨¡å‹
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ text_encoder/ # å¾®è°ƒåçš„æ–‡æœ¬ç¼–ç å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint-100/  # ä¸­é—´æ£€æŸ¥ç‚¹ï¼ˆæ­¥æ•°å‘½åï¼‰
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ unet/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ text_encoder/
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ inference/          # ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶å¤¹
â”‚   â”‚   â”‚   â”œâ”€â”€ generated_1.png # ç¤ºä¾‹ç”Ÿæˆå›¾åƒ
â”‚   â”‚   â”‚   â”œâ”€â”€ generated_2.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ sd_lora.py                  # å¾®è°ƒå’Œç”Ÿæˆå›¾åƒçš„ä¸»è„šæœ¬
â””â”€â”€ config.yaml                 # é…ç½®æ–‡ä»¶
```


[^1]: [Celebrity Face Image Dataset](https://www.kaggle.com/datasets/vishesh1412/celebrity-face-image-dataset/data).

</details>

</details> <details> <summary> <strong>3. AI Chat</strong> </summary>

> [19a. ä»åŠ è½½åˆ°å¯¹è¯ï¼šä½¿ç”¨ Transformers æœ¬åœ°è¿è¡Œé‡åŒ– LLM å¤§æ¨¡å‹ï¼ˆGPTQ & AWQï¼‰](../Guide/19a.%20ä»åŠ è½½åˆ°å¯¹è¯ï¼šä½¿ç”¨%20Transformers%20æœ¬åœ°è¿è¡Œé‡åŒ–%20LLM%20å¤§æ¨¡å‹ï¼ˆGPTQ%20%26%20AWQï¼‰.md)
>
> [19b. ä»åŠ è½½åˆ°å¯¹è¯ï¼šä½¿ç”¨ Llama-cpp-python æœ¬åœ°è¿è¡Œé‡åŒ– LLM å¤§æ¨¡å‹ï¼ˆGGUFï¼‰](../Guide/19b.%20ä»åŠ è½½åˆ°å¯¹è¯ï¼šä½¿ç”¨%20Llama-cpp-python%20æœ¬åœ°è¿è¡Œé‡åŒ–%20LLM%20å¤§æ¨¡å‹ï¼ˆGGUFï¼‰.md)
>
> æ ¹æ® [AI Chat ä¾èµ–](#ai-chat-ä¾èµ–)è¿›è¡Œç¯å¢ƒé…ç½®ã€‚

**[chat.py](./chat.py)** æ˜¯ä¸€ä¸ª LLM å¯¹è¯å·¥å…·ï¼Œç”¨äºä¸é‡åŒ–çš„å¤§æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¯¹è¯ã€‚æ”¯æŒ GPTQã€AWQ å’Œ GGUF æ ¼å¼çš„æ¨¡å‹åŠ è½½ä¸æ¨ç†ã€‚

#### åŠŸèƒ½

- **ä¸ LLM å¯¹è¯**ï¼šæ”¯æŒä»æ¨¡å‹è·¯å¾„åŠ è½½ä¸åŒæ ¼å¼çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œå¹¶æ ¹æ®é…ç½®ä¸ä¹‹è¿›è¡Œäº¤äº’ã€‚
- **é…ç½®ç®¡ç†**ï¼šç°åœ¨æ”¯æŒåˆæ­¥çš„ç¯å¢ƒæ£€æµ‹æ˜¯å¦ç¬¦åˆè„šæœ¬è¿è¡Œæ¡ä»¶ã€‚
- **èŠå¤©å†å²ä¿å­˜**ï¼šè‡ªåŠ¨ä¿å­˜èŠå¤©è®°å½•å¹¶æ”¯æŒä»å†å²è®°å½•ä¸­åŠ è½½ã€‚

#### å¿«é€Ÿä½¿ç”¨

```bash
python chat.py <model_path>
```

æ›¿æ¢ `<model_path>` ä¸º GPTQã€AWQ æˆ– GGUF æ ¼å¼æ¨¡å‹çš„è·¯å¾„ï¼Œå³å¯å¼€å§‹ä¸æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚

ä»¥ [DeepSeek-R1-Distill-Qwen-7B-GGUF](https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF) ä¸ºä¾‹ï¼ŒåŠ è½½ Q5_K_L é‡åŒ–ç‰ˆæœ¬ï¼š

```bash
python chat.py 'bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/*Q5_K_L.gguf' --remote
```

**æ³¨æ„ï¼Œæš‚æ—¶ä»…æ”¯æŒæ‹¥æœ‰ `tokenizer.chat_template` å±æ€§çš„æ¨¡å‹è¿›è¡Œæ­£å¸¸å¯¹è¯ï¼Œå¯¹äºå…¶ä»–æ¨¡å‹ï¼Œéœ€è¦è‡ªå®šä¹‰ [config.yaml](./config.yaml#L38) ä¸­çš„ `custom_template` å‚æ•°ã€‚**

#### ä½¿ç”¨æ–¹æ³•

å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œè¿è¡Œ `chat.py`ï¼Œå¹¶æŒ‡å®šè¦åŠ è½½çš„æ¨¡å‹è·¯å¾„ï¼š

```bash
python chat.py <model_path> [--no_stream] [--max_length 512] [--io history.json] [å…¶ä»–å¯é€‰å‚æ•°]
```

- `model_path`ï¼šæ¨¡å‹çš„åç§°æˆ–æœ¬åœ°è·¯å¾„ï¼Œå¯ä»¥æ˜¯ GPTQã€AWQ æˆ– GGUF æ ¼å¼çš„æ¨¡å‹ã€‚
- `--no_stream`ï¼šç¦ç”¨æµå¼è¾“å‡ºï¼Œæ¨¡å‹ä¼šåœ¨ç”Ÿæˆå®Œæ¯•åä¸€æ¬¡æ€§è¿”å›å…¨éƒ¨å†…å®¹ï¼ˆä¸å»ºè®®å¯ç”¨ï¼Œé»˜è®¤æµå¼è¾“å‡ºï¼‰ã€‚
- `--max_length`ï¼šå¯é€‰å‚æ•°ï¼Œç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦ã€‚
- `--io`ï¼šåŒæ—¶æŒ‡å®šå¯¹è¯å†å²çš„è¾“å…¥å’Œè¾“å‡ºè·¯å¾„ï¼Œé¿å…é‡å¤é…ç½®ã€‚
- `--remote`ï¼š**ä»…é€‚ç”¨äº GGUF æ¨¡å‹æ–‡ä»¶**ï¼Œä» `<model_path>` è§£æå‡º `repo_id` å’Œ `model_name` è¿›è¡Œè¿œç¨‹æ¨¡å‹æ–‡ä»¶çš„åŠ è½½ã€‚
- å…¶ä»–å‚æ•°ä½¿ç”¨ `--help` è¿›è¡ŒæŸ¥çœ‹ã€‚

[config.yaml](./config.yaml#L35) ç¤ºä¾‹ï¼š

```yaml
chat:
  max_length: 512
  no_stream: False
  custom_template: |
    {{ bos_token }}
    {% for message in messages %}
        {% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}
            {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}
        {% endif %}
        
        {% if message['role'] == 'user' %}
            {{ '[INST] ' + message['content'] + ' [/INST]' }}
        {% elif message['role'] == 'assistant' %}
            {{ message['content'] + eos_token}}
        {% else %}
            {{ raise_exception('Only user and assistant roles are supported!') }}
        {% endif %}
    {% endfor %}
```

</details>


---

æ¬¢è¿ä½ éšæ—¶åœ¨è¿™ä¸ªæ¸¸ä¹åœºä¸­æ¢ç´¢æ›´å¤šè„šæœ¬ï¼